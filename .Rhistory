import zipfile
import os
import pandas as pd
import re
# Unzipping the file
with zipfile.ZipFile("data/speeches.zip", 'r') as zip_ref:
zip_ref.extractall("data")
# Getting the list of filenames of the extracted speeches from the 'data' directory
filenames = os.listdir("data")
filenames = [filename for filename in filenames if filename.endswith('.txt')]
# Read the content of each speech file
speeches = []
for filename in filenames:
with open(os.path.join("data", filename), 'r', encoding='utf-8') as file:
# Skip the first two lines
next(file)
next(file)
speeches.append(file.read())
# Create DataFrame
sona = pd.DataFrame({'filename': filenames, 'speech': speeches})
# Extract year and president for each speech
sona['year'] = sona['filename'].str[:4]
sona['president'] = sona['filename'].str.split('_').str[-1].str.split('.').str[0]
# Clean the sona dataset by adding the date and removing unnecessary text
replace_reg = r'(http.*?(\s|.$))|(www.*?(\s|.$))|&amp;|&lt;|&gt;|\n'
sona['speech'] = sona['speech'].str.replace(replace_reg, ' ')
sona['date'] = sona['speech'].str[:30]
date_replacements = {
"February": "02",
"June": "06",
"Feb": "02",
"May": "05",
"Jun": "06",
"Thursday, ": "",
" ": "-",
"[A-z]": "",
"-----": "",
"----": "",
"---": "",
"--": ""
}
for key, value in date_replacements.items():
sona['date'] = sona['date'].str.replace(key, value)
# Split speeches into sentences
sona_sentences = sona['speech'].str.split(r'(?<!\w\.\w.)(?<![A-Z][a-z]\.)(?<=\.|\?)\s', expand=True).stack().reset_index(level=-1, drop=True)
sona_sentences.name = 'sentence'
# Display the first few rows of the updated sentences
sona_sentences.head()
# Split speeches into sentences
sona_sentences = sona['speech'].str.split(r'(?<!\w\.\w.)(?<![A-Z][a-z]\.)(?<=\.|\?)\s', expand=True).stack().reset_index(level=-1, drop=True)
sona_sentences.name = 'sentence'
# Merge with the president column to associate each sentence with the president
df_sentences = sona[['president']].join(sona_sentences)
# Filter only relevant columns
df_sentences = df_sentences[['sentence', 'president']]
# Display the first few rows of the final dataframe
df_sentences.head()
# Filter sentences for president " Motlanthe"
motlanthe_sentences_corrected = df_sentences[df_sentences['president'] == ' Motlanthe']
# Display the first few sentences from Motlanthe's speeches
motlanthe_sentences_corrected.head(10)
import matplotlib.pyplot as plt
# Group by president and count sentences
sentence_counts = df_sentences.groupby('president').size()
# Plot
plt.figure(figsize=(12, 6))
sentence_counts.sort_values().plot(kind='barh', color='skyblue')
plt.title('Number of Sentences for Each President')
plt.xlabel('Number of Sentences')
plt.ylabel('President')
plt.show()
# Display the sentence counts for each president
sentence_counts.sort_values(ascending=False)
library("knitr")
library(kableExtra)
knitr::opts_chunk$set(echo = T, warning = F, message = F, fig.pos = 'H')
options(digits=4)
require("latex2exp")
library(readxl)
library(dplyr)
library(readr)
library(tidyr)
library(ggplot2)
library(seminr)
library(haven)
# Set a random seed for reproducible results.
set.seed(1)
setwd("/Users/jared/Library/Group Containers/UBF8T346G9.OneDriveStandaloneSuite/OneDrive.noindex/OneDrive/Documents/University stuff/Masters Year/Consulting/Adhir/Analysis")
# Load the data
library(readxl)
headings = read_excel("TRAM_data.xlsx",
col_names = FALSE)[2,]
headings
TRAM_data <- read_excel("TRAM_data.xlsx",
col_names = FALSE, skip = 3)
colnames(TRAM_data) = headings
View(TRAM_data)
TRAM_data = TRAM_data[, -1]
colnames(TRAM_data)
group = TRAM_data
# Removed DIS9 and DIS11, DIS as a whole (depends if we want it in or not)
# Removed INS14 and INS16
# Removed PU3 and PU6
# Removed OPT2
# UPDATE: DIS and INN removed
## Construct the measurement model
mm = constructs(
composite("OPT", multi_items("OPT", c(1,3,4))),
composite("INN", multi_items("INN", 5:8)),
#composite("DIS", multi_items("DIS", c(10, 12))),
#composite("INS", multi_items("INS", c(13, 15))),
composite("PU", multi_items("PU", c(1,2,4,5))),
composite("PEOU", multi_items("PEOU", 7:12)),
composite("TA", multi_items("TA", 1:2)),
higher_composite("TR",  c("OPT", "INN"), method = two_stage)
)
# Create the structural model
sm = relationships(
paths(from = c("TR"), to = c("PU", "TA", "PEOU")),
paths(from = c("PEOU", "PU"), to = c("TA")),
paths(from = c("PEOU"), to = c("PU"))
)
# Estimating the model
model = estimate_pls(
data = group,
measurement_model = mm,
structural_model = sm
)
# Summarize the model
summary_sem = summary(model)
# Iterations to converge
summary_sem$iterations
# Check that the indicator loadings are all above 0.708
loadings = summary_sem$loadings
loadings
# Find row names where values in each column are less than 0.708
loadings_result <- apply(loadings, 2, function(column) {
indices <- which((abs(column) < 0.708) & (abs(column) > 0))
result <- paste(rownames(loadings)[indices], round(column[indices], 3), sep = ": ")
result
})
# Print the problematic loadings
print(loadings_result)
# For reliability, check which ones are above 0.5
reliability = summary_sem$loadings^2
reliability
# Find row names where values in each column are less than 0.708
reliability_result <- apply(reliability, 2, function(column) {
indices <- which((abs(column) < 0.5) & (abs(column) > 0))
result <- paste(rownames(reliability)[indices], round(column[indices], 3), sep = ": ")
result
})
# Print the problematic loadings
print(reliability_result)
## Assess the internal consistency reliability and convergent validity
plot(summary_sem$reliability)
# Check that the reliability measures are above 0.7 and that AVE is above 0.5
summary_sem$reliability
## Assess the discriminant validity
# Check that the diagonal values are larger than the values on the lower triangle for each construct.
summary_sem$validity$fl_criteria
# Check that the values are less that 0.9
summary_sem$validity$htmt
# Check that the values are significantly different from 1 using bootstrap results
set.seed(1)
boot_model = bootstrap_model(seminr_model = model,
nboot = 10000,
cores = parallel::detectCores())
sum_boot_mod = summary(boot_model, alpha = 0.1)
# Check that the upper boundaries are less than 0.9
sum_boot_mod$bootstrapped_HTMT
plot(boot_model)
sum_boot_ext = summary(boot_model, alpha = 0.05)
## 1. Assess collinearity issues with structural model
# Check that the VIF values < 3
summary_sem$vif_antecedents
## 2. Assess the significance and relevance of the structural model relationships
# Inspect the structural paths - CI must not include 0 and check bs mean
sum_boot_ext$bootstrapped_paths
# Inspect the total effects
sum_boot_ext$bootstrapped_total_paths
## 3. Assess the model's explanatory power
# Inspect the model RSquares (0.75, 0.50, and 0.25 are considered substantial, moderate, and weak. A dot is very weak)
summary_sem$paths
# Inspect the effect sizes (check rank order and effect sizes - read as row to col)
summary_sem$fSquare
# For a specific path
bootstrap_samples = boot_model$bootstraps
# For a specific path
bootstrap_samples = boot_model$boots
head(bootstrap_samples)
# For a specific path
bootstrap_samples = boot_model$path_coef
head(bootstrap_samples)
# For a specific path
bootstrap_samples = boot_model$boot_paths
head(bootstrap_samples)
# For a specific path
bootstrap_samples = boot_model$boot_paths
typeof(bootstrap_samples)
head(bootstrap_samples)
# Extract t-statistics from the summary table
t_stats <- sum_boot_ext$bootstrapped_paths[, "T Stat."]
# Compute p-values
p_values <- 2 * (1 - pnorm(abs(t_stats)))
# Combine t-stats and p-values for a concise table
result_table <- cbind(sum_boot_ext$bootstrapped_paths, P.Value = p_values)
# Print the result
print(result_table)
describe(TRAM_data)
library(Hmisc)
library(Hmisc)
describe(TRAM_data)
# Load the necessary library
library(e1071)
# Calculate kurtosis for each column in the dataframe
kurt_values <- sapply(TRAM_data, kurtosis)
# Print the kurtosis values
print(kurt_values)
## 2. Assess the significance and relevance of the structural model relationships
# Inspect the structural paths - CI must not include 0 and check bs mean
sum_boot_ext$bootstrapped_paths
# Assuming sum_boot_ext$bootstrapped_paths is a dataframe or matrix
write.csv(sum_boot_ext$bootstrapped_paths, "bootstrapped_paths.csv", row.names = TRUE)
# Extract t-statistics from the summary table
t_stats <- sum_boot_ext$bootstrapped_paths[, "T Stat."]
# Compute p-values
p_values <- 2 * (1 - pnorm(abs(t_stats)))
# Combine t-stats and p-values for a concise table
result_table <- cbind(sum_boot_ext$bootstrapped_paths, P.Value = p_values)
# Print the result
print(result_table)
# Write to a csv file
write.csv(result_table, "bootstrapped_paths_with_pvals.csv", row.names = TRUE)
# Inspect the total effects
sum_boot_ext$bootstrapped_total_paths
# Write to a csv file
write.csv(sum_boot_ext$bootstrapped_total_paths, "bootstrapped_total_paths.csv", row.names = TRUE)
## 3. Assess the model's explanatory power
# Inspect the model RSquares (0.75, 0.50, and 0.25 are considered substantial, moderate, and weak. A dot is very weak)
summary_sem$paths
# Write to a csv file
write.csv(summary_sem$paths, "exp_power.csv", row.names = TRUE)
# Inspect the effect sizes (check rank order and effect sizes - read as row to col)
summary_sem$fSquare
# Write to a csv file
write.csv(summary_sem$fSquare, "fSquare.csv", row.names = TRUE)
## 4. Assess the model's predictive power - check this later
# Generate model predictions
predict_sem = predict_pls(
model = model,
technique = predict_DA,
noFolds = 10,
reps = 10,
cores = parallel::detectCores()
)
predict_pls(model = model)
# Summarise the prediction results
sum_pred_sem = summary(predict_sem)
# Analyse the disribution of the prediction error - use RMSE if more symmetric
#par(mfrow = c(2,2))
#plot(sum_pred_sem, indicator = "TA1")
#plot(sum_pred_sem, indicator = "TA2")
#par(mfrow=c(1,1))
# Compute the prediction statistics
# Specifically, check that the PLS out-of-sample RMSE is lower than the naive LM for the primary
# outcome construct UTIL
sum_pred_sem
## 4. Assess the model's predictive power - check this later
# Generate model predictions
predict_sem = predict_pls(
model = model
)
predict_pls(model = model)
# Summarise the prediction results
sum_pred_sem = summary(predict_sem)
# Analyse the disribution of the prediction error - use RMSE if more symmetric
#par(mfrow = c(2,2))
#plot(sum_pred_sem, indicator = "TA1")
#plot(sum_pred_sem, indicator = "TA2")
#par(mfrow=c(1,1))
predict_pls(model = model)
?predict_pls
# Generate model predictions
predict_sem = predict_pls(
model = model,
technique = predict_EA,
noFolds = 10,
reps = 10,
cores = parallel::detectCores()
)
predict_sem
# Generate model predictions
predict_sem = predict_pls(
model = model,
technique = predict_DA,
noFolds = 10,
reps = 10,
cores = parallel::detectCores()
)
typeof(model)
# Estimating the model
model = estimate_pls(
data = group,
measurement_model = mm,
structural_model = sm
)
# Generate model predictions
predict_sem = predict_pls(
model = model,
technique = predict_DA,
noFolds = 10,
reps = 10,
cores = parallel::detectCores()
)
predict_sem
sum_boot_ext = summary(boot_model, alpha = 0.05)
## 1. Assess collinearity issues with structural model
# Check that the VIF values < 3
summary_sem$vif_antecedents
write.csv(summary_sem$vif_antecedents, "vif_antecedents.csv", row.names = TRUE)
# Check that the values are significantly different from 1 using bootstrap results
set.seed(1)
boot_model = bootstrap_model(seminr_model = model,
nboot = 10000,
cores = parallel::detectCores())
sum_boot_mod = summary(boot_model, alpha = 0.1)
# Check that the upper boundaries are less than 0.9
sum_boot_mod$bootstrapped_HTMT
# Write to csv
write.csv(sum_boot_mod$bootstrapped_HTMT, "bootstrapped_HTMT.csv", row.names = TRUE)
# Check that the reliability measures are above 0.7 and that AVE is above 0.5
summary_sem$reliability
# Write to csv
write.csv(summary_sem$reliability, "reliability.csv", row.names = TRUE)
