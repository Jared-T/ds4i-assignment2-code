{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "151d8238",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# imports\n",
    "import os\n",
    "import sys\n",
    "import types\n",
    "import json\n",
    "\n",
    "# figure size/format\n",
    "fig_width = 7\n",
    "fig_height = 5\n",
    "fig_format = 'retina'\n",
    "fig_dpi = 96\n",
    "\n",
    "# matplotlib defaults / format\n",
    "try:\n",
    "  import matplotlib.pyplot as plt\n",
    "  plt.rcParams['figure.figsize'] = (fig_width, fig_height)\n",
    "  plt.rcParams['figure.dpi'] = fig_dpi\n",
    "  plt.rcParams['savefig.dpi'] = fig_dpi\n",
    "  from IPython.display import set_matplotlib_formats\n",
    "  set_matplotlib_formats(fig_format)\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# plotly use connected mode\n",
    "try:\n",
    "  import plotly.io as pio\n",
    "  pio.renderers.default = \"notebook_connected\"\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# enable pandas latex repr when targeting pdfs\n",
    "try:\n",
    "  import pandas as pd\n",
    "  if fig_format == 'pdf':\n",
    "    pd.set_option('display.latex.repr', True)\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "\n",
    "\n",
    "# output kernel dependencies\n",
    "kernel_deps = dict()\n",
    "for module in list(sys.modules.values()):\n",
    "  # Some modules play games with sys.modules (e.g. email/__init__.py\n",
    "  # in the standard library), and occasionally this can cause strange\n",
    "  # failures in getattr.  Just ignore anything that's not an ordinary\n",
    "  # module.\n",
    "  if not isinstance(module, types.ModuleType):\n",
    "    continue\n",
    "  path = getattr(module, \"__file__\", None)\n",
    "  if not path:\n",
    "    continue\n",
    "  if path.endswith(\".pyc\") or path.endswith(\".pyo\"):\n",
    "    path = path[:-1]\n",
    "  if not os.path.exists(path):\n",
    "    continue\n",
    "  kernel_deps[path] = os.stat(path).st_mtime\n",
    "print(json.dumps(kernel_deps))\n",
    "\n",
    "# set run_path if requested\n",
    "if r'/Users/jared/Library/Group Containers/UBF8T346G9.OneDriveStandaloneSuite/OneDrive.noindex/OneDrive/Documents/University stuff/Masters Year/DS4I/Assignment2_code/project':\n",
    "  os.chdir(r'/Users/jared/Library/Group Containers/UBF8T346G9.OneDriveStandaloneSuite/OneDrive.noindex/OneDrive/Documents/University stuff/Masters Year/DS4I/Assignment2_code/project')\n",
    "\n",
    "# reset state\n",
    "%reset\n",
    "\n",
    "def ojs_define(**kwargs):\n",
    "  import json\n",
    "  try:\n",
    "    # IPython 7.14 preferred import\n",
    "    from IPython.display import display, HTML\n",
    "  except:\n",
    "    from IPython.core.display import display, HTML\n",
    "\n",
    "  # do some minor magic for convenience when handling pandas\n",
    "  # dataframes\n",
    "  def convert(v):\n",
    "    try:\n",
    "      import pandas as pd\n",
    "    except ModuleNotFoundError: # don't do the magic when pandas is not available\n",
    "      return v\n",
    "    if type(v) == pd.Series:\n",
    "      v = pd.DataFrame(v)\n",
    "    if type(v) == pd.DataFrame:\n",
    "      j = json.loads(v.T.to_json(orient='split'))\n",
    "      return dict((k,v) for (k,v) in zip(j[\"index\"], j[\"data\"]))\n",
    "    else:\n",
    "      return v\n",
    "  \n",
    "  v = dict(contents=list(dict(name=key, value=convert(value)) for (key, value) in kwargs.items()))\n",
    "  display(HTML('<script type=\"ojs-define\">' + json.dumps(v) + '</script>'), metadata=dict(ojs_define = True))\n",
    "globals()[\"ojs_define\"] = ojs_define\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ceb53fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: true\n",
    "\n",
    "# Run 1\n",
    "\n",
    "# Loading in the necessary libraries\n",
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from itertools import cycle\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet, stopwords, words\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from ast import literal_eval\n",
    "from collections import defaultdict\n",
    "import pyLDAvis.gensim_models\n",
    "import gensim\n",
    "from gensim.models import LsiModel, TfidfModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim import corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from plsa import Corpus, Pipeline, Visualize\n",
    "from plsa.pipeline import DEFAULT_PIPELINE\n",
    "from plsa.algorithms import PLSA\n",
    "from gensim.models import AuthorTopicModel\n",
    "from gensim.models import LdaModel\n",
    "import tqdm\n",
    "import tomotopy as tp\n",
    "\n",
    "# Global params\n",
    "plt.rcParams['xtick.labelsize'] = 18\n",
    "plt.rcParams['ytick.labelsize'] = 18\n",
    "\n",
    "# Set the global label sizes for the plots\n",
    "plt.rcParams['axes.labelsize'] = 20\n",
    "\n",
    "# Set the global legend size\n",
    "plt.rcParams['legend.fontsize'] = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4d2720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "# Unzip the file and get the list of filenames\n",
    "with zipfile.ZipFile(\"data/speeches.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"data\")\n",
    "\n",
    "filenames = os.listdir(\"data\")\n",
    "filenames = [filename for filename in filenames if filename.endswith('.txt')]\n",
    "\n",
    "# Read the content of each speech file and extract the date from the first line\n",
    "speeches = []\n",
    "dates = []\n",
    "for filename in filenames:\n",
    "    with open(os.path.join(\"data\", filename), 'r', encoding='utf-8') as file:\n",
    "        # Extract date from the first line\n",
    "        date = file.readline().strip()\n",
    "        dates.append(date)\n",
    "        \n",
    "        # Read the rest of the file\n",
    "        speeches.append(file.read())\n",
    "\n",
    "# Create DataFrame\n",
    "sona = pd.DataFrame({'filename': filenames, 'speech': speeches, 'date': dates})\n",
    "\n",
    "# Extract year and president for each speech\n",
    "sona['year'] = sona['filename'].str[:4]\n",
    "sona['president'] = sona['filename'].str.split('_').str[-1].str.split('.').str[0]\n",
    "\n",
    "# Clean the sona dataset by removing unnecessary text\n",
    "replace_reg = r'(http.*?(\\s|.$))|(www.*?(\\s|.$))|&amp;|&lt;|&gt;|\\n'\n",
    "sona['speech'] = sona['speech'].str.replace(replace_reg, ' ')\n",
    "\n",
    "# Split speeches into sentences\n",
    "sona_sentences = sona.copy()\n",
    "\n",
    "import itertools\n",
    "\n",
    "# Replace new lines with space and split into sentences based on regular expression\n",
    "sona_sentences['speech'] = sona_sentences['speech'].str.replace('\\n', ' ').str.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s')\n",
    "\n",
    "# Flatten the list of sentence fragments to avoid nested lists\n",
    "sona_sentences['speech'] = sona_sentences['speech'].apply(lambda sentences: list(itertools.chain.from_iterable(sentence.split('.') for sentence in sentences)))\n",
    "\n",
    "# Remove empty strings from the list of sentences\n",
    "sona_sentences['speech'] = sona_sentences['speech'].apply(lambda sentences: [sentence.strip() for sentence in sentences if sentence.strip()])\n",
    "\n",
    "# Make a csv of the speeches\n",
    "sona.to_csv('data/sona_speeches.csv', index=False)\n",
    "\n",
    "# Make a csv of the sentences\n",
    "sona_sentences.to_csv('data/sona_sentences_untransformed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a52c1718",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "# Make sure to download the necessary NLTK corpus if you haven't already\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('words')\n",
    "\n",
    "# Read in the sona speeches dataset\n",
    "sona_speeches_df = pd.read_csv('data/sona_speeches.csv')\n",
    "sona_sentences_clean = pd.read_csv('data/sona_sentences_untransformed.csv')\n",
    "sona_sentences_clean['speech'] = sona_sentences_clean['speech'].apply(literal_eval)\n",
    "\n",
    "# Initialize the WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "english_words = set(words.words())\n",
    "additional_words = {\n",
    "    'honourable', 'member', 'chairperson',\n",
    "    'south', 'africa', 'african', 'africans', 'year',\n",
    "    'madame', 'madam', 'soes', 'ms', 'madams', 'madames', 'mw',\n",
    "    'compatriotsthe',\n",
    "    'also'\n",
    "}\n",
    "\n",
    "# Function to convert NLTK's part-of-speech tags to WordNet's part-of-speech tags\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map NLTK part of speech tags to WordNet part of speech tags.\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": nltk.corpus.wordnet.ADJ,\n",
    "                \"N\": nltk.corpus.wordnet.NOUN,\n",
    "                \"V\": nltk.corpus.wordnet.VERB,\n",
    "                \"R\": nltk.corpus.wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, nltk.corpus.wordnet.NOUN)\n",
    "\n",
    "# Clean the text, convert to lowercase, and lemmatize each word\n",
    "def clean_text(text):\n",
    "    # Remove special characters: keep only letters, numbers, and basic punctuation\n",
    "    text = re.sub(r'[.;]', ' ', text)  # Replaces periods with spaces\n",
    "    text = re.sub(r'[^a-zA-Z ]', '', text)\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    \n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Remove additional words\n",
    "    words = [word for word in words if word not in additional_words]\n",
    "\n",
    "    # Lemmatize each word with the correct POS tag\n",
    "    lemmatized_words = []\n",
    "    for word, tag in nltk.pos_tag(words):\n",
    "        wntag = get_wordnet_pos(tag)\n",
    "        lemmatized_word = lemmatizer.lemmatize(word, wntag)\n",
    "        # Only append the lemmatized word if it is in the set of English words\n",
    "        if lemmatized_word in english_words:\n",
    "            lemmatized_words.append(lemmatized_word)\n",
    "    \n",
    "    # Join the lemmatized words back into one string\n",
    "    text = ' '.join(words)\n",
    "    return text\n",
    "\n",
    "def clean_text_no_word_removals(text):\n",
    "    # Remove special characters: keep only letters, numbers, and basic punctuation\n",
    "    text = re.sub(r'[.;]', ' ', text)  # Replaces periods with spaces\n",
    "    text = re.sub(r'[^a-zA-Z ]', '', text)\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the speech column\n",
    "tempdf = sona_speeches_df.copy()\n",
    "sona_speeches_df['speech'] = tempdf['speech'].apply(clean_text)\n",
    "sona_speeches_df['speech_untrans'] = tempdf['speech'].apply(clean_text_no_word_removals)\n",
    "\n",
    "def clean_speeches(speeches):\n",
    "    # The input is expected to be a list of strings\n",
    "    return [clean_text(sentence) for sentence in speeches]\n",
    "\n",
    "# Apply the cleaning to the sentences too\n",
    "sona_sentences_clean['sentence'] = sona_sentences_clean['speech'].apply(lambda speeches: [clean_text(sentence) for sentence in speeches])\n",
    "\n",
    "# Apply the cleaning to sentences that need to keep their words\n",
    "sona_sentences_clean['sent_untrans'] = sona_sentences_clean['speech'].apply(lambda speeches: [clean_text_no_word_removals(sentence) for sentence in speeches])\n",
    "\n",
    "# Make a csv of the speeches\n",
    "sona_speeches_df.to_csv('data/sona_speeches_adapted.csv', index=False)\n",
    "\n",
    "# Remove the speech column from the sentences DataFrame\n",
    "sona_sentences_clean.drop(columns=['speech'], inplace=True)\n",
    "\n",
    "# Make a csv of the sentences\n",
    "sona_sentences_clean.to_csv('data/sona_sentences_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68348b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: true\n",
    "\n",
    "# Run 2\n",
    "\n",
    "sona_sentences_clean = pd.read_csv('data/sona_sentences_clean.csv')\n",
    "sona_sentences_clean['sentence'] = sona_sentences_clean['sentence'].apply(literal_eval)\n",
    "sona_sentences_clean['sent_untrans'] = sona_sentences_clean['sent_untrans'].apply(literal_eval)\n",
    "\n",
    "# Make the sentences into a single column\n",
    "sona_sentences_alltogether = sona_sentences_clean.explode('sentence')\n",
    "sona_sentences_all_untrans = sona_sentences_clean.explode('sent_untrans')\n",
    "\n",
    "# Drop the other columns\n",
    "sona_sentences_alltogether.drop(columns=['sent_untrans'], inplace=True)\n",
    "sona_sentences_all_untrans.drop(columns=['sentence'], inplace=True)\n",
    "\n",
    "# Make a csv of the sentences\n",
    "sona_sentences_all_untrans.to_csv('data/sona_sentiment_sentences.csv', index=False)\n",
    "\n",
    "# Speeches\n",
    "sona_speeches_clean = pd.read_csv('data/sona_speeches_adapted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed7ef5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "max_features = 2000\n",
    "\n",
    "bow_vectorizer = CountVectorizer(max_features=max_features)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "\n",
    "# Transformed on the words\n",
    "bow_matrix_words = bow_vectorizer.fit_transform(sona_speeches_clean['speech'])\n",
    "tfidf_matrix_words = tfidf_vectorizer.fit_transform(sona_speeches_clean['speech'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3110dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "cmap = plt.cm.cividis\n",
    "\n",
    "norm = plt.Normalize(0, 100)\n",
    "\n",
    "# Define a colour map based on cividis\n",
    "# Define a new colormap using a smaller slice of the cividis colormap, this time stopping well before the yellows\n",
    "cividis_modified = cmap(np.linspace(0, 0.4, cmap.N))  # Using only 40% of the colormap range\n",
    "\n",
    "# Create a new colormap from the data\n",
    "cividis_no_yellow_light = LinearSegmentedColormap.from_list('cividis_no_yellow_light', cividis_modified)\n",
    "\n",
    "# Let's pick three colors from the modified colormap\n",
    "colormap = [cividis_no_yellow_light(norm(0)), \n",
    "          cividis_no_yellow_light(norm(50)), \n",
    "          cividis_no_yellow_light(norm(100))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f55f9323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to count words in speeches excluding stopwords\n",
    "def get_word_frequencies(speeches, stopwords):\n",
    "    word_counts = Counter()\n",
    "    for speech in speeches:\n",
    "        words = speech.lower().split()\n",
    "        # Remove stopwords from the count\n",
    "        words = [word.strip('.,!?\"\\'-()') for word in words if word.strip('.,!?\"\\'-()') not in stopwords]\n",
    "        word_counts.update(words)\n",
    "    return word_counts\n",
    "\n",
    "# Get the word frequencies excluding stopwords\n",
    "word_frequencies = get_word_frequencies(sona_speeches_clean['speech'], ENGLISH_STOP_WORDS)\n",
    "\n",
    "# Get the top 10 most frequent words across all speeches\n",
    "top_10_words = word_frequencies.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f5093eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar([word for word, count in top_10_words], [count for word, count in top_10_words], color=colormap[2])\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks()\n",
    "plt.yticks()\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig(f'saved_plots/overall_top_words.png', bbox_inches='tight')\n",
    "plt.close()  # Close the figure to avoid displaying it in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce1a6bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get top N frequent words for each president\n",
    "def get_top_words_by_president(speeches_df, n, stopwords):\n",
    "    presidents = speeches_df['president'].unique()\n",
    "    top_words_by_president = {}\n",
    "    for president in presidents:\n",
    "        president_speeches = speeches_df[speeches_df['president'] == president]['speech']\n",
    "        word_frequencies = get_word_frequencies(president_speeches, stopwords)\n",
    "        top_words_by_president[president] = word_frequencies.most_common(n)\n",
    "    return top_words_by_president\n",
    "\n",
    "# Get the top 10 most frequent words for each president\n",
    "top_10_words_by_president = get_top_words_by_president(sona_speeches_clean, 10, ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "140c142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the word frequencies for each president\n",
    "for president, top_words in top_10_words_by_president.items():\n",
    "    \n",
    "    # Individual plot for each president\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar([word for word, count in top_words], [count for word, count in top_words], color=colormap[0])\n",
    "    plt.xlabel('Words')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Save the plot as a PNG file\n",
    "    plt.savefig(f'saved_plots/{president}_top_words.png', bbox_inches='tight')\n",
    "    plt.close()  # Close the figure to avoid displaying it in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c2b051e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.tokenize import treebank\n",
    "from afinn import Afinn\n",
    "\n",
    "from dateutil import parser\n",
    "\n",
    "# Function to parse date strings based on the described rule\n",
    "def parse_date(date_str):\n",
    "    # Split the string by comma and take the last part\n",
    "    date_part = date_str.split(',')[-1].strip()\n",
    "    # Parse the date part into a datetime object\n",
    "    return parser.parse(date_part)\n",
    "\n",
    "# Define a function to get Bing lexicon sentiment scores\n",
    "def get_bing_sentiment(text):\n",
    "    tokenizer = treebank.TreebankWordTokenizer()\n",
    "    tokens = tokenizer.tokenize(text.lower())\n",
    "    pos_score = sum(1 for word in tokens if word in positive_words)\n",
    "    neg_score = sum(1 for word in tokens if word in negative_words)\n",
    "    compound_score = pos_score - neg_score\n",
    "    return compound_score\n",
    "\n",
    "\n",
    "# Load the AFINN lexicon\n",
    "afinn = Afinn()\n",
    "\n",
    "# Define a function to get AFINN sentiment scores\n",
    "def get_afinn_sentiment(text):\n",
    "    return afinn.score(text)\n",
    "\n",
    "# Load positive and negative words\n",
    "positive_words = set(opinion_lexicon.positive())\n",
    "negative_words = set(opinion_lexicon.negative())\n",
    "\n",
    "# Apply Bing sentiment analysis\n",
    "sona_speeches_clean['bing_sentiment'] = sona_speeches_clean['speech_untrans'].apply(get_bing_sentiment)\n",
    "sona_sentences_all_untrans['bing_sentiment'] = sona_sentences_all_untrans['sent_untrans'].apply(get_bing_sentiment)\n",
    "\n",
    "# Apply AFINN sentiment analysis\n",
    "sona_speeches_clean['afinn_sentiment'] = sona_speeches_clean['speech_untrans'].apply(lambda text: get_afinn_sentiment(text))\n",
    "sona_sentences_all_untrans['afinn_sentiment'] = sona_sentences_all_untrans['sent_untrans'].apply(lambda text: get_afinn_sentiment(text))\n",
    "\n",
    "# Convert the date strings to datetime objects\n",
    "sona_speeches_clean['date'] = sona_speeches_clean['date'].apply(parse_date)\n",
    "sona_sentences_all_untrans['date'] = sona_sentences_all_untrans['date'].apply(parse_date)\n",
    "\n",
    "# Sort the DataFrames by date in ascending order\n",
    "sona_speeches_clean.sort_values('date', ascending=True, inplace=True)\n",
    "#sona_sentences_all_untrans.sort_values('date', ascending=True, inplace=True)\n",
    "\n",
    "# Create a new variable which is the date as a string\n",
    "sona_speeches_clean['date_str'] = sona_speeches_clean['date'].dt.strftime('%Y-%m-%d')\n",
    "sona_sentences_all_untrans['date_str'] = sona_sentences_all_untrans['date'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0755c1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# For plotting sentiment scores of speeches by each president\n",
    "def plot_speeches_by_president(df, lexicon):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    presidents = df['president'].unique()\n",
    "\n",
    "    lexicon_lab = lexicon\n",
    "\n",
    "    if lexicon == 'afinn':\n",
    "        lexicon_lab = 'AFINN'\n",
    "\n",
    "    colors = ['lightsteelblue', colormap[1], 'midnightblue', 'lightgray', 'darkgray',  'dimgray']\n",
    "\n",
    "    for idx, president in enumerate(presidents):\n",
    "        president_df = df[df['president'] == president]\n",
    "        plt.bar(president_df['date_str'], president_df[f'{lexicon}_sentiment'], label=president, color=colors[idx])\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel(f'Sentiment Score')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks()\n",
    "    plt.legend(loc =\"upper left\", fontsize=14)\n",
    "    plt.savefig(f'sentiment_plots/speech_{lexicon}_all.png', bbox_inches='tight')\n",
    "    plt.close()  # Close the figure to avoid displaying it in the notebook\n",
    "\n",
    "\n",
    "# For plotting sentiment scores of sentences by each president\n",
    "def plot_sentences_by_president(df, lexicon):\n",
    "    #plt.figure(figsize=(10, 6))\n",
    "\n",
    "    presidents = df['president'].unique()\n",
    "\n",
    "    colors = [colormap[1],  'dimgray', 'midnightblue', 'darkgray', 'lightsteelblue', 'lightgray']\n",
    "\n",
    "    lexicon_lab = lexicon\n",
    "\n",
    "    if lexicon == 'afinn':\n",
    "        lexicon_lab = 'AFINN'\n",
    "    \n",
    "    # Create a copy of the DataFrame\n",
    "    df = df.copy()\n",
    "\n",
    "    # Add a column for the sentence number\n",
    "    df['sentence_num'] = df.groupby('date_str').cumcount() + 1\n",
    "    \n",
    "    i = 0\n",
    "\n",
    "    for idx, president in enumerate(presidents):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        president_df = df[df['president'] == president]\n",
    "        plt.bar(president_df['sentence_num'], president_df[f'{lexicon}_sentiment'], label=president, color=colors[i])\n",
    "        plt.xlabel('Sentence')\n",
    "        plt.ylabel(f'Sentiment Score')\n",
    "        plt.xticks()\n",
    "        plt.savefig(f'sentiment_plots/sent_{lexicon}_{president}.png', bbox_inches='tight')\n",
    "        plt.close()  # Close the figure to avoid displaying it in the notebook\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    \n",
    "# Assuming 'date' is a column in datetime format and 'president' is the name of each president\n",
    "plot_speeches_by_president(sona_speeches_clean, 'bing')\n",
    "plot_speeches_by_president(sona_speeches_clean, 'afinn')\n",
    "\n",
    "plot_sentences_by_president(sona_sentences_all_untrans, 'bing')\n",
    "plot_sentences_by_president(sona_sentences_all_untrans, 'afinn')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27d71239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate word sentiments across all speeches of a president\n",
    "def calculate_word_sentiments(president_speeches, lexicon):\n",
    "    # Combine all speeches into one large text\n",
    "    all_speeches = ' '.join(president_speeches)\n",
    "    # Tokenize the text into words and filter out stopwords and non-alphabetic tokens\n",
    "    words = [word for word in word_tokenize(all_speeches.lower()) if word.isalpha() and word not in stopwords.words('english')]\n",
    "    # Get sentiment score for each word\n",
    "    word_sentiments = defaultdict(int)\n",
    "    for word in words:\n",
    "        # Get the sentiment score for the word\n",
    "        if lexicon == 'bing':\n",
    "            sentiment = get_bing_sentiment(word)\n",
    "        elif lexicon == 'afinn':\n",
    "            sentiment = get_afinn_sentiment(word)\n",
    "\n",
    "        word_sentiments[word] += sentiment\n",
    "    return word_sentiments\n",
    "\n",
    "# Function to plot the top positive and negative words\n",
    "def plot_top_words(word_sentiments, president, lexicon):\n",
    "    # Sort words by sentiment score\n",
    "    sorted_words = sorted(word_sentiments.items(), key=lambda kv: kv[1])\n",
    "    # Select the top 10 positive and negative words\n",
    "    top_positive_words = sorted_words[-10:]\n",
    "    top_negative_words = sorted_words[:10]\n",
    "\n",
    "    # Words and their sentiment scores for plotting\n",
    "    words_positive, scores_positive = zip(*top_positive_words)\n",
    "    words_negative, scores_negative = zip(*top_negative_words)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot the top negative words\n",
    "    ax.barh(range(10), scores_negative, color=colormap[2], label='Negative')\n",
    "    # Plot the top positive words\n",
    "    ax.barh(range(10, 20), scores_positive, color=colormap[0], label='Positive')\n",
    "\n",
    "    # Add the word labels\n",
    "    ax.set_yticks(range(20))\n",
    "    ax.set_yticklabels(words_negative + words_positive)\n",
    "    \n",
    "    # Set the labels and title\n",
    "    ax.set_xlabel(f'Contribution to Sentiment Score')\n",
    "    ax.legend(loc = \"lower right\")\n",
    "\n",
    "    # Adjust the view so negative words are at the bottom and positive at the top\n",
    "    ax.set_ylim(-1, 20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    # Save the plot as a PNG file\n",
    "    plt.savefig(f'sentiment_plots/word_contr_{lexicon}_{president}.png', bbox_inches='tight')\n",
    "    plt.close()  # Close the figure to avoid displaying it in the notebook\n",
    "\n",
    "# Aggregate the speeches by president and calculate the top words\n",
    "presidents_speeches = sona_speeches_clean.groupby('president')['speech_untrans'].apply(list)\n",
    "for president, speeches in presidents_speeches.items():\n",
    "    word_sentiments_bing = calculate_word_sentiments(speeches, 'bing')\n",
    "    word_sentiments_afinn = calculate_word_sentiments(speeches, 'afinn')\n",
    "    plot_top_words(word_sentiments_bing, president, 'bing')\n",
    "    plot_top_words(word_sentiments_bing, president, 'AFINN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5a7b4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate word sentiments across all speeches\n",
    "def calculate_word_sentiments(speeches, lexicon):\n",
    "    # Combine all speeches into one large text\n",
    "    all_speeches = ' '.join(speeches)\n",
    "    # Tokenize the text into words and filter out stopwords and non-alphabetic tokens\n",
    "    words = [word for word in word_tokenize(all_speeches.lower()) if word.isalpha() and word not in stopwords.words('english')]\n",
    "    # Get sentiment score for each word\n",
    "    word_sentiments = defaultdict(int)\n",
    "    for word in words:\n",
    "        # Get the sentiment score for the word\n",
    "        if lexicon == 'bing':\n",
    "            sentiment = get_bing_sentiment(word)\n",
    "        elif lexicon == 'afinn':\n",
    "            sentiment = get_afinn_sentiment(word)\n",
    "\n",
    "        word_sentiments[word] += sentiment\n",
    "    return word_sentiments\n",
    "\n",
    "# Function to plot the top positive and negative words\n",
    "def plot_top_words(word_sentiments, lexicon):\n",
    "    # Sort words by sentiment score\n",
    "    sorted_words = sorted(word_sentiments.items(), key=lambda kv: kv[1])\n",
    "    # Select the top 10 positive and negative words\n",
    "    top_positive_words = sorted_words[-10:]\n",
    "    top_negative_words = sorted_words[:10]\n",
    "\n",
    "    # Words and their sentiment scores for plotting\n",
    "    words_positive, scores_positive = zip(*top_positive_words)\n",
    "    words_negative, scores_negative = zip(*top_negative_words)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot the top negative words\n",
    "    ax.barh(range(10), scores_negative, color=colormap[2], label='Negative')\n",
    "    # Plot the top positive words\n",
    "    ax.barh(range(10, 20), scores_positive, color=colormap[0], label='Positive')\n",
    "\n",
    "    # Add the word labels\n",
    "    ax.set_yticks(range(20))\n",
    "    ax.set_yticklabels(words_negative + words_positive)\n",
    "    # ax.yticks(fontsize=16)\n",
    "\n",
    "    # Set the labels and title\n",
    "    ax.set_xlabel(f'Contribution to Sentiment Score')\n",
    "    ax.legend()\n",
    "    # ax.xticks(fontsize=16)\n",
    "\n",
    "    # Adjust the view so negative words are at the bottom and positive at the top\n",
    "    ax.set_ylim(-1, 20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'sentiment_plots/word_contr_{lexicon}_all.png', bbox_inches='tight')\n",
    "    plt.close()  # Close the figure to avoid displaying it in the notebook\n",
    "\n",
    "# Calculate the word sentiments across all speeches for each lexicon\n",
    "all_speeches = sona_speeches_clean['speech_untrans'].tolist()\n",
    "word_sentiments_bing = calculate_word_sentiments(all_speeches, 'bing')\n",
    "word_sentiments_afinn = calculate_word_sentiments(all_speeches, 'afinn')\n",
    "\n",
    "# Plot the top words for each lexicon\n",
    "plot_top_words(word_sentiments_bing, 'bing')\n",
    "plot_top_words(word_sentiments_afinn, 'AFINN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b37d2c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "# Run 2.5\n",
    "\n",
    "texts = sona_speeches_clean['speech']\n",
    "sentences = sona_sentences_alltogether['sentence']\n",
    "\n",
    "# Further process tokens using gensim's simple_preprocess\n",
    "tokenized_texts = [simple_preprocess(doc, deacc=True) for doc in texts]  # deacc=True removes punctuations\n",
    "tokenized_sentences = [simple_preprocess(doc, deacc=True) for doc in sentences]  # deacc=True removes punctuations\n",
    "\n",
    "# Create a Gensim dictionary from the tokenized documents\n",
    "dictionary = corpora.Dictionary(tokenized_texts)\n",
    "dict_sentences = corpora.Dictionary(tokenized_sentences)\n",
    "\n",
    "#dictionary.filter_extremes(no_below=2, no_above=0.7)\n",
    "#dict_sentences.filter_extremes(no_below=2, no_above=0.7)\n",
    "\n",
    "# Create a BOW corpus\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in tokenized_texts]\n",
    "bow_corpus_sentences = [dict_sentences.doc2bow(text) for text in tokenized_sentences]\n",
    "\n",
    "# Create a TF-IDF corpus\n",
    "tfidf = TfidfModel(bow_corpus)\n",
    "tfidf_corpus = tfidf[bow_corpus]\n",
    "\n",
    "tfidf_sentences = TfidfModel(bow_corpus_sentences)\n",
    "tfidf_corpus_sentences = tfidf_sentences[bow_corpus_sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "945db282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to compute coherence values\n",
    "def compute_coherence_values(dictionary, corpus, texts, start, limit, step, coherence='u_mass'):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = LsiModel(corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=tokenized_texts, dictionary=dictionary, coherence=coherence)\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "    return model_list, coherence_values\n",
    "\n",
    "# Set parameters\n",
    "start, limit, step = 2, 20, 1\n",
    "\n",
    "# Compute coherence values for BOW\n",
    "bow_model_list, bow_coherence_values = compute_coherence_values(dictionary=dictionary, corpus=bow_corpus, texts=texts, start=start, limit=limit, step=step)\n",
    "\n",
    "bow_model_list_sentences, bow_coherence_values_sentences = compute_coherence_values(dictionary=dict_sentences, corpus=bow_corpus_sentences, texts=sentences, start=start, limit=limit, step=step)\n",
    "\n",
    "# Compute coherence values for TF-IDF\n",
    "tfidf_model_list, tfidf_coherence_values = compute_coherence_values(dictionary=dictionary, corpus=tfidf_corpus, texts=tokenized_texts, start=start, limit=limit, step=step)\n",
    "\n",
    "tfidf_model_list_sentences, tfidf_coherence_values_sentences = compute_coherence_values(dictionary=dict_sentences, corpus=tfidf_corpus_sentences, texts=sentences, start=start, limit=limit, step=step)\n",
    "\n",
    "# Save the to csv\n",
    "coherence_df = pd.DataFrame({'bow_coherence_values': bow_coherence_values, 'tfidf_coherence_values': tfidf_coherence_values, 'bow_coherence_values_sentences': bow_coherence_values_sentences, 'tfidf_coherence_values_sentences': tfidf_coherence_values_sentences})\n",
    "\n",
    "coherence_df.to_csv('lsa_plots/coherence_values.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4962f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "# Read in the coherence values\n",
    "coherence_df = pd.read_csv('lsa_plots/coherence_values.csv')\n",
    "\n",
    "# Extract the coherence values\n",
    "bow_coherence_values = coherence_df['bow_coherence_values']\n",
    "tfidf_coherence_values = coherence_df['tfidf_coherence_values']\n",
    "bow_coherence_values_sentences = coherence_df['bow_coherence_values_sentences']\n",
    "tfidf_coherence_values_sentences = coherence_df['tfidf_coherence_values_sentences']\n",
    "\n",
    "# Plotting the coherence values\n",
    "x = range(start, limit, step)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, bow_coherence_values, label='BoW', color='midnightblue')\n",
    "plt.plot(x, tfidf_coherence_values, label='tf-idf', color='darkgray')\n",
    "plt.xlabel(\"Number of Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend(loc='lower left')\n",
    "plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.savefig(f'lsa_plots/words_coherence_plots.png', bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Plotting the coherence values\n",
    "x = range(start, limit, step)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, bow_coherence_values_sentences, label='BoW', color='midnightblue')\n",
    "plt.plot(x, tfidf_coherence_values_sentences, label='tf-idf', color='darkgray')\n",
    "plt.xlabel(\"Number of Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.savefig(f'lsa_plots/sentence_coherence_plots.png', bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2fd1822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 3\n",
    "\n",
    "# TODO: Set the number of topics based on the plots\n",
    "lsa_bow_words = LsiModel(corpus=bow_corpus, num_topics=3, id2word=dictionary)\n",
    "lsa_bow_sentences = LsiModel(corpus=bow_corpus_sentences, num_topics=2, id2word=dict_sentences)\n",
    "\n",
    "lsa_tfidf_words = LsiModel(corpus=tfidf_corpus, num_topics=3, id2word=dictionary)\n",
    "lsa_tfidf_sentences = LsiModel(corpus=tfidf_corpus_sentences, num_topics=2, id2word=dict_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9155ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 4\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to plot the top words for each topic in a single LSA model\n",
    "def plot_top_words_for_each_topic(model, fiton, lexicon, num_words=10):\n",
    "\n",
    "    colors = ['lightsteelblue', 'midnightblue', 'lightgray', 'darkgray', 'dimgray']\n",
    "    \n",
    "    j = 0\n",
    "\n",
    "    for i in range(model.num_topics):\n",
    "        # Extract the top words for this topic\n",
    "        top_words = model.show_topic(i, num_words)\n",
    "        # Separate the words and their corresponding weights\n",
    "        words, weights = zip(*top_words)\n",
    "        weights = [abs(weight) for weight in weights]  # Use absolute values for weights\n",
    "\n",
    "        # Create a bar chart for the top words in this topic\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.barh(words, weights, color = colors[j])\n",
    "        # ax.set_yticklabels(words, fontsize=20)\n",
    "        j += 1\n",
    "\n",
    "        if j == 4:\n",
    "            j = 0\n",
    "\n",
    "        plt.xlabel('Weight')\n",
    "        plt.gca().invert_yaxis()  # Highest weights on top\n",
    "        plt.savefig(f'lsa_plots/{fiton}_{lexicon}_topic_{i + 1}.png', bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "# Apply the plotting function to each of your LSA models\n",
    "plot_top_words_for_each_topic(lsa_bow_words, 'words', 'bow')\n",
    "plot_top_words_for_each_topic(lsa_bow_sentences, 'sentences', 'bow')\n",
    "plot_top_words_for_each_topic(lsa_tfidf_words, 'words', 'tfidf')\n",
    "plot_top_words_for_each_topic(lsa_tfidf_sentences, 'sentences', 'tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b581556",
   "metadata": {},
   "outputs": [],
   "source": [
    "sona_speeches_clean['speech'].to_csv('data/sona_speeches_only.csv', index=False)\n",
    "sona_sentences_alltogether['sentence'].to_csv('data/sona_sentences_only.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd80a9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calculate_umass_coherence(plsa_result, corpus, top_n=10, tf_idf=False):\n",
    "    # Extract the top N words for each topic\n",
    "    top_words_by_topic = [\n",
    "        [word for word, _ in plsa_result.word_given_topic[i][:top_n]]\n",
    "        for i in range(plsa_result.n_topics)\n",
    "    ]\n",
    "    \n",
    "    # Get document-word matrix (document frequency matrix)\n",
    "    doc_word_matrix = corpus.get_doc_word(tf_idf=tf_idf)\n",
    "    \n",
    "    # Calculate document frequencies for single words\n",
    "    word_doc_freq = np.sum(doc_word_matrix > 0, axis=0)\n",
    "    \n",
    "    # Calculate coherence for each topic\n",
    "    topic_coherences = []\n",
    "    for top_words in top_words_by_topic:\n",
    "        pair_scores = []\n",
    "        for i, word in enumerate(top_words):\n",
    "            for j in range(i + 1, len(top_words)):\n",
    "                # Get indices in the vocabulary\n",
    "                word_i_index = corpus.index[word]\n",
    "                word_j_index = corpus.index[top_words[j]]\n",
    "                \n",
    "                # Count the documents where both words appear\n",
    "                both_docs = np.sum((doc_word_matrix[:, word_i_index] > 0) & (doc_word_matrix[:, word_j_index] > 0))\n",
    "                \n",
    "                # Calculate score for this word pair\n",
    "                score = math.log((both_docs + 1.0) / word_doc_freq[word_i_index])  # Add 1 to avoid log(0)\n",
    "                pair_scores.append(score)\n",
    "                \n",
    "        # Average over all pairs to get the topic coherence\n",
    "        topic_coherence = sum(pair_scores) / len(pair_scores)\n",
    "        topic_coherences.append(topic_coherence)\n",
    "        \n",
    "    # Average over all topics to get the overall coherence\n",
    "    overall_coherence = sum(topic_coherences) / len(topic_coherences)\n",
    "    return overall_coherence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf49c675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 4.5\n",
    "\n",
    "pipeline = Pipeline(*DEFAULT_PIPELINE)\n",
    "\n",
    "corpus = Corpus.from_csv(\"data/sona_speeches_only.csv\", pipeline)\n",
    "corpus_sent = Corpus.from_csv(\"data/sona_sentences_only.csv\", pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66ce6cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_numbers = range(2, 12, 1)\n",
    "\n",
    "# Loop over the topic number and calculate the coherence values\n",
    "bow_coherence_values = []\n",
    "bow_coherence_values_sent = []\n",
    "tfidf_coherence_values = []\n",
    "tfidf_coherence_values_sent = []\n",
    "\n",
    "for n_topics in topic_numbers:\n",
    "    # Initialize the models\n",
    "    tfidf_plsa = PLSA(corpus, n_topics, tf_idf=True)\n",
    "    bow_plsa = PLSA(corpus, n_topics, tf_idf=False)\n",
    "\n",
    "    tfidf_plsa_sent = PLSA(corpus_sent, n_topics, tf_idf=True)\n",
    "    bow_plsa_sent = PLSA(corpus_sent, n_topics, tf_idf=False)\n",
    "\n",
    "    # Fit the models\n",
    "    tfidf_result = tfidf_plsa.fit()\n",
    "    bow_result = bow_plsa.fit()\n",
    "    tfidf_result_sent = tfidf_plsa_sent.fit()\n",
    "    bow_result_sent = bow_plsa_sent.fit()\n",
    "\n",
    "    # Calculate the coherence values\n",
    "    bow_coherence_values.append(calculate_umass_coherence(bow_result, corpus, tf_idf=False))\n",
    "    tfidf_coherence_values.append(calculate_umass_coherence(tfidf_result, corpus, tf_idf=True))\n",
    "    bow_coherence_values_sent.append(calculate_umass_coherence(bow_result_sent, corpus_sent, tf_idf=False))\n",
    "    tfidf_coherence_values_sent.append(calculate_umass_coherence(tfidf_result_sent, corpus_sent, tf_idf=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5132338c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the coherence value results\n",
    "pd.DataFrame({\n",
    "    'topic_number': topic_numbers,\n",
    "    'bow_coherence': bow_coherence_values,\n",
    "    'tfidf_coherence': tfidf_coherence_values,\n",
    "    'bow_coherence_sent': bow_coherence_values_sent,\n",
    "    'tfidf_coherence_sent': tfidf_coherence_values_sent\n",
    "}).to_csv('data/saved_plsa_coherence_values.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b793acd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: true\n",
    "\n",
    "# Load the coherence value results\n",
    "coherence_values = pd.read_csv('data/saved_plsa_coherence_values.csv')\n",
    "\n",
    "topic_numbers = coherence_values['topic_number']\n",
    "bow_coherence_values = coherence_values['bow_coherence']\n",
    "tfidf_coherence_values = coherence_values['tfidf_coherence']\n",
    "bow_coherence_values_sent = coherence_values['bow_coherence_sent']\n",
    "tfidf_coherence_values_sent = coherence_values['tfidf_coherence_sent']\n",
    "\n",
    "# Plot the speech coherence values - updated\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(topic_numbers, bow_coherence_values, label='BoW', color='midnightblue')\n",
    "plt.plot(topic_numbers, tfidf_coherence_values, label='tf-idf', color='darkgray')\n",
    "plt.xlabel(\"Number of Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(f'plsa_plots/words_coherence.png', bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Plot the sentence coherence values - updated\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(topic_numbers, bow_coherence_values_sent, label='BoW', color='midnightblue')\n",
    "plt.plot(topic_numbers, tfidf_coherence_values_sent, label='tf-idf', color='darkgray')\n",
    "plt.xlabel(\"Number of Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(f'plsa_plots/sentences_coherence.png', bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89ba4d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 5\n",
    "\n",
    "# TODO: Change to the official number of topics\n",
    "\n",
    "# Fit the models with the calibrated number of topics\n",
    "tfidf_plsa = PLSA(corpus, 5, tf_idf=True)\n",
    "bow_plsa = PLSA(corpus, 5, tf_idf=False)\n",
    "tfidf_plsa_sent = PLSA(corpus_sent, 4, tf_idf=True)\n",
    "bow_plsa_sent = PLSA(corpus_sent, 4, tf_idf=False)\n",
    "\n",
    "# Fit the models\n",
    "tfidf_result = tfidf_plsa.fit()\n",
    "bow_result = bow_plsa.fit()\n",
    "tfidf_result_sent = tfidf_plsa_sent.fit()\n",
    "bow_result_sent = bow_plsa_sent.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0a328de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 6\n",
    "\n",
    "# Function to plot the top words for a given topic\n",
    "def plot_top_words_for_topic(word_given_topic, topic_num, corptype, color, top_n=10):\n",
    "    # Extract the top words for this topic\n",
    "    top_words_data = word_given_topic[topic_num][:top_n]\n",
    "    words, probabilities = zip(*top_words_data)\n",
    "\n",
    "    # Create a bar plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(words, probabilities, color=color)\n",
    "    plt.xlabel('Probability')\n",
    "    plt.gca().invert_yaxis() \n",
    "    plt.savefig(f'plsa_plots/{corptype}_topic_{topic_num + 1}.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_word_contribution(result, corptype):\n",
    "    # Number of topics in your model\n",
    "    n_topics = len(result.word_given_topic)\n",
    "\n",
    "    colours = ['lightsteelblue', 'midnightblue', 'lightgray', 'darkgray', 'dimgray']\n",
    "    \n",
    "    i = 0\n",
    "\n",
    "    # Plot the top words for each topic\n",
    "    for topic_num in range(n_topics):\n",
    "        plot_top_words_for_topic(result.word_given_topic, topic_num, corptype, colours[i])\n",
    "        i+=1\n",
    "\n",
    "        if i == 4:\n",
    "            i = 0\n",
    "\n",
    "# Plot the word contribution for each topic for each model\n",
    "plot_word_contribution(bow_result, 'words-BoW')\n",
    "plot_word_contribution(tfidf_result, 'words-tf-idf')\n",
    "plot_word_contribution(bow_result_sent, 'sentences-BoW')\n",
    "plot_word_contribution(tfidf_result_sent, 'sentences-tf-idf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f80afea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: true\n",
    "\n",
    "texts = sona_speeches_clean['speech']\n",
    "sentences = sona_sentences_alltogether['sentence']\n",
    "\n",
    "# Further process tokens using gensim's simple_preprocess\n",
    "tokenized_texts = [simple_preprocess(doc, deacc=True) for doc in texts]  # deacc=True removes punctuations\n",
    "tokenized_sentences = [simple_preprocess(doc, deacc=True) for doc in sentences]  # deacc=True removes punctuations\n",
    "\n",
    "# Create a Gensim dictionary from the tokenized documents\n",
    "dictionary = corpora.Dictionary(tokenized_texts)\n",
    "dictionary.filter_extremes(no_below=3, no_above=0.7)\n",
    "\n",
    "dict_sentences = corpora.Dictionary(tokenized_sentences)\n",
    "dict_sentences.filter_extremes(no_below=3, no_above=0.7)\n",
    "\n",
    "# Create a BOW corpus\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in tokenized_texts]\n",
    "bow_corpus_sentences = [dict_sentences.doc2bow(text) for text in tokenized_sentences]\n",
    "\n",
    "# Create a TF-IDF corpus\n",
    "tfidf = TfidfModel(bow_corpus)\n",
    "tfidf_corpus = tfidf[bow_corpus]\n",
    "\n",
    "tfidf_sentences = TfidfModel(bow_corpus_sentences)\n",
    "tfidf_corpus_sentences = tfidf_sentences[bow_corpus_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69adae2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to compute coherence values\n",
    "def compute_coherence_values(corpus, dictionary, k, a, b, texts):\n",
    "    lda_model = LdaModel(corpus=corpus,\n",
    "                         id2word=dictionary,\n",
    "                         num_topics=k, \n",
    "                         random_state=100,\n",
    "                         eval_every=None,\n",
    "                         alpha=a,\n",
    "                         eta=b)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='u_mass')\n",
    "    \n",
    "    return coherence_model_lda.get_coherence()\n",
    "\n",
    "# Define the parameter space for grid search\n",
    "grid = {}\n",
    "grid['Validation_Set'] = {}\n",
    "# Topics range\n",
    "min_topics = 2\n",
    "max_topics = 10\n",
    "step_size = 1\n",
    "topics_range = range(min_topics, max_topics, step_size)\n",
    "# Alpha parameter\n",
    "alpha = list(np.arange(0.1, 1, 0.1))\n",
    "# Beta parameter\n",
    "beta = list(np.arange(0.1, 1, 0.2))\n",
    "\n",
    "# Validation sets\n",
    "num_of_docs = len(bow_corpus)\n",
    "corpus_sets = [tfidf_corpus, \n",
    "               bow_corpus]\n",
    "corpus_title = ['TF-IDF Corpus', 'BoW Corpus']\n",
    "model_results = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "model_results_sentences = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "\n",
    "# Can take a long time to run\n",
    "# If you want to only test a few models, reduce the number of steps in topics_range\n",
    "# and/or limit the number of values in alpha and beta lists.\n",
    "if 1 == 1:\n",
    "    pbar = tqdm.tqdm(total=(max_topics-min_topics)*len(alpha)*len(beta)*len(corpus_sets))\n",
    "    \n",
    "    # iterate through validation corpuses\n",
    "    for i in range(len(corpus_sets)):\n",
    "        # iterate through number of topics\n",
    "        for k in topics_range:\n",
    "            # iterate through alpha values\n",
    "            for a in alpha:\n",
    "                # iterare through beta values\n",
    "                for b in beta:\n",
    "                    # get the coherence score for the given parameters\n",
    "                    cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=dictionary, k=k, a=a, b=b, texts=tokenized_texts)\n",
    "                    # Save the model results\n",
    "                    model_results['Validation_Set'].append(corpus_title[i])\n",
    "                    model_results['Topics'].append(k)\n",
    "                    model_results['Alpha'].append(a)\n",
    "                    model_results['Beta'].append(b)\n",
    "                    model_results['Coherence'].append(cv)\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "    pbar.close()\n",
    "\n",
    "\n",
    "# Get the results for the sentences\n",
    "if 1 == 1:\n",
    "    pbar = tqdm.tqdm(total=(max_topics-min_topics)*len(alpha)*len(beta)*len(corpus_sets))\n",
    "    \n",
    "    # iterate through validation corpuses\n",
    "    for i in range(len(corpus_sets)):\n",
    "        # iterate through number of topics\n",
    "        for k in topics_range:\n",
    "            # iterate through alpha values\n",
    "            for a in alpha:\n",
    "                # iterare through beta values\n",
    "                for b in beta:\n",
    "                    # get the coherence score for the given parameters\n",
    "                    cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=dict_sentences, k=k, a=a, b=b, texts=tokenized_sentences)\n",
    "                    # Save the model results\n",
    "                    model_results_sentences['Validation_Set'].append(corpus_title[i])\n",
    "                    model_results_sentences['Topics'].append(k)\n",
    "                    model_results_sentences['Alpha'].append(a)\n",
    "                    model_results_sentences['Beta'].append(b)\n",
    "                    model_results_sentences['Coherence'].append(cv)\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b31eb5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the results to a csv\n",
    "# model_results_df = pd.DataFrame(model_results)\n",
    "# model_results_sentences_df = pd.DataFrame(model_results_sentences)\n",
    "\n",
    "# model_results_df.to_csv('data/sona_speeches_lda.csv', index=False)\n",
    "# model_results_sentences_df.to_csv('data/sona_sentences_lda.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6c0d46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: true\n",
    "\n",
    "# Save the results to a csv\n",
    "model_results_df = pd.read_csv('data/sona_speeches_lda.csv')\n",
    "sorted_speeches_df = model_results_df.sort_values(by='Coherence', ascending=False)\n",
    "\n",
    "# Concatenate the head and tail of the DataFrame\n",
    "combined_speeches_df = pd.concat([sorted_speeches_df.head(5), sorted_speeches_df.tail(5)])\n",
    "\n",
    "combined_speeches_df['Validation_Set'] = combined_speeches_df['Validation_Set'].replace(['TF-IDF Corpus', 'BoW Corpus'], ['tf-idf', 'BoW'])\n",
    "\n",
    "# Change the validation set column name from \"Validation_Set\" to \"Corpus\"\n",
    "combined_speeches_df = combined_speeches_df.rename(columns={'Validation_Set': 'Corpus'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a891969",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: true\n",
    "\n",
    "# Save the results to a csv\n",
    "model_results_sentences_df = pd.read_csv('data/sona_sentences_lda.csv')\n",
    "sorted_sentences_df = model_results_sentences_df.sort_values(by='Coherence', ascending=False)\n",
    "\n",
    "# Concatenate the head and tail of the DataFrame\n",
    "combined_sentences_df = pd.concat([sorted_sentences_df.head(5), sorted_sentences_df.tail(5)])\n",
    "combined_sentences_df['Validation_Set'] = combined_sentences_df['Validation_Set'].replace(['TF-IDF Corpus', 'BoW Corpus'], ['tf-idf', 'BoW'])\n",
    "\n",
    "# Change the validation set column name from \"Validation_Set\" to \"Corpus\"\n",
    "combined_sentences_df = combined_sentences_df.rename(columns={'Validation_Set': 'Corpus'})\n",
    "\n",
    "num_cols = combined_sentences_df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Remove the first value from the num_cols\n",
    "num_cols = num_cols[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3eab4da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pivot_table to handle duplicate (Alpha, Beta) pairs by averaging their coherence values\n",
    "pivot_table = model_results_df.pivot_table(index='Alpha', columns='Beta', values='Coherence', aggfunc=np.mean)\n",
    "pivot_table_sentences = model_results_sentences_df.pivot_table(index='Alpha', columns='Beta', values='Coherence', aggfunc=np.mean)\n",
    "\n",
    "# Create the meshgrid for Alpha and Beta values\n",
    "Alpha, Beta = np.meshgrid(pivot_table.columns, pivot_table.index)\n",
    "Alpha_sentences, Beta_sentences = np.meshgrid(pivot_table_sentences.columns, pivot_table_sentences.index)\n",
    "\n",
    "# Create the contour plot using the values of the pivot_table\n",
    "# We need to use the values attribute to get the coherence scores as a 2D array\n",
    "plt.figure(figsize=(8, 6))\n",
    "cp = plt.contourf(Alpha, Beta, pivot_table.values, cmap='seismic', levels=100)\n",
    "plt.colorbar(cp)\n",
    "plt.xlabel('Beta')\n",
    "plt.ylabel('Alpha')\n",
    "plt.savefig(f'lda_plots/words_contour_plot.png', bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "cp = plt.contourf(Alpha_sentences, Beta_sentences, pivot_table_sentences.values, cmap='seismic', levels=100)\n",
    "plt.colorbar(cp)\n",
    "plt.xlabel('Beta')\n",
    "plt.ylabel('Alpha')\n",
    "plt.savefig(f'lda_plots/sentences_contour_plot.png', bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "word-lda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_81840 th {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_81840 td {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_81840  {\n",
       "  margin: auto;\n",
       "  border: 1px solid black;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_81840\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_81840_level0_col0\" class=\"col_heading level0 col0\" >Corpus</th>\n",
       "      <th id=\"T_81840_level0_col1\" class=\"col_heading level0 col1\" >Topics</th>\n",
       "      <th id=\"T_81840_level0_col2\" class=\"col_heading level0 col2\" >Alpha</th>\n",
       "      <th id=\"T_81840_level0_col3\" class=\"col_heading level0 col3\" >Beta</th>\n",
       "      <th id=\"T_81840_level0_col4\" class=\"col_heading level0 col4\" >Coherence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_81840_row0_col0\" class=\"data row0 col0\" >BoW</td>\n",
       "      <td id=\"T_81840_row0_col1\" class=\"data row0 col1\" >9</td>\n",
       "      <td id=\"T_81840_row0_col2\" class=\"data row0 col2\" >0.60</td>\n",
       "      <td id=\"T_81840_row0_col3\" class=\"data row0 col3\" >0.50</td>\n",
       "      <td id=\"T_81840_row0_col4\" class=\"data row0 col4\" >-0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_81840_row1_col0\" class=\"data row1 col0\" >BoW</td>\n",
       "      <td id=\"T_81840_row1_col1\" class=\"data row1 col1\" >9</td>\n",
       "      <td id=\"T_81840_row1_col2\" class=\"data row1 col2\" >0.60</td>\n",
       "      <td id=\"T_81840_row1_col3\" class=\"data row1 col3\" >0.10</td>\n",
       "      <td id=\"T_81840_row1_col4\" class=\"data row1 col4\" >-0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_81840_row2_col0\" class=\"data row2 col0\" >BoW</td>\n",
       "      <td id=\"T_81840_row2_col1\" class=\"data row2 col1\" >9</td>\n",
       "      <td id=\"T_81840_row2_col2\" class=\"data row2 col2\" >0.60</td>\n",
       "      <td id=\"T_81840_row2_col3\" class=\"data row2 col3\" >0.70</td>\n",
       "      <td id=\"T_81840_row2_col4\" class=\"data row2 col4\" >-0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_81840_row3_col0\" class=\"data row3 col0\" >BoW</td>\n",
       "      <td id=\"T_81840_row3_col1\" class=\"data row3 col1\" >9</td>\n",
       "      <td id=\"T_81840_row3_col2\" class=\"data row3 col2\" >0.60</td>\n",
       "      <td id=\"T_81840_row3_col3\" class=\"data row3 col3\" >0.90</td>\n",
       "      <td id=\"T_81840_row3_col4\" class=\"data row3 col4\" >-0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_81840_row4_col0\" class=\"data row4 col0\" >BoW</td>\n",
       "      <td id=\"T_81840_row4_col1\" class=\"data row4 col1\" >9</td>\n",
       "      <td id=\"T_81840_row4_col2\" class=\"data row4 col2\" >0.60</td>\n",
       "      <td id=\"T_81840_row4_col3\" class=\"data row4 col3\" >0.30</td>\n",
       "      <td id=\"T_81840_row4_col4\" class=\"data row4 col4\" >-0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_81840_row5_col0\" class=\"data row5 col0\" >tf-idf</td>\n",
       "      <td id=\"T_81840_row5_col1\" class=\"data row5 col1\" >7</td>\n",
       "      <td id=\"T_81840_row5_col2\" class=\"data row5 col2\" >0.20</td>\n",
       "      <td id=\"T_81840_row5_col3\" class=\"data row5 col3\" >0.90</td>\n",
       "      <td id=\"T_81840_row5_col4\" class=\"data row5 col4\" >-4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_81840_row6_col0\" class=\"data row6 col0\" >tf-idf</td>\n",
       "      <td id=\"T_81840_row6_col1\" class=\"data row6 col1\" >7</td>\n",
       "      <td id=\"T_81840_row6_col2\" class=\"data row6 col2\" >0.20</td>\n",
       "      <td id=\"T_81840_row6_col3\" class=\"data row6 col3\" >0.10</td>\n",
       "      <td id=\"T_81840_row6_col4\" class=\"data row6 col4\" >-4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_81840_row7_col0\" class=\"data row7 col0\" >tf-idf</td>\n",
       "      <td id=\"T_81840_row7_col1\" class=\"data row7 col1\" >7</td>\n",
       "      <td id=\"T_81840_row7_col2\" class=\"data row7 col2\" >0.20</td>\n",
       "      <td id=\"T_81840_row7_col3\" class=\"data row7 col3\" >0.30</td>\n",
       "      <td id=\"T_81840_row7_col4\" class=\"data row7 col4\" >-4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_81840_row8_col0\" class=\"data row8 col0\" >tf-idf</td>\n",
       "      <td id=\"T_81840_row8_col1\" class=\"data row8 col1\" >7</td>\n",
       "      <td id=\"T_81840_row8_col2\" class=\"data row8 col2\" >0.20</td>\n",
       "      <td id=\"T_81840_row8_col3\" class=\"data row8 col3\" >0.50</td>\n",
       "      <td id=\"T_81840_row8_col4\" class=\"data row8 col4\" >-4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_81840_row9_col0\" class=\"data row9 col0\" >tf-idf</td>\n",
       "      <td id=\"T_81840_row9_col1\" class=\"data row9 col1\" >7</td>\n",
       "      <td id=\"T_81840_row9_col2\" class=\"data row9 col2\" >0.20</td>\n",
       "      <td id=\"T_81840_row9_col3\" class=\"data row9 col3\" >0.70</td>\n",
       "      <td id=\"T_81840_row9_col4\" class=\"data row9 col4\" >-4.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b2d7bca0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: true\n",
    "#| output: true\n",
    "#| label: word-lda\n",
    "#| tbl-cap: 'Table 1: Coherence scores obtained from a hyperparameter-combination grid search for implementation of LDA on SONA speeches tokenized by words.'\n",
    "\n",
    "def style_df(df):\n",
    "    # Select the numeric columns except the first one\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns[1:]\n",
    "    format_dict = {col: \"{:.2f}\" for col in numeric_cols}\n",
    "    styles = [\n",
    "        dict(selector=\"th\", props=[(\"text-align\", \"center\")]),\n",
    "        dict(selector=\"td\", props=[(\"text-align\", \"center\")]),\n",
    "        dict(selector=\"\", props=[(\"margin\", \"auto\"), (\"border\", \"1px solid black\")])\n",
    "    ]\n",
    "    return df.style.set_table_styles(styles).format(format_dict).hide()\n",
    "\n",
    "\n",
    "# Save the results to a csv\n",
    "style_df(combined_speeches_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "sent-lda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7656d th {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_7656d td {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_7656d  {\n",
       "  margin: auto;\n",
       "  border: 1px solid black;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7656d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_7656d_level0_col0\" class=\"col_heading level0 col0\" >Corpus</th>\n",
       "      <th id=\"T_7656d_level0_col1\" class=\"col_heading level0 col1\" >Topics</th>\n",
       "      <th id=\"T_7656d_level0_col2\" class=\"col_heading level0 col2\" >Alpha</th>\n",
       "      <th id=\"T_7656d_level0_col3\" class=\"col_heading level0 col3\" >Beta</th>\n",
       "      <th id=\"T_7656d_level0_col4\" class=\"col_heading level0 col4\" >Coherence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_7656d_row0_col0\" class=\"data row0 col0\" >BoW</td>\n",
       "      <td id=\"T_7656d_row0_col1\" class=\"data row0 col1\" >2</td>\n",
       "      <td id=\"T_7656d_row0_col2\" class=\"data row0 col2\" >0.90</td>\n",
       "      <td id=\"T_7656d_row0_col3\" class=\"data row0 col3\" >0.90</td>\n",
       "      <td id=\"T_7656d_row0_col4\" class=\"data row0 col4\" >-18.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7656d_row1_col0\" class=\"data row1 col0\" >BoW</td>\n",
       "      <td id=\"T_7656d_row1_col1\" class=\"data row1 col1\" >2</td>\n",
       "      <td id=\"T_7656d_row1_col2\" class=\"data row1 col2\" >0.80</td>\n",
       "      <td id=\"T_7656d_row1_col3\" class=\"data row1 col3\" >0.50</td>\n",
       "      <td id=\"T_7656d_row1_col4\" class=\"data row1 col4\" >-18.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7656d_row2_col0\" class=\"data row2 col0\" >BoW</td>\n",
       "      <td id=\"T_7656d_row2_col1\" class=\"data row2 col1\" >2</td>\n",
       "      <td id=\"T_7656d_row2_col2\" class=\"data row2 col2\" >0.70</td>\n",
       "      <td id=\"T_7656d_row2_col3\" class=\"data row2 col3\" >0.10</td>\n",
       "      <td id=\"T_7656d_row2_col4\" class=\"data row2 col4\" >-18.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7656d_row3_col0\" class=\"data row3 col0\" >BoW</td>\n",
       "      <td id=\"T_7656d_row3_col1\" class=\"data row3 col1\" >2</td>\n",
       "      <td id=\"T_7656d_row3_col2\" class=\"data row3 col2\" >0.70</td>\n",
       "      <td id=\"T_7656d_row3_col3\" class=\"data row3 col3\" >0.30</td>\n",
       "      <td id=\"T_7656d_row3_col4\" class=\"data row3 col4\" >-18.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7656d_row4_col0\" class=\"data row4 col0\" >BoW</td>\n",
       "      <td id=\"T_7656d_row4_col1\" class=\"data row4 col1\" >2</td>\n",
       "      <td id=\"T_7656d_row4_col2\" class=\"data row4 col2\" >0.70</td>\n",
       "      <td id=\"T_7656d_row4_col3\" class=\"data row4 col3\" >0.50</td>\n",
       "      <td id=\"T_7656d_row4_col4\" class=\"data row4 col4\" >-18.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7656d_row5_col0\" class=\"data row5 col0\" >tf-idf</td>\n",
       "      <td id=\"T_7656d_row5_col1\" class=\"data row5 col1\" >2</td>\n",
       "      <td id=\"T_7656d_row5_col2\" class=\"data row5 col2\" >0.40</td>\n",
       "      <td id=\"T_7656d_row5_col3\" class=\"data row5 col3\" >0.10</td>\n",
       "      <td id=\"T_7656d_row5_col4\" class=\"data row5 col4\" >-20.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7656d_row6_col0\" class=\"data row6 col0\" >tf-idf</td>\n",
       "      <td id=\"T_7656d_row6_col1\" class=\"data row6 col1\" >2</td>\n",
       "      <td id=\"T_7656d_row6_col2\" class=\"data row6 col2\" >0.40</td>\n",
       "      <td id=\"T_7656d_row6_col3\" class=\"data row6 col3\" >0.30</td>\n",
       "      <td id=\"T_7656d_row6_col4\" class=\"data row6 col4\" >-20.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7656d_row7_col0\" class=\"data row7 col0\" >tf-idf</td>\n",
       "      <td id=\"T_7656d_row7_col1\" class=\"data row7 col1\" >2</td>\n",
       "      <td id=\"T_7656d_row7_col2\" class=\"data row7 col2\" >0.40</td>\n",
       "      <td id=\"T_7656d_row7_col3\" class=\"data row7 col3\" >0.50</td>\n",
       "      <td id=\"T_7656d_row7_col4\" class=\"data row7 col4\" >-20.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7656d_row8_col0\" class=\"data row8 col0\" >tf-idf</td>\n",
       "      <td id=\"T_7656d_row8_col1\" class=\"data row8 col1\" >2</td>\n",
       "      <td id=\"T_7656d_row8_col2\" class=\"data row8 col2\" >0.40</td>\n",
       "      <td id=\"T_7656d_row8_col3\" class=\"data row8 col3\" >0.70</td>\n",
       "      <td id=\"T_7656d_row8_col4\" class=\"data row8 col4\" >-20.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7656d_row9_col0\" class=\"data row9 col0\" >tf-idf</td>\n",
       "      <td id=\"T_7656d_row9_col1\" class=\"data row9 col1\" >2</td>\n",
       "      <td id=\"T_7656d_row9_col2\" class=\"data row9 col2\" >0.40</td>\n",
       "      <td id=\"T_7656d_row9_col3\" class=\"data row9 col3\" >0.90</td>\n",
       "      <td id=\"T_7656d_row9_col4\" class=\"data row9 col4\" >-20.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b67d6650>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: true\n",
    "#| output: true\n",
    "#| label: sent-lda\n",
    "#| tbl-cap: 'Table 2: Coherence scores obtained from a hyperparameter-combination grid search for implementation of LDA on SONA speeches tokenized by sentences.'\n",
    "\n",
    "# Save the results to a csv\n",
    "style_df(combined_sentences_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f2c0a4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: true\n",
    "\n",
    "# Set the number of topics based on the plots\n",
    "\n",
    "# Train the best models for each corpus\n",
    "lda_model_speeches = LdaModel(corpus=bow_corpus,\n",
    "                         id2word=dictionary,\n",
    "                         num_topics=9, \n",
    "                         random_state=100,\n",
    "                         eval_every=None,\n",
    "                         alpha=0.6,\n",
    "                         eta=0.5)\n",
    "\n",
    "lda_model_sentences = LdaModel(corpus=bow_corpus,\n",
    "                         id2word=dict_sentences,\n",
    "                         num_topics=2, \n",
    "                         random_state=100,\n",
    "                         eval_every=None,\n",
    "                         alpha=0.9,\n",
    "                         eta=0.9)\n",
    "\n",
    "# Prepare the visualization data\n",
    "vis_data_speeches = pyLDAvis.gensim_models.prepare(lda_model_speeches, bow_corpus, dictionary)\n",
    "vis_data_sentences = pyLDAvis.gensim_models.prepare(lda_model_sentences, bow_corpus_sentences, dict_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c81b5ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el3926773574000003654059862\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el3926773574000003654059862_data = {\"mdsDat\": {\"x\": [-0.003029268777711012, -0.0015002568747045908, -0.001427594321958475, 4.6729250427953635e-05, 0.001407105858534189, 0.001316081347675634, 0.0008741921612215678, 0.0005119364346939991, 0.0018010749218207315], \"y\": [-0.00028351503474712957, 0.0027885432371966847, -0.0009054973468915476, -0.002291954257262981, -4.8304310823830484e-05, 3.1093023915318905e-05, -0.0001899829601646658, -0.00055227387737999, 0.001451891526158142], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [31.839476796985878, 21.035561150099078, 16.374411665558164, 9.70686556594877, 9.366196200516121, 4.133442886129981, 3.597373617616158, 3.5722813474244157, 0.3743907697214367]}, \"tinfo\": {\"Term\": [\"plan\", \"shall\", \"necessary\", \"number\", \"key\", \"mining\", \"relations\", \"fact\", \"households\", \"possible\", \"crisis\", \"second\", \"elections\", \"businesses\", \"per\", \"eskom\", \"say\", \"around\", \"project\", \"question\", \"parties\", \"reform\", \"objectives\", \"potential\", \"fellow\", \"decade\", \"child\", \"law\", \"rand\", \"students\", \"alliance\", \"covid\", \"establish\", \"improvements\", \"weapons\", \"election\", \"dr\", \"proteas\", \"oil\", \"reading\", \"mining\", \"municipal\", \"stakeholders\", \"kwazulunatal\", \"secured\", \"childhood\", \"madiba\", \"extension\", \"rise\", \"hardship\", \"located\", \"broadband\", \"vaccine\", \"na\", \"promotes\", \"investors\", \"mogoeng\", \"disabilities\", \"story\", \"body\", \"eskom\", \"position\", \"municipalities\", \"funds\", \"technology\", \"elements\", \"necessary\", \"second\", \"number\", \"reform\", \"structures\", \"key\", \"northern\", \"industries\", \"prevention\", \"supply\", \"brought\", \"plan\", \"total\", \"increased\", \"per\", \"transport\", \"possible\", \"approach\", \"potential\", \"welcome\", \"cost\", \"objectives\", \"law\", \"crisis\", \"rest\", \"fellow\", \"relations\", \"shall\", \"households\", \"businesses\", \"rand\", \"fact\", \"project\", \"compatriots\", \"speech\", \"solutions\", \"mandate\", \"serious\", \"adequate\", \"seriously\", \"developmental\", \"gauteng\", \"visit\", \"engagements\", \"decade\", \"recession\", \"currently\", \"centre\", \"obligations\", \"expectancy\", \"question\", \"valued\", \"comes\", \"cut\", \"acts\", \"functioning\", \"welllocated\", \"anc\", \"sudan\", \"ready\", \"intensify\", \"pilot\", \"discuss\", \"debt\", \"legal\", \"host\", \"liberation\", \"child\", \"anniversary\", \"thousand\", \"want\", \"foundation\", \"shall\", \"aware\", \"living\", \"defence\", \"matters\", \"drive\", \"crisis\", \"households\", \"complete\", \"presidential\", \"former\", \"number\", \"elections\", \"around\", \"law\", \"agricultural\", \"second\", \"key\", \"possible\", \"relations\", \"indeed\", \"necessary\", \"objectives\", \"mining\", \"plan\", \"businesses\", \"rand\", \"eskom\", \"reform\", \"fellow\", \"leave\", \"consultations\", \"vigour\", \"republic\", \"financing\", \"authorities\", \"born\", \"road\", \"trends\", \"sugar\", \"livestock\", \"results\", \"belongs\", \"allocations\", \"obstacles\", \"priority\", \"george\", \"groupings\", \"diversity\", \"aims\", \"consequence\", \"formal\", \"interactions\", \"ensured\", \"head\", \"look\", \"devastation\", \"commitments\", \"occupy\", \"frames\", \"undertaken\", \"broad\", \"au\", \"committee\", \"plan\", \"shall\", \"proud\", \"sanitation\", \"chief\", \"objective\", \"reduction\", \"immediate\", \"terms\", \"positive\", \"reconstruction\", \"rates\", \"ministers\", \"indeed\", \"week\", \"rand\", \"objectives\", \"say\", \"could\", \"relations\", \"spirit\", \"elections\", \"households\", \"implemented\", \"crisis\", \"fellow\", \"respond\", \"implementing\", \"child\", \"businesses\", \"necessary\", \"key\", \"number\", \"possible\", \"reform\", \"law\", \"mining\", \"eskom\", \"supply\", \"potential\", \"second\", \"operations\", \"upliftment\", \"vaccines\", \"consultations\", \"millions\", \"patriotism\", \"dealt\", \"welfare\", \"spending\", \"received\", \"disability\", \"shows\", \"neither\", \"hydrogen\", \"institution\", \"strengthened\", \"weeks\", \"streets\", \"coming\", \"councils\", \"morality\", \"bold\", \"presidents\", \"healthier\", \"contain\", \"confidence\", \"fulfil\", \"syndicates\", \"competitiveness\", \"ranks\", \"involvement\", \"vital\", \"inequality\", \"benefit\", \"negotiations\", \"group\", \"town\", \"ordinary\", \"shall\", \"conference\", \"transition\", \"structure\", \"governance\", \"around\", \"urban\", \"available\", \"pandemic\", \"say\", \"meeting\", \"cent\", \"difficult\", \"businesses\", \"agreed\", \"additional\", \"criminal\", \"plan\", \"approach\", \"particularly\", \"number\", \"roads\", \"fact\", \"manufacturing\", \"restructuring\", \"possible\", \"mining\", \"key\", \"law\", \"necessary\", \"implementing\", \"increased\", \"potential\", \"elections\", \"crimes\", \"project\", \"indeed\", \"eskom\", \"reform\", \"fellow\", \"households\", \"party\", \"tons\", \"struggled\", \"movement\", \"certainty\", \"marks\", \"conflict\", \"say\", \"amount\", \"example\", \"confident\", \"nutrition\", \"councillors\", \"food\", \"deeds\", \"competitiveness\", \"ideals\", \"wife\", \"eastern\", \"changing\", \"tide\", \"hundred\", \"slow\", \"maputo\", \"guest\", \"turned\", \"attitudes\", \"congratulate\", \"house\", \"specific\", \"allocated\", \"addressed\", \"problem\", \"former\", \"speak\", \"changes\", \"anc\", \"procurement\", \"related\", \"rates\", \"starting\", \"started\", \"urban\", \"cup\", \"continued\", \"clear\", \"fact\", \"students\", \"project\", \"believe\", \"mining\", \"coming\", \"rand\", \"parties\", \"plan\", \"shall\", \"necessary\", \"key\", \"number\", \"actions\", \"per\", \"investments\", \"increased\", \"elections\", \"indeed\", \"objectives\", \"crisis\", \"relations\", \"reform\", \"question\", \"possible\", \"calendar\", \"surpassed\", \"asgisa\", \"moral\", \"evolution\", \"attend\", \"field\", \"occasion\", \"historical\", \"path\", \"practice\", \"refused\", \"machel\", \"low\", \"pretoria\", \"effectiveness\", \"inflows\", \"somewhat\", \"impetus\", \"languages\", \"applies\", \"expectations\", \"smme\", \"terrorism\", \"nd\", \"technologies\", \"setas\", \"shortage\", \"medicines\", \"favourable\", \"left\", \"municipality\", \"current\", \"project\", \"child\", \"stations\", \"nuclear\", \"alleviation\", \"courts\", \"shall\", \"partnerships\", \"plan\", \"capital\", \"learning\", \"per\", \"hand\", \"cabinet\", \"agree\", \"technical\", \"businesses\", \"systems\", \"households\", \"shared\", \"agency\", \"fact\", \"basis\", \"general\", \"started\", \"farmers\", \"parties\", \"crimes\", \"necessary\", \"present\", \"objectives\", \"reform\", \"bill\", \"number\", \"transport\", \"crisis\", \"relations\", \"mining\", \"increased\", \"context\", \"indeed\", \"elections\", \"second\", \"key\", \"possible\", \"law\", \"principle\", \"low\", \"licence\", \"intervene\", \"nutrition\", \"worst\", \"voters\", \"recently\", \"carry\", \"room\", \"opposition\", \"recognised\", \"faster\", \"arise\", \"battle\", \"vision\", \"miss\", \"integral\", \"preserve\", \"commitments\", \"deserves\", \"benefits\", \"nd\", \"nuclear\", \"thorough\", \"urgent\", \"evolved\", \"demand\", \"raising\", \"mind\", \"inclusive\", \"firmly\", \"north\", \"ability\", \"centres\", \"achieved\", \"rather\", \"municipality\", \"fact\", \"media\", \"concerns\", \"decisive\", \"redistribution\", \"technical\", \"direct\", \"say\", \"line\", \"immediate\", \"learning\", \"restructuring\", \"extend\", \"conference\", \"presidential\", \"number\", \"funds\", \"cup\", \"plan\", \"crisis\", \"improvement\", \"question\", \"proud\", \"objectives\", \"matters\", \"structures\", \"necessary\", \"elections\", \"eskom\", \"law\", \"indeed\", \"context\", \"key\", \"pleased\", \"businesses\", \"second\", \"relations\", \"shall\", \"municipalities\", \"reform\", \"households\", \"possible\", \"percent\", \"hundred\", \"related\", \"compensation\", \"nationally\", \"confront\", \"farms\", \"finalised\", \"earnings\", \"grows\", \"orders\", \"broaden\", \"zimbabwe\", \"relationship\", \"faith\", \"challenging\", \"leaks\", \"someone\", \"rich\", \"exchange\", \"redistribution\", \"scaling\", \"van\", \"testing\", \"aimed\", \"offering\", \"field\", \"unions\", \"petroleum\", \"outcomes\", \"affected\", \"developing\", \"joint\", \"largest\", \"historic\", \"context\", \"turn\", \"capture\", \"producers\", \"numbers\", \"necessary\", \"technology\", \"recovery\", \"improvement\", \"around\", \"republic\", \"procurement\", \"cent\", \"farmers\", \"project\", \"mining\", \"governance\", \"funding\", \"plan\", \"could\", \"municipalities\", \"shall\", \"possible\", \"potential\", \"approach\", \"rand\", \"matters\", \"cost\", \"urgent\", \"find\", \"bill\", \"manufacturing\", \"fact\", \"second\", \"supply\", \"law\", \"actions\", \"per\", \"businesses\", \"number\", \"indeed\", \"say\", \"relations\", \"households\", \"key\", \"crisis\", \"refurbishment\", \"attracting\", \"preferential\", \"telescope\", \"eyes\", \"wetlands\", \"twenty\", \"intensified\", \"catalyst\", \"acid\", \"victories\", \"hundred\", \"meerkat\", \"utilise\", \"parameters\", \"prospects\", \"focuses\", \"controls\", \"transferred\", \"municipality\", \"plumbers\", \"frene\", \"maths\", \"robotics\", \"mere\", \"contractors\", \"relationship\", \"sefako\", \"minimise\", \"tone\", \"colleges\", \"concerns\", \"brics\", \"prevent\", \"decades\", \"active\", \"pain\", \"changing\", \"students\", \"improvement\", \"plays\", \"huge\", \"pursuit\", \"decisive\", \"abuse\", \"bank\", \"shared\", \"teams\", \"words\", \"finalised\", \"civil\", \"relations\", \"plan\", \"early\", \"white\", \"parties\", \"informed\", \"participate\", \"houses\", \"started\", \"elections\", \"key\", \"conference\", \"manufacturing\", \"around\", \"led\", \"bill\", \"fellow\", \"criminal\", \"priority\", \"serve\", \"necessary\", \"shall\", \"households\", \"possible\", \"fact\", \"second\", \"mining\", \"potential\", \"number\", \"decade\", \"per\", \"eskom\", \"crisis\", \"question\", \"rand\", \"child\", \"reform\", \"businesses\"], \"Freq\": [127.0, 134.0, 94.0, 99.0, 82.0, 88.0, 66.0, 59.0, 68.0, 71.0, 69.0, 65.0, 57.0, 64.0, 55.0, 66.0, 58.0, 53.0, 55.0, 59.0, 50.0, 68.0, 66.0, 55.0, 58.0, 56.0, 54.0, 65.0, 60.0, 44.0, 7.8014490290915015, 10.553120336530492, 21.11981456647969, 10.715355975292939, 8.085907786382755, 10.59515335148334, 9.306896922723414, 3.880427101445566, 3.6172395786503033, 6.270313953352379, 36.63439978588677, 15.105683142884471, 14.90289598151498, 18.221528500026203, 4.08545535113321, 8.197333536006141, 9.08345140006701, 8.93297599834395, 10.196734820178046, 3.2707873971529042, 3.663093753623681, 8.247824506916704, 6.1673996523608166, 5.954765253868891, 3.923128774824778, 8.954976261569943, 5.753730614394024, 8.13428350412283, 6.923635775322567, 6.113721027527388, 26.792473212356015, 12.03344195695228, 24.028507760044622, 18.291087316713497, 16.769921747066203, 9.753184774453885, 36.68110245656233, 25.288632136763532, 37.97922802896837, 26.267737589863422, 17.88990856342417, 31.355271969264287, 14.055400847068992, 16.819833978188306, 13.552830550911075, 22.17539110866986, 15.402530803499403, 45.53429285783739, 15.623081608305442, 21.47817676450398, 20.65187899371831, 18.853703903739987, 25.47391853298067, 19.782187965695297, 20.311266174417472, 17.85020375343017, 17.622447230694608, 22.9087766896143, 22.84083386113914, 23.3663397781389, 18.094399339100526, 20.526702060670598, 22.27134168240049, 33.20743492267779, 21.53342603614006, 20.656150256382414, 19.68999920058964, 19.449991327120966, 18.219166671100773, 18.365384538254574, 5.481104695435684, 8.242671651732026, 8.750806132520141, 11.649491937237135, 2.1030608088690403, 2.5866738146290795, 6.478071250144619, 9.093856364577633, 5.463844678972075, 3.428825123577289, 16.530850777448954, 3.2209624221856092, 10.6271483115202, 11.83244407274598, 5.319679112441397, 2.7766910120642008, 17.19636308464026, 2.9911221460082857, 3.31025944651988, 4.23642425584687, 3.0421940231167532, 5.081555509330193, 1.8054729485693437, 5.344098602582804, 6.30376460572166, 9.3478889368419, 12.22629422221415, 3.097223452362099, 3.4597167833087648, 9.440014611300198, 5.925186608886481, 11.00133725580691, 8.7384010005626, 14.517096922135824, 10.341217694009128, 8.333635438966605, 13.416371011044875, 11.032463177852323, 32.280008603345394, 6.711554709204199, 10.036167098041897, 10.218048897116377, 13.186350999126685, 9.898986991372485, 16.386994867999917, 16.16109733427296, 10.163502129017848, 12.58199596555936, 12.053780223026862, 20.328510807054634, 13.494303620482942, 12.701934231289519, 14.680735880096272, 11.18053042361167, 14.320696244937821, 16.69888282696328, 14.648505963238055, 13.912947877844546, 12.701139893558354, 17.01269469883823, 13.713375235062436, 15.668090948258115, 18.007745418646408, 12.916173849060284, 12.544208377253266, 12.96484521061847, 12.739196748891962, 12.025664706349051, 2.7248151513365384, 4.477362473721083, 1.4222833112958455, 11.958504751369603, 4.014257496869534, 5.544990687324198, 2.7324608969649704, 9.62243418550366, 3.0631078241401597, 2.676820294474629, 1.8965183998615132, 7.439889521131221, 3.8381551353987753, 2.3610689733652754, 2.655033508862531, 10.90027717354019, 1.3531861493390842, 1.367662421024881, 2.925323009527481, 1.7232408141598223, 2.388664607799522, 2.7951750324714313, 1.715685459259984, 2.678952991665206, 3.5969211449353815, 6.551282634527148, 1.942598283287805, 5.544248173339174, 1.9784744944675314, 1.6865527894364836, 5.312597958125674, 5.007650556101168, 4.637282274752527, 5.965187578315688, 26.78903054062685, 28.00667382742448, 8.616345027935294, 8.936813435066657, 9.146803935692315, 7.99071490105192, 6.1778525964992586, 6.424546972976022, 10.095524062838368, 6.964749215269061, 10.09994770649509, 9.61903339809166, 8.924890242959926, 11.121109321554801, 9.299550118900907, 11.689160292322148, 12.681177840466493, 11.338365664746686, 8.398494463953702, 12.445457684447288, 9.210333159768785, 10.932116718182417, 12.2289653394136, 7.670833378651134, 12.259272695705645, 10.584577204844761, 8.611726454707346, 9.27326816305555, 9.936920560416933, 10.998290067571826, 14.187793736524023, 12.780849731870457, 14.290597077168993, 11.461828395916399, 11.1362006431982, 10.616732200029675, 11.237075648299847, 10.102336117746848, 9.681122658561323, 9.558297116527664, 9.71141219870976, 3.0962156757840473, 0.9446637019353873, 1.6402926371008444, 2.6726590094565736, 5.551261725627789, 2.481898750870842, 1.271508320769649, 1.7671730084748563, 3.894114432907424, 4.332052492021661, 2.8496799544159686, 1.7174912403659848, 1.4746554729794408, 1.4615573066134426, 2.718347585689647, 2.2580282374857803, 3.516637740849858, 1.286013966901438, 5.2685251028195195, 1.4331036012356717, 1.0929909772444284, 1.6590100056789978, 2.1780219745730784, 0.7738429212344883, 1.5035940770361786, 5.478097007208944, 1.9686473223688845, 1.2613402035960632, 2.992398589047182, 1.1070232957900061, 2.575857577213283, 3.8810237217421273, 4.765779605272939, 4.516378601768542, 4.301161557281189, 4.5011361333007445, 4.124911914961048, 2.8746113880955924, 16.003097744714008, 5.761774849105791, 3.885742863786245, 2.9917391144184524, 6.498410805097074, 6.489538494995437, 5.18943753807661, 4.668572485858135, 3.7531350344732233, 6.850319265081755, 4.1543217498288, 4.134370700851212, 4.794932546349848, 7.182296245990688, 4.677923171338126, 5.524527375911826, 5.521864626727902, 11.73175108820536, 5.914038004435237, 4.783912517179423, 9.351363281987686, 4.845499930175397, 6.189961195068962, 4.955667916009944, 5.217874469252801, 6.688721577207172, 7.5885624380909595, 7.269214567170549, 6.155118693323277, 7.324629695252319, 5.275116121506465, 5.639597777474405, 5.542892020306785, 5.629957581700502, 5.379571559803406, 5.4856522318532965, 5.44140810075616, 5.709131191884843, 5.525410195928242, 5.323585487601238, 5.289998565907048, 3.777119087360768, 1.4336191857857967, 1.0867491800404756, 4.696661646869717, 2.3991135759346895, 2.1165934425772965, 3.946519517405121, 8.058121533394162, 1.806071196991698, 3.7769994945069074, 4.336114669654996, 1.7960890902033777, 1.1831160676076364, 4.890672128172004, 1.710045029165454, 3.068842249765358, 1.1323997805597938, 1.158447119117162, 6.525424913485633, 2.241719339250384, 1.6010228048215835, 2.440110995351863, 1.5480055542627815, 0.9334538460497902, 1.4846809882779688, 2.1140734502995238, 0.9402791810665373, 3.9949225519520084, 4.713258077724614, 4.185058404628097, 4.224015102377329, 2.933911537464497, 4.024559999044029, 6.173559957837129, 4.217330491282606, 3.8146682461582997, 2.4610211614267077, 5.29913657496305, 3.2599621208354903, 5.664033854636242, 3.925345287911101, 5.606533370714992, 5.001630917500315, 5.001986998478727, 4.318096612469622, 5.280182156686299, 6.564061498032051, 5.151967827015272, 6.116071463174411, 3.7781840332499055, 8.513941153536367, 4.503574038742959, 6.230117486574808, 5.472807578896634, 10.358523947054282, 10.521525110356983, 8.28902086508031, 7.417539646250077, 8.104482797212986, 5.1745430013688, 5.630192374039845, 5.194051323389747, 5.492026959786951, 5.444207202667664, 5.3546270596913494, 5.596765122325743, 5.573566506528532, 5.504559331730839, 5.541668484740232, 5.339661467728317, 5.487379923179804, 0.6297226729882656, 0.3859156668459383, 1.001944864689024, 0.9134873459541245, 0.5163140332691413, 1.1691358972289765, 0.6671973871838517, 1.6503302911161322, 0.8063879733869679, 1.6846217835871693, 1.0721832175210577, 0.4579433500778641, 0.5420220374741376, 1.2462129849361416, 0.5916466982753747, 1.1531761375291862, 0.3933903185480289, 0.42701672733608126, 0.6587238533353689, 0.49377721367350846, 0.6095880845970418, 0.7287545328614584, 0.3924620717808558, 0.3480832122325653, 0.3410208647945685, 0.9415544593904485, 0.3815868358319281, 0.5562342990562043, 0.42094033206635195, 0.421598603535798, 0.6432686604034279, 1.9276954516351315, 2.672298301673923, 3.1092286515730168, 3.029114639387401, 1.5165299515481863, 1.1636276604097924, 0.9627400466685372, 1.4364052250072954, 6.78655993322295, 1.8893539328702136, 6.351697321615904, 2.224333488601678, 1.9046487411630098, 2.8753030587898825, 1.6095111107629108, 1.9569813560529636, 1.30434444699761, 1.8860617157290418, 3.1443778215700036, 1.6779094384214834, 3.237153820722614, 1.7622525785928578, 2.325412451712316, 2.848443625151819, 1.8858654181583279, 2.1722771982570217, 2.312624538001845, 2.1627453903421663, 2.404182275276911, 2.4742499259424986, 3.7723787241208044, 2.0376144192274483, 2.7566533466844914, 2.7929670745066573, 2.184616828633834, 3.4655600655033165, 2.262644319336673, 2.688861107616897, 2.6146016307950264, 2.934468522273366, 2.334201662213433, 2.2185089798879, 2.2687993857520774, 2.2318562887645097, 2.2705134180440663, 2.3828863698222893, 2.3057266096207196, 2.2486061329588245, 1.1889631006055894, 1.1573901248295864, 0.4435452875614173, 0.47540569174366676, 0.7052973317882517, 0.7161496176455623, 0.4170249445652495, 0.6120596090618124, 1.3244582385184382, 0.341137254637811, 0.44788304758839836, 0.38011225296622436, 1.3573925203538642, 0.4095753482513968, 0.5845506930881581, 1.9185941379592104, 0.3346910819130022, 0.32931792343372107, 0.32162504762472455, 1.2764606014810376, 0.2965178727074104, 1.378714544919609, 0.2907678080092244, 1.0299444788648948, 0.3852952027405007, 2.148778962461033, 0.26304203281447597, 1.5337054275397095, 0.6157776150785692, 0.7850342369147917, 1.8081702859857454, 0.847388328531936, 1.4149035282275084, 1.1826855513945682, 1.8495408663959383, 1.9651791249623467, 1.1928495862348591, 1.6261732784460734, 2.807856701363071, 0.9799295761971122, 1.321273415504998, 1.1867744197766892, 1.0775842046516617, 1.6780062873799417, 1.3311197163305737, 2.5906214950182287, 1.910816101375799, 1.408621604417734, 1.6335878779698996, 2.0407514696362314, 1.5769143755154773, 1.9608537980055067, 2.155471407827501, 3.5912674440957897, 1.963514935499766, 1.8139890779327665, 4.209735322286634, 2.633706918139725, 1.7244571583949828, 2.3074180301993668, 1.7347950259752083, 2.46027065499725, 2.0963558431795453, 1.8951776015587816, 2.908645614703358, 2.162208520149661, 2.3379865750774025, 2.3142942087134744, 2.095808097367221, 1.9913447513161808, 2.5083012166463203, 1.9516922370058463, 2.193621362587088, 2.2080803324349856, 2.2032024245829884, 2.9926910966783535, 2.0998334189463987, 2.157718570134472, 2.126317239799027, 2.1295473053732583, 1.3498803524059617, 1.0592538497867765, 1.4807999918016697, 0.44915448971865984, 0.4221135881455163, 1.4100143807947454, 0.5580079195949584, 1.4655567111160188, 0.40420329635618346, 0.373972150047555, 0.4712331027445257, 0.3935837513664701, 0.9959897936857879, 0.5775605328094361, 0.334952204870364, 0.5544071302275724, 0.2661769621921432, 0.3590022037760708, 0.5261199334711396, 0.9612596326539763, 1.1402527480777076, 0.44171321465059454, 0.455137381074836, 0.4189220573321731, 1.5275341177684734, 0.3098880335450506, 0.5388964025063955, 1.1627850607925, 0.36998339385955914, 0.8833384615756762, 1.3766607231845065, 1.351192952047727, 1.3355448712112756, 1.0279405404090953, 1.2817326299841039, 2.476913706233989, 1.3677116790147903, 1.5350220631730436, 0.8703915443549237, 1.2547257951844533, 4.045163219910103, 1.9427624737528697, 1.763438750581012, 1.8064051828539205, 2.352963008378227, 2.20004480715846, 1.908944799251329, 1.5223321900469184, 1.934181990917856, 2.3588881119693004, 3.4223261160400216, 2.2157928019547533, 1.6300921393690107, 4.262256820580811, 1.7836816160718336, 2.381262665800132, 4.011638313888144, 2.5794130826841846, 2.1782086912576677, 2.1100961787896217, 2.2517078693867476, 2.0563356093128484, 1.917590100410405, 1.790902971826117, 1.7398563124255946, 1.8940003459009487, 1.7946891850411726, 2.1186592852837935, 2.192634712333583, 2.0723723714576088, 2.182904876006294, 1.8878830736983263, 2.0090484127079278, 2.0931501310194824, 2.457657291040049, 1.9803763071382374, 1.9896340099939636, 2.033683719936735, 2.0433945794707364, 2.0663537557164777, 1.9994941688775685, 0.03922904868222457, 0.040217295093330455, 0.053738179867192835, 0.06806645138866355, 0.05057632570566627, 0.029272478895060388, 0.045538451653469814, 0.07534251993772827, 0.0331606860965297, 0.041608664281607456, 0.02872942365855902, 0.10079952248404114, 0.03622241777169058, 0.06173156476306704, 0.0279503720508382, 0.032154522052568954, 0.032334935422637, 0.05082131983166606, 0.031988683607521266, 0.18277605347442774, 0.027625446472085993, 0.04116713630743449, 0.04349036917180233, 0.029003507729441203, 0.08173490952480046, 0.027079476849632137, 0.05845671150139293, 0.03126750038274193, 0.0472756383444647, 0.026700570732713706, 0.125679955853028, 0.1439417318614351, 0.08259330850998003, 0.0824421737860431, 0.09232246933037058, 0.1239620915708507, 0.08118263787969086, 0.0869211027584926, 0.2175795606613016, 0.19312774870012672, 0.057109935712972695, 0.10160940428149368, 0.10597743682485282, 0.11992614926317936, 0.15031419100233273, 0.19507761367946322, 0.15804577837529712, 0.10690100663177364, 0.12607174756950204, 0.1269106354446153, 0.1847740702200255, 0.2790503043555395, 0.48043079134399064, 0.173379054775915, 0.17890624015182197, 0.21649259354453484, 0.12909000906652474, 0.1567831094291645, 0.16214048764328481, 0.20013535827267592, 0.23302325424974324, 0.3083555244148822, 0.19097986122943267, 0.18109645660738813, 0.21312932625968956, 0.16484681099988005, 0.1932056853111069, 0.22395023462848118, 0.19403073509464722, 0.19090688476556172, 0.17682946010405912, 0.3018399997748739, 0.3724242110532746, 0.23889803331631243, 0.24132258677021245, 0.21637436472406557, 0.22486759826099958, 0.2648665839811059, 0.2053643717135384, 0.2783320894313552, 0.2068915458957371, 0.20186399350231998, 0.21670103953344083, 0.21461003800109174, 0.20205631302260502, 0.20224899197384003, 0.19605259409325815, 0.20242444220154088, 0.19682801844364242], \"Total\": [127.0, 134.0, 94.0, 99.0, 82.0, 88.0, 66.0, 59.0, 68.0, 71.0, 69.0, 65.0, 57.0, 64.0, 55.0, 66.0, 58.0, 53.0, 55.0, 59.0, 50.0, 68.0, 66.0, 55.0, 58.0, 56.0, 54.0, 65.0, 60.0, 44.0, 15.73935848094152, 24.44629849821539, 49.1188389579668, 25.315462797714368, 19.137126802599475, 25.104319893802213, 22.11558839965699, 9.27825607803019, 8.6626542856811, 15.07533965333929, 88.1055580334661, 36.3540207659287, 35.939688449727996, 44.11718875800266, 9.911408501490454, 19.924266100575437, 22.085539723145917, 21.84758162731065, 24.95128890952843, 8.026270661255799, 8.9936372778085, 20.30093944447907, 15.184944535780252, 14.683500919613428, 9.68069815574102, 22.203532185613152, 14.286415142457866, 20.204267395568387, 17.2306128330662, 15.248518251755879, 66.82921524014338, 30.039963661246098, 61.010729145269515, 46.20588129670108, 42.3992460377682, 24.39422643929568, 94.52326901076634, 65.22413517760174, 99.84699888246318, 68.09038078640772, 45.64879649114078, 82.78765560811861, 35.65391002055403, 43.12682734887869, 34.395056977878205, 58.32025774742305, 39.45968246256773, 127.72546410819763, 40.080514302880076, 57.1369635009237, 55.61522138529638, 50.137179189288624, 71.01636397697048, 53.192479806787034, 55.59079876854557, 47.569992688407, 47.11409416799107, 66.13627204100894, 65.92588029259363, 69.0904402145642, 49.06911409104353, 58.72281836097142, 66.02798791601829, 134.18205376336138, 68.00748112471017, 64.18769861414106, 60.11920300801475, 59.8235973624643, 55.76861367923028, 46.217767341374355, 17.143483767385717, 26.175661547502376, 28.520068571476415, 38.699068648958686, 6.995266922980783, 8.649218000525279, 21.732423765293206, 30.694052197633102, 18.45788044348736, 11.603077386497382, 56.43144228943766, 11.069762669423882, 36.593044551645825, 40.79800920274777, 18.381932935751195, 9.61180092795983, 59.592445409113274, 10.366844908885522, 11.507739979868699, 14.75053815657887, 10.739814922954611, 17.945856503135825, 6.3900050998725115, 18.93758976764143, 22.405123204729772, 33.308793792726334, 43.60443356316506, 11.099456772258993, 12.45592973209386, 34.180337014487364, 21.365167902136875, 40.025196309933676, 31.826763697552536, 54.32880921118747, 38.25324677784651, 30.826018823788058, 51.44154163505837, 41.70752914525767, 134.18205376336138, 24.4337523213473, 38.224291395913085, 39.193612680581786, 52.63723386529244, 38.13690167046018, 69.0904402145642, 68.00748112471017, 39.774834411307, 51.653553180394475, 49.100791051529725, 99.84699888246318, 57.86959698517219, 53.65820748934756, 65.92588029259363, 45.294950507154304, 65.22413517760174, 82.78765560811861, 71.01636397697048, 66.02798791601829, 56.56823339823999, 94.52326901076634, 66.13627204100894, 88.1055580334661, 127.72546410819763, 64.18769861414106, 60.11920300801475, 66.82921524014338, 68.09038078640772, 58.72281836097142, 10.50205719881994, 18.41279399208411, 5.937234216299438, 50.39021455074934, 17.05633171888126, 23.568104158710476, 11.655153737051707, 41.0530452136239, 13.09651612772857, 11.444974239524237, 8.17024085122674, 32.054264216454605, 16.5451806023277, 10.290631693913934, 11.593971364434715, 47.65065751590737, 5.973904267448826, 6.039952859481214, 12.95638757142399, 7.677339990952131, 10.650905538161249, 12.521112950005072, 7.689372075124589, 12.023428365717717, 16.212627201453902, 29.56210300599828, 8.768267592821596, 25.089456303217407, 8.956785717621795, 7.640891329948413, 24.08631490186499, 22.75169687927195, 21.10909678231211, 27.224892305423143, 127.72546410819763, 134.18205376336138, 40.0522855636641, 41.58935793868727, 42.66050977536696, 37.217032690579465, 28.521623177916457, 29.7463783487368, 48.88381352362627, 33.038733333283524, 49.66593461645861, 47.28845148876622, 44.075272787882774, 56.56823339823999, 46.26410561007821, 60.11920300801475, 66.13627204100894, 58.45180231260775, 41.275335492456115, 66.02798791601829, 46.49205373519141, 57.86959698517219, 68.00748112471017, 37.55822992526802, 69.0904402145642, 58.72281836097142, 44.26864223340488, 49.12485408665926, 54.32880921118747, 64.18769861414106, 94.52326901076634, 82.78765560811861, 99.84699888246318, 71.01636397697048, 68.09038078640772, 65.92588029259363, 88.1055580334661, 66.82921524014338, 58.32025774742305, 55.59079876854557, 65.22413517760174, 20.174160999947556, 6.457965765508708, 11.2728832835801, 18.41279399208411, 38.43353640487834, 17.27214513040613, 8.942820091758204, 12.52226612386326, 27.612280849931015, 31.09539454679232, 20.60933477827478, 12.501188811647426, 10.73439190710129, 10.639535533891024, 19.79849359766837, 16.51277206965095, 25.740359396255336, 9.46794946147893, 38.81048162055594, 10.591354435196658, 8.102615996156747, 12.307248169709112, 16.168495280919146, 5.749867217669513, 11.174577803469397, 40.71403117202393, 14.799516783284396, 9.486319689970676, 22.576636680188344, 8.358203488061635, 19.550429378206225, 29.666750193074467, 36.86357018326368, 35.07726328450366, 33.47257493118458, 35.19049468019849, 32.11791059915244, 21.988156308457196, 134.18205376336138, 45.82474572798878, 30.20179733832027, 22.938889103412723, 53.4173109707982, 53.65820748934756, 42.06462596029658, 37.57631009551366, 29.583630551453908, 58.45180231260775, 33.24793747723719, 33.095512262996095, 39.50799372297301, 64.18769861414106, 38.5169927497205, 47.78052808538943, 48.05344097436579, 127.72546410819763, 53.192479806787034, 40.22089012439925, 99.84699888246318, 41.67724681239731, 59.8235973624643, 43.145646577120104, 47.023867441687365, 71.01636397697048, 88.1055580334661, 82.78765560811861, 65.92588029259363, 94.52326901076634, 49.12485408665926, 57.1369635009237, 55.59079876854557, 57.86959698517219, 52.80223971812674, 55.76861367923028, 56.56823339823999, 66.82921524014338, 68.09038078640772, 58.72281836097142, 68.00748112471017, 24.88806979266043, 9.776048372940854, 7.430589712498441, 32.259040828710184, 16.84597050218519, 15.06882562585561, 28.362881959217564, 58.45180231260775, 13.11969939775912, 27.4801383888283, 31.583039292191824, 13.110550609991966, 8.655065973829016, 35.90353895766183, 12.5632573772783, 22.576636680188344, 8.352884499830399, 8.551903644148231, 48.31072259252106, 16.60935892630696, 11.999583435278424, 18.290211757377474, 11.652741333030601, 7.050086466205868, 11.241654232517485, 16.015619087607863, 7.124186158500208, 30.3424704547062, 35.810809311412996, 31.82350902917558, 32.13445557254875, 22.50243560819579, 31.169574926770675, 49.100791051529725, 33.31506719914959, 30.024474225656245, 18.93758976764143, 42.891733688690515, 25.60669818186181, 47.28845148876622, 31.66750704483958, 47.717822222332465, 42.06462596029658, 42.07840348356405, 35.65655835123037, 45.6926181575314, 59.8235973624643, 44.70582571210496, 55.76861367923028, 30.93125577554856, 88.1055580334661, 38.81048162055594, 60.11920300801475, 50.768716523116254, 127.72546410819763, 134.18205376336138, 94.52326901076634, 82.78765560811861, 99.84699888246318, 47.82932010730084, 55.61522138529638, 48.349375163892724, 57.1369635009237, 57.86959698517219, 56.56823339823999, 66.13627204100894, 69.0904402145642, 66.02798791601829, 68.09038078640772, 59.592445409113274, 71.01636397697048, 9.395684238114608, 5.934116244468871, 15.703631778495401, 14.363751391381932, 8.139606494512613, 18.437773763123893, 10.584788545055742, 26.309494179334713, 12.909752185161633, 27.35851892652133, 17.42984981464484, 7.468198755127877, 8.916414566786871, 20.52675566672259, 9.779989012855681, 19.14192954856899, 6.531933637663211, 7.099312164531939, 10.954713972405887, 8.22262542589672, 10.15159264025702, 12.21006320721827, 6.576301920468307, 5.837491825482179, 5.729043348253226, 16.018084461009668, 6.50633879758397, 9.495031817675184, 7.194189904755866, 7.225527807237826, 11.025333812524883, 33.684723297905684, 47.33654682837756, 55.76861367923028, 54.32880921118747, 26.630248408890743, 20.320419651864736, 16.788995862433385, 25.630512554274034, 134.18205376336138, 34.55374807699733, 127.72546410819763, 41.64580659042907, 35.300622092587716, 55.61522138529638, 29.497565767990483, 36.77545194264948, 23.45107809673405, 35.71170379559015, 64.18769861414106, 31.416713859139993, 68.00748112471017, 33.30863308429251, 46.46277571461805, 59.8235973624643, 36.44122265338165, 43.95816893783306, 47.717822222332465, 44.062333933736106, 50.768716523116254, 52.80223971812674, 94.52326901076634, 41.91945313330648, 66.13627204100894, 68.09038078640772, 47.31149666459976, 99.84699888246318, 50.137179189288624, 69.0904402145642, 66.02798791601829, 88.1055580334661, 57.1369635009237, 51.8268499149025, 56.56823339823999, 57.86959698517219, 65.22413517760174, 82.78765560811861, 71.01636397697048, 65.92588029259363, 19.88591779191723, 20.52675566672259, 8.027158019338255, 8.760446610676603, 13.110550609991966, 13.497544199176021, 7.915436194497655, 11.635807224051343, 25.358112960356635, 6.55501930922989, 8.618947637255143, 7.32712750490862, 26.2124076228487, 7.9225382449150175, 11.318846525933388, 37.3044425664492, 6.514997200711347, 6.433875673517465, 6.297264428245868, 25.089456303217407, 5.832414299476587, 27.12503058369636, 5.729043348253226, 20.320419651864736, 7.618130408062154, 42.51645128623401, 5.209220299233198, 30.4655283051661, 12.250163309402565, 15.62237929489129, 36.13507123829438, 16.910074262991248, 28.434368990573127, 23.831704123329015, 37.616335133427164, 40.35508392705785, 24.250201093671283, 33.684723297905684, 59.8235973624643, 19.87501159000751, 27.35613889158577, 24.417098536086087, 22.034330699722943, 35.71170379559015, 27.764413367286004, 58.45180231260775, 41.76448519894514, 29.7463783487368, 35.300622092587716, 47.023867441687365, 35.00062573390395, 45.82474572798878, 51.653553180394475, 99.84699888246318, 46.20588129670108, 42.07840348356405, 127.72546410819763, 69.0904402145642, 39.431264993998425, 59.592445409113274, 40.0522855636641, 66.13627204100894, 52.63723386529244, 45.64879649114078, 94.52326901076634, 57.86959698517219, 66.82921524014338, 65.92588029259363, 56.56823339823999, 51.8268499149025, 82.78765560811861, 50.15217520877385, 64.18769861414106, 65.22413517760174, 66.02798791601829, 134.18205376336138, 61.010729145269515, 68.09038078640772, 68.00748112471017, 71.01636397697048, 23.068815427338393, 18.290211757377474, 25.60669818186181, 7.94593621009707, 7.489890122063294, 25.44411334068152, 10.071077121169521, 26.474357418505924, 7.4393615479576995, 6.9529391332416655, 8.838885576013357, 7.430564142125075, 18.82392638332723, 10.947256641385929, 6.355194608366991, 10.519890920895488, 5.0604736093497955, 6.892614714351362, 10.10866414669656, 18.486971940571436, 22.034330699722943, 8.600244908942432, 8.865360296290548, 8.201644648158771, 29.924999588116897, 6.079898450895152, 10.584788545055742, 22.96934459311336, 7.3130209295243125, 17.462934481522897, 27.341669550510233, 26.902722680311204, 26.61725533924037, 20.519571489488097, 26.03290407527224, 51.8268499149025, 27.933076763084145, 31.815706242363238, 17.523952552650233, 26.04008850449855, 94.52326901076634, 42.3992460377682, 38.26390164270889, 39.431264993998425, 53.65820748934756, 50.39021455074934, 42.891733688690515, 33.095512262996095, 44.062333933736106, 55.76861367923028, 88.1055580334661, 53.4173109707982, 36.58391056949968, 127.72546410819763, 41.275335492456115, 61.010729145269515, 134.18205376336138, 71.01636397697048, 55.59079876854557, 53.192479806787034, 60.11920300801475, 52.63723386529244, 47.11409416799107, 42.51645128623401, 40.62286860054203, 47.31149666459976, 43.145646577120104, 59.8235973624643, 65.22413517760174, 58.32025774742305, 65.92588029259363, 47.82932010730084, 55.61522138529638, 64.18769861414106, 99.84699888246318, 56.56823339823999, 58.45180231260775, 66.02798791601829, 68.00748112471017, 82.78765560811861, 69.0904402145642, 6.310023282148556, 6.777004925556775, 9.256145820301843, 11.75472805333113, 8.73471753882306, 5.0798509939274155, 7.942810342130553, 13.217363359247917, 5.868648918598366, 7.538868211904633, 5.205894759677257, 18.290211757377474, 6.582916592345036, 11.224575126913109, 5.102465827951575, 5.880109979153862, 5.925156631746704, 9.327595501811919, 5.878676545746904, 33.684723297905684, 5.09414807414275, 7.592922303284284, 8.072522645551366, 5.393222752271257, 15.244082532875614, 5.067154192261851, 10.947256641385929, 5.872489222004397, 8.882058155322932, 5.028421945077664, 23.727075881361696, 27.35613889158577, 15.610716684050024, 15.625595803818022, 17.539513758003913, 23.82164043995423, 15.404907310264324, 16.60935892630696, 44.70582571210496, 39.431264993998425, 10.798189227625702, 20.028929001628573, 21.063216615244155, 24.417098536086087, 31.369253659916016, 41.99383563961557, 33.30863308429251, 21.625599574594943, 26.101176843682563, 26.474357418505924, 40.873322702218616, 66.02798791601829, 127.72546410819763, 38.51504482422862, 40.17876826548477, 50.768716523116254, 27.025665530529864, 34.32579612488085, 35.93893251903977, 47.717822222332465, 57.86959698517219, 82.78765560811861, 45.82474572798878, 43.145646577120104, 53.65820748934756, 38.139847994760565, 47.31149666459976, 58.72281836097142, 48.05344097436579, 47.65065751590737, 42.84581996833569, 94.52326901076634, 134.18205376336138, 68.00748112471017, 71.01636397697048, 59.8235973624643, 65.22413517760174, 88.1055580334661, 55.59079876854557, 99.84699888246318, 56.43144228943766, 55.61522138529638, 66.82921524014338, 69.0904402145642, 59.592445409113274, 60.11920300801475, 54.32880921118747, 68.09038078640772, 64.18769861414106], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -7.7159, -7.4138, -6.72, -7.3985, -7.6801, -7.4098, -7.5395, -8.4143, -8.4845, -7.9344, -6.1692, -7.0552, -7.0687, -6.8676, -8.3628, -7.6664, -7.5638, -7.5805, -7.4482, -8.5852, -8.4719, -7.6603, -7.9509, -7.986, -8.4033, -7.578, -8.0204, -7.6741, -7.8353, -7.9597, -6.4821, -7.2825, -6.591, -6.8638, -6.9506, -7.4926, -6.168, -6.5399, -6.1332, -6.5019, -6.886, -6.3248, -7.1272, -6.9477, -7.1636, -6.6712, -7.0357, -5.9518, -7.0215, -6.7032, -6.7424, -6.8335, -6.5326, -6.7854, -6.759, -6.8882, -6.9011, -6.6387, -6.6417, -6.6189, -6.8746, -6.7485, -6.6669, -6.2675, -6.7006, -6.7422, -6.7901, -6.8024, -6.8678, -6.4453, -7.6544, -7.2464, -7.1866, -6.9005, -8.6123, -8.4054, -7.4873, -7.1481, -7.6576, -8.1235, -6.5505, -8.1861, -6.9923, -6.8849, -7.6843, -8.3345, -6.511, -8.2601, -8.1587, -7.912, -8.2432, -7.7301, -8.7649, -7.6797, -7.5146, -7.1206, -6.8521, -8.2252, -8.1145, -7.1108, -7.5765, -6.9577, -7.188, -6.6804, -7.0196, -7.2354, -6.7593, -6.9549, -5.8813, -7.4519, -7.0495, -7.0316, -6.7766, -7.0633, -6.5592, -6.5731, -7.0369, -6.8235, -6.8664, -6.3437, -6.7535, -6.814, -6.6692, -6.9416, -6.694, -6.5404, -6.6714, -6.7229, -6.814, -6.5218, -6.7374, -6.6041, -6.4649, -6.7973, -6.8265, -6.7935, -6.811, -6.8687, -8.1028, -7.6062, -8.753, -6.6238, -7.7154, -7.3923, -8.1, -6.8411, -7.9858, -8.1206, -8.4652, -7.0984, -7.7602, -8.2461, -8.1288, -6.7164, -8.8028, -8.7921, -8.0318, -8.561, -8.2345, -8.0773, -8.5654, -8.1198, -7.8252, -7.2256, -8.4412, -7.3925, -8.4229, -8.5826, -7.4352, -7.4943, -7.5711, -7.3193, -5.8172, -5.7728, -6.9516, -6.9151, -6.8918, -7.027, -7.2843, -7.2451, -6.7931, -7.1644, -6.7927, -6.8415, -6.9164, -6.6964, -6.8753, -6.6466, -6.5651, -6.677, -6.9772, -6.5839, -6.8849, -6.7135, -6.6014, -7.0678, -6.599, -6.7458, -6.9521, -6.8781, -6.809, -6.7075, -6.4529, -6.5573, -6.4456, -6.6662, -6.695, -6.7428, -6.686, -6.7925, -6.8351, -6.8478, -6.8319, -7.4522, -8.6393, -8.0875, -7.5993, -6.8683, -7.6733, -8.3421, -8.013, -7.2229, -7.1163, -7.5351, -8.0415, -8.1939, -8.2028, -7.5823, -7.7679, -7.3248, -8.3308, -6.9206, -8.2225, -8.4934, -8.0761, -7.8039, -8.8387, -8.1745, -6.8816, -7.905, -8.3502, -7.4863, -8.4807, -7.6362, -7.2263, -7.0209, -7.0746, -7.1235, -7.078, -7.1653, -7.5264, -5.8096, -6.8311, -7.225, -7.4865, -6.7108, -6.7122, -6.9357, -7.0415, -7.2598, -6.6581, -7.1582, -7.163, -7.0148, -6.6107, -7.0395, -6.8732, -6.8736, -6.1201, -6.805, -7.0171, -6.3468, -7.0043, -6.7594, -6.9818, -6.9303, -6.6819, -6.5557, -6.5987, -6.7651, -6.5911, -6.9194, -6.8525, -6.8698, -6.8542, -6.8997, -6.8802, -6.8883, -6.8403, -6.873, -6.9102, -6.9165, -7.2177, -8.1864, -8.4634, -6.9998, -7.6715, -7.7968, -7.1738, -6.4599, -7.9555, -7.2177, -7.0796, -7.961, -8.3785, -6.9593, -8.0101, -7.4253, -8.4223, -8.3995, -6.6709, -7.7394, -8.076, -7.6546, -8.1097, -8.6155, -8.1514, -7.798, -8.6082, -7.1616, -6.9962, -7.1151, -7.1058, -7.4703, -7.1542, -6.7263, -7.1074, -7.2078, -7.646, -6.8791, -7.3649, -6.8125, -7.1792, -6.8227, -6.9369, -6.9368, -7.0838, -6.8827, -6.665, -6.9072, -6.7357, -7.2174, -6.4049, -7.0418, -6.7172, -6.8468, -6.2088, -6.1932, -6.4317, -6.5428, -6.4542, -6.9029, -6.8185, -6.8991, -6.8433, -6.8521, -6.8687, -6.8244, -6.8286, -6.841, -6.8343, -6.8715, -6.8442, -8.1911, -8.6808, -7.7267, -7.8191, -8.3897, -7.5724, -8.1333, -7.2277, -7.9438, -7.2071, -7.6589, -8.5096, -8.3411, -7.5085, -8.2535, -7.5861, -8.6616, -8.5796, -8.1461, -8.4343, -8.2236, -8.045, -8.6639, -8.7839, -8.8044, -7.7889, -8.692, -8.3152, -8.5939, -8.5923, -8.1698, -7.0723, -6.7457, -6.5943, -6.6204, -7.3122, -7.5771, -7.7666, -7.3665, -5.8137, -7.0924, -5.8799, -6.9292, -7.0843, -6.6725, -7.2527, -7.0572, -7.4629, -7.0941, -6.583, -7.2111, -6.5539, -7.162, -6.8847, -6.6819, -7.0942, -6.9529, -6.8902, -6.9573, -6.8514, -6.8227, -6.4009, -7.0168, -6.7146, -6.7015, -6.9472, -6.4858, -6.9121, -6.7395, -6.7675, -6.6521, -6.881, -6.9318, -6.9094, -6.9258, -6.9086, -6.8603, -6.8932, -6.9183, -7.4166, -7.4436, -8.4027, -8.3333, -7.9389, -7.9236, -8.4643, -8.0806, -7.3087, -8.6652, -8.3929, -8.557, -7.2842, -8.4824, -8.1266, -6.9381, -8.6843, -8.7005, -8.7241, -7.3456, -8.8054, -7.2686, -8.825, -7.5602, -8.5435, -6.8248, -8.9252, -7.162, -8.0746, -7.8318, -6.9974, -7.7553, -7.2427, -7.4219, -6.9748, -6.9141, -7.4134, -7.1035, -6.5573, -7.61, -7.3111, -7.4185, -7.515, -7.0721, -7.3037, -6.6378, -6.9422, -7.2471, -7.0989, -6.8764, -7.1343, -6.9163, -6.8217, -6.3112, -6.915, -6.9942, -6.1523, -6.6213, -7.0448, -6.7536, -7.0388, -6.6895, -6.8495, -6.9504, -6.522, -6.8186, -6.7404, -6.7506, -6.8498, -6.9009, -6.6701, -6.921, -6.8042, -6.7976, -6.7998, -6.4935, -6.8479, -6.8207, -6.8353, -6.8338, -7.2827, -7.5252, -7.1901, -8.3831, -8.4452, -7.2391, -8.1661, -7.2005, -8.4886, -8.5663, -8.3351, -8.5152, -7.5867, -8.1317, -8.6765, -8.1726, -8.9063, -8.6071, -8.2249, -7.6222, -7.4515, -8.3998, -8.3699, -8.4528, -7.1591, -8.7543, -8.201, -7.4319, -8.577, -7.7068, -7.2631, -7.2817, -7.2934, -7.5552, -7.3345, -6.6757, -7.2696, -7.1542, -7.7215, -7.3558, -6.1852, -6.9186, -7.0155, -6.9914, -6.727, -6.7942, -6.9362, -7.1625, -6.923, -6.7245, -6.3524, -6.7871, -7.0941, -6.1329, -7.004, -6.7151, -6.1935, -6.6352, -6.8042, -6.836, -6.771, -6.8618, -6.9317, -7.0, -7.0289, -6.944, -6.9979, -6.8319, -6.7976, -6.854, -6.8021, -6.9473, -6.8851, -6.8441, -6.6835, -6.8994, -6.8948, -6.8729, -6.8681, -6.8569, -6.8898, -8.5654, -8.5405, -8.2507, -8.0143, -8.3113, -8.8582, -8.4163, -7.9128, -8.7335, -8.5065, -8.8769, -7.6217, -8.6451, -8.112, -8.9044, -8.7643, -8.7587, -8.3065, -8.7694, -7.0266, -8.9161, -8.5172, -8.4623, -8.8674, -7.8313, -8.936, -8.1665, -8.7922, -8.3788, -8.9501, -7.4011, -7.2654, -7.8209, -7.8227, -7.7095, -7.4148, -7.8381, -7.7698, -6.8523, -6.9715, -8.1898, -7.6137, -7.5716, -7.4479, -7.2221, -6.9614, -7.1719, -7.5629, -7.398, -7.3913, -7.0157, -6.6034, -6.0601, -7.0793, -7.048, -6.8573, -7.3743, -7.18, -7.1464, -6.9358, -6.7837, -6.5036, -6.9827, -7.0358, -6.8729, -7.1298, -6.9711, -6.8234, -6.9668, -6.983, -7.0596, -6.5249, -6.3148, -6.7588, -6.7487, -6.8578, -6.8193, -6.6556, -6.91, -6.606, -6.9026, -6.9272, -6.8563, -6.866, -6.9263, -6.9253, -6.9564, -6.9245, -6.9525], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.4426, 0.3044, 0.3004, 0.2847, 0.283, 0.2818, 0.2789, 0.2727, 0.2712, 0.2672, 0.2669, 0.2662, 0.2642, 0.2602, 0.2582, 0.2563, 0.256, 0.2501, 0.2496, 0.2468, 0.2463, 0.2437, 0.2434, 0.2419, 0.2412, 0.2364, 0.235, 0.2347, 0.2327, 0.2305, 0.2304, 0.2296, 0.2127, 0.2178, 0.2169, 0.2277, 0.1979, 0.197, 0.1779, 0.192, 0.2077, 0.1736, 0.2136, 0.2029, 0.2131, 0.1775, 0.2037, 0.113, 0.2023, 0.166, 0.1538, 0.1664, 0.1192, 0.1553, 0.1376, 0.1643, 0.1611, 0.0843, 0.0845, 0.0603, 0.1468, 0.0934, 0.0577, -0.252, -0.0055, 0.0107, 0.0282, 0.0209, 0.0257, 0.6361, 0.4186, 0.4035, 0.3775, 0.3584, 0.3571, 0.3519, 0.3486, 0.3425, 0.3416, 0.3399, 0.3312, 0.3244, 0.3225, 0.3212, 0.319, 0.3172, 0.3161, 0.316, 0.313, 0.3114, 0.2976, 0.2972, 0.295, 0.2938, 0.2908, 0.2883, 0.2874, 0.2826, 0.2779, 0.2723, 0.2764, 0.2675, 0.2664, 0.2392, 0.2509, 0.2509, 0.215, 0.2291, 0.1342, 0.2668, 0.2217, 0.2146, 0.1747, 0.2102, 0.12, 0.1219, 0.1945, 0.1467, 0.1545, -0.0327, 0.103, 0.1181, 0.057, 0.1599, 0.0428, -0.042, -0.0196, 0.0017, 0.0652, -0.1559, -0.0144, -0.168, -0.4001, -0.0444, -0.0081, -0.0809, -0.1172, -0.0268, 0.4603, 0.3954, 0.3805, 0.3711, 0.3628, 0.3625, 0.3589, 0.3587, 0.3565, 0.3565, 0.349, 0.3489, 0.3483, 0.3373, 0.3354, 0.3343, 0.3245, 0.3242, 0.3213, 0.3154, 0.3145, 0.3099, 0.3094, 0.308, 0.3037, 0.3026, 0.3023, 0.2998, 0.2994, 0.2986, 0.2979, 0.2958, 0.2939, 0.2913, 0.2476, 0.2427, 0.2729, 0.2718, 0.2696, 0.271, 0.2798, 0.2769, 0.2321, 0.2526, 0.2167, 0.2169, 0.2124, 0.1828, 0.205, 0.1718, 0.1579, 0.1694, 0.2172, 0.1407, 0.1905, 0.143, 0.0936, 0.221, 0.0803, 0.096, 0.1723, 0.1422, 0.1107, 0.0454, -0.087, -0.0589, -0.1346, -0.0144, -0.0012, -0.0166, -0.2499, -0.0799, 0.0137, 0.0488, -0.0951, 0.4581, 0.4101, 0.4048, 0.4024, 0.3974, 0.3923, 0.3817, 0.3742, 0.3735, 0.3613, 0.3538, 0.3474, 0.3473, 0.3473, 0.3468, 0.3427, 0.3418, 0.336, 0.3354, 0.3321, 0.3291, 0.3284, 0.3277, 0.3268, 0.3266, 0.3265, 0.3151, 0.3147, 0.3115, 0.3108, 0.3055, 0.2984, 0.2866, 0.2825, 0.2805, 0.2759, 0.28, 0.2978, 0.2059, 0.2588, 0.2817, 0.2954, 0.2258, 0.2199, 0.2398, 0.2468, 0.2677, 0.1884, 0.2525, 0.2523, 0.2234, 0.1421, 0.2241, 0.1749, 0.1687, -0.0552, 0.1357, 0.2032, -0.0358, 0.1804, 0.0639, 0.1683, 0.1338, -0.0302, -0.1196, -0.1003, -0.0389, -0.2253, 0.101, 0.0167, 0.0268, 0.0022, 0.0484, 0.0133, -0.0091, -0.1277, -0.1791, -0.0683, -0.2215, 0.4826, 0.4483, 0.4456, 0.4411, 0.4191, 0.4052, 0.3958, 0.3865, 0.3851, 0.3835, 0.3824, 0.3803, 0.3781, 0.3746, 0.3738, 0.3724, 0.3698, 0.369, 0.3661, 0.3653, 0.3538, 0.3537, 0.3495, 0.3462, 0.3436, 0.3431, 0.343, 0.3405, 0.3402, 0.3394, 0.3389, 0.3308, 0.321, 0.2945, 0.3013, 0.3049, 0.3275, 0.2769, 0.3069, 0.2459, 0.2802, 0.2267, 0.2386, 0.2384, 0.2569, 0.2101, 0.1583, 0.2073, 0.1578, 0.2655, 0.0312, 0.2142, 0.1011, 0.1406, -0.144, -0.1777, -0.0659, -0.0444, -0.1432, 0.1442, 0.0777, 0.1371, 0.0259, 0.0044, 0.0106, -0.1015, -0.1493, -0.1164, -0.1405, -0.0443, -0.1924, 0.4833, 0.4532, 0.4341, 0.4309, 0.4283, 0.4279, 0.422, 0.4171, 0.4129, 0.3986, 0.3976, 0.3944, 0.3857, 0.3844, 0.3809, 0.3767, 0.3764, 0.3751, 0.3748, 0.3735, 0.3735, 0.3674, 0.3673, 0.3664, 0.3647, 0.3521, 0.3499, 0.3487, 0.3475, 0.3447, 0.3447, 0.3253, 0.3117, 0.2992, 0.2993, 0.3204, 0.326, 0.3274, 0.3044, 0.2018, 0.2798, 0.1849, 0.2563, 0.2665, 0.2238, 0.2777, 0.2526, 0.2968, 0.2451, 0.1699, 0.2563, 0.1411, 0.2468, 0.1913, 0.1414, 0.2247, 0.1786, 0.1591, 0.1718, 0.136, 0.1254, -0.0351, 0.1621, 0.0084, -0.0077, 0.1107, -0.1747, 0.0878, -0.0602, -0.0429, -0.2159, -0.0117, 0.035, -0.0301, -0.0693, -0.1718, -0.3619, -0.2415, -0.1922, 0.508, 0.4494, 0.4292, 0.4111, 0.4024, 0.3886, 0.3815, 0.38, 0.3729, 0.3693, 0.3678, 0.3661, 0.3643, 0.3626, 0.3616, 0.3574, 0.3563, 0.3527, 0.3505, 0.3466, 0.3459, 0.3457, 0.3442, 0.3428, 0.3407, 0.34, 0.3391, 0.3361, 0.3346, 0.3342, 0.33, 0.3315, 0.3244, 0.3217, 0.3125, 0.3028, 0.3129, 0.2942, 0.266, 0.3152, 0.2946, 0.3009, 0.3071, 0.2671, 0.2872, 0.2087, 0.2405, 0.2749, 0.2518, 0.1876, 0.2251, 0.1735, 0.1484, -0.0002, 0.1666, 0.181, -0.0875, 0.0579, 0.1953, 0.0736, 0.1857, 0.0335, 0.1017, 0.1433, -0.1562, 0.0379, -0.0279, -0.0245, 0.0295, 0.0659, -0.1717, 0.0786, -0.0513, -0.0607, -0.0752, -0.4781, -0.0442, -0.1268, -0.1403, -0.182, 0.4935, 0.4832, 0.4817, 0.4589, 0.4559, 0.4391, 0.4389, 0.438, 0.4193, 0.4092, 0.4004, 0.3939, 0.3928, 0.3899, 0.3889, 0.3888, 0.3869, 0.3771, 0.3763, 0.3754, 0.3706, 0.3631, 0.3627, 0.3576, 0.3569, 0.3554, 0.3543, 0.3486, 0.348, 0.3478, 0.3432, 0.3407, 0.3397, 0.3381, 0.3208, 0.2911, 0.3153, 0.3006, 0.3296, 0.2992, 0.1806, 0.2489, 0.2547, 0.2487, 0.205, 0.2006, 0.2198, 0.2528, 0.206, 0.1689, 0.0838, 0.1494, 0.221, -0.0681, 0.1904, 0.0885, -0.178, 0.0166, 0.0925, 0.1048, 0.0473, 0.0895, 0.1305, 0.1648, 0.1814, 0.1139, 0.1522, -0.0087, -0.0608, -0.0053, -0.0759, 0.0998, 0.0112, -0.0912, -0.3725, -0.0202, -0.0483, -0.1483, -0.173, -0.3585, -0.2106, 0.5071, 0.4606, 0.4387, 0.4361, 0.436, 0.4312, 0.4262, 0.4204, 0.4116, 0.3881, 0.388, 0.3866, 0.3851, 0.3846, 0.3806, 0.3788, 0.3768, 0.3752, 0.3739, 0.3711, 0.3705, 0.3703, 0.3639, 0.3621, 0.3592, 0.3559, 0.3551, 0.3522, 0.3518, 0.3494, 0.347, 0.3403, 0.3458, 0.3431, 0.3407, 0.3293, 0.3419, 0.3349, 0.2623, 0.2687, 0.3455, 0.3038, 0.2956, 0.2715, 0.2468, 0.2157, 0.2369, 0.2779, 0.2547, 0.2472, 0.1885, 0.1212, 0.0047, 0.1843, 0.1734, 0.1301, 0.2436, 0.1988, 0.1865, 0.1136, 0.0728, -0.0052, 0.1072, 0.1143, 0.0591, 0.1436, 0.0869, 0.0185, 0.0756, 0.0678, 0.0974, -0.1591, -0.2993, -0.0637, -0.0969, -0.0345, -0.0824, -0.2194, -0.0134, -0.295, -0.021, -0.031, -0.1438, -0.1867, -0.0991, -0.107, -0.0368, -0.2306, -0.1996]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8], \"Freq\": [0.335687282730602, 0.25176546204795147, 0.167843641365301, 0.0839218206826505, 0.0839218206826505, 0.04196091034132525, 0.04196091034132525, 0.04196091034132525, 0.35066183337526846, 0.19127009093196462, 0.15939174244330384, 0.09563504546598231, 0.09563504546598231, 0.031878348488660765, 0.031878348488660765, 0.031878348488660765, 0.3221403286757527, 0.24780025282750207, 0.12390012641375103, 0.07434007584825063, 0.07434007584825063, 0.04956005056550041, 0.04956005056550041, 0.04956005056550041, 0.2652918108903666, 0.2652918108903666, 0.1326459054451833, 0.1326459054451833, 0.1326459054451833, 0.33452284005094407, 0.20907677503184002, 0.14635374252228803, 0.08363071001273602, 0.10453838751592001, 0.04181535500636801, 0.04181535500636801, 0.04181535500636801, 0.3358290970836, 0.20989318567725, 0.12593591140635, 0.0839572742709, 0.0839572742709, 0.04197863713545, 0.04197863713545, 0.04197863713545, 0.2793344225688645, 0.2793344225688645, 0.09311147418962148, 0.09311147418962148, 0.09311147418962148, 0.29300638902484194, 0.20929027787488708, 0.18836125008739837, 0.12557416672493224, 0.08371611114995484, 0.04185805557497742, 0.04185805557497742, 0.04185805557497742, 0.3110774372108624, 0.17775853554906423, 0.17775853554906423, 0.08887926777453212, 0.13331890166179816, 0.04443963388726606, 0.04443963388726606, 0.04443963388726606, 0.28590760324379033, 0.28590760324379033, 0.14295380162189517, 0.14295380162189517, 0.14295380162189517, 0.3291679018859347, 0.21944526792395647, 0.14629684528263764, 0.10972263396197823, 0.07314842264131882, 0.03657421132065941, 0.03657421132065941, 0.03657421132065941, 0.36588429637559267, 0.2152260566915251, 0.1721808453532201, 0.06456781700745753, 0.06456781700745753, 0.04304521133830502, 0.04304521133830502, 0.02152260566915251, 0.29849373965348164, 0.2132098140382012, 0.2132098140382012, 0.08528392561528048, 0.08528392561528048, 0.04264196280764024, 0.04264196280764024, 0.04264196280764024, 0.25962566872702086, 0.2336631018543188, 0.18173796810891463, 0.12981283436351043, 0.10385026749080835, 0.051925133745404174, 0.051925133745404174, 0.025962566872702087, 0.3532402579283713, 0.24285267732575527, 0.11038758060261604, 0.08831006448209283, 0.08831006448209283, 0.044155032241046416, 0.044155032241046416, 0.022077516120523208, 0.3675856358029177, 0.16708437991041714, 0.16708437991041714, 0.06683375196416685, 0.10025062794625028, 0.03341687598208343, 0.03341687598208343, 0.06683375196416685, 0.26050689462196963, 0.13025344731098482, 0.26050689462196963, 0.13025344731098482, 0.13025344731098482, 0.23825129464414813, 0.23825129464414813, 0.17868847098311108, 0.11912564732207406, 0.11912564732207406, 0.05956282366103703, 0.05956282366103703, 0.5082799282885031, 0.12706998207212578, 0.12706998207212578, 0.06353499103606289, 0.12706998207212578, 0.06353499103606289, 0.06353499103606289, 0.2800732061472471, 0.2178347158923033, 0.1555962256373595, 0.0933577353824157, 0.1244769805098876, 0.0311192451274719, 0.0311192451274719, 0.0311192451274719, 0.19435152860274227, 0.19435152860274227, 0.19435152860274227, 0.09717576430137113, 0.09717576430137113, 0.3048850342320504, 0.1524425171160252, 0.1524425171160252, 0.0762212585580126, 0.1524425171160252, 0.0762212585580126, 0.0762212585580126, 0.21122012088543501, 0.26402515110679375, 0.15841509066407625, 0.10561006044271751, 0.10561006044271751, 0.052805030221358754, 0.052805030221358754, 0.31369886247014, 0.26141571872511665, 0.15684943123507, 0.078424715617535, 0.078424715617535, 0.05228314374502334, 0.02614157187251167, 0.02614157187251167, 0.19701342152647328, 0.2955201322897099, 0.19701342152647328, 0.09850671076323664, 0.09850671076323664, 0.09850671076323664, 0.3759929988721474, 0.20679614937968108, 0.11279789966164422, 0.11279789966164422, 0.07519859977442948, 0.03759929988721474, 0.03759929988721474, 0.03759929988721474, 0.2524443477800407, 0.2524443477800407, 0.12622217389002036, 0.12622217389002036, 0.12622217389002036, 0.2981836469877676, 0.24227421317756118, 0.1490918234938838, 0.11181886762041285, 0.09318238968367737, 0.03727295587347095, 0.03727295587347095, 0.03727295587347095, 0.38207722166641844, 0.19103861083320922, 0.12735907388880613, 0.06367953694440306, 0.06367953694440306, 0.06367953694440306, 0.06367953694440306, 0.06367953694440306, 0.2169459312924276, 0.27118241411553445, 0.16270944846932067, 0.1084729656462138, 0.0542364828231069, 0.0542364828231069, 0.0542364828231069, 0.0542364828231069, 0.2807338207485923, 0.2807338207485923, 0.14036691037429616, 0.14036691037429616, 0.14036691037429616, 0.29511561847296236, 0.14755780923648118, 0.14755780923648118, 0.14755780923648118, 0.14755780923648118, 0.2842376470142277, 0.1894917646761518, 0.23686470584518976, 0.0947458823380759, 0.0947458823380759, 0.04737294116903795, 0.04737294116903795, 0.04737294116903795, 0.29701158620401324, 0.21215113300286662, 0.2545813596034399, 0.08486045320114664, 0.08486045320114664, 0.04243022660057332, 0.04243022660057332, 0.04243022660057332, 0.3193501429357406, 0.186287583379182, 0.1596750714678703, 0.13306255955655857, 0.07983753573393515, 0.05322502382262343, 0.026612511911311715, 0.026612511911311715, 0.28648894807222197, 0.28648894807222197, 0.163707970326984, 0.081853985163492, 0.081853985163492, 0.040926992581746, 0.040926992581746, 0.040926992581746, 0.3571952828678861, 0.1905041508628726, 0.1905041508628726, 0.0952520754314363, 0.07143905657357723, 0.04762603771571815, 0.023813018857859074, 0.023813018857859074, 0.3292974034965984, 0.1920901520396824, 0.1646487017482992, 0.1097658011655328, 0.1097658011655328, 0.0548829005827664, 0.0274414502913832, 0.0274414502913832, 0.265044675102405, 0.17669645006826998, 0.17669645006826998, 0.08834822503413499, 0.08834822503413499, 0.08834822503413499, 0.29096781796730614, 0.22630830286346032, 0.16164878775961453, 0.0969892726557687, 0.12931903020769162, 0.032329757551922904, 0.032329757551922904, 0.032329757551922904, 0.3022028057703137, 0.18132168346218822, 0.24176224461625095, 0.06044056115406274, 0.12088112230812548, 0.06044056115406274, 0.06044056115406274, 0.06044056115406274, 0.2850849542876902, 0.19955946800138316, 0.17105097257261415, 0.1425424771438451, 0.08552548628630707, 0.057016990857538044, 0.028508495428769022, 0.028508495428769022, 0.22119790727927624, 0.22119790727927624, 0.18433158939939687, 0.11059895363963812, 0.11059895363963812, 0.03686631787987937, 0.03686631787987937, 0.03686631787987937, 0.31704767461359057, 0.23250162804996644, 0.1690920931272483, 0.08454604656362415, 0.08454604656362415, 0.042273023281812074, 0.021136511640906037, 0.042273023281812074, 0.3934808550535128, 0.1967404275267564, 0.1311602850178376, 0.0655801425089188, 0.0655801425089188, 0.24375879633139033, 0.1625058642209269, 0.1625058642209269, 0.1625058642209269, 0.08125293211046344, 0.08125293211046344, 0.3431958162236856, 0.1715979081118428, 0.2573968621677642, 0.0857989540559214, 0.0857989540559214, 0.25623423196751305, 0.25623423196751305, 0.1921756739756348, 0.06405855799187826, 0.12811711598375652, 0.06405855799187826, 0.06405855799187826, 0.26371659361664274, 0.21976382801386896, 0.21976382801386896, 0.08790553120554759, 0.08790553120554759, 0.043952765602773794, 0.043952765602773794, 0.043952765602773794, 0.3940704331382869, 0.14777641242685757, 0.14777641242685757, 0.09851760828457172, 0.04925880414228586, 0.04925880414228586, 0.04925880414228586, 0.04925880414228586, 0.2691585674715699, 0.2691585674715699, 0.13457928373578495, 0.13457928373578495, 0.13457928373578495, 0.3801348379888589, 0.15205393519554355, 0.17739625772813417, 0.10136929013036237, 0.07602696759777178, 0.05068464506518119, 0.025342322532590594, 0.025342322532590594, 0.3271654920398335, 0.20253101888180172, 0.17137240059229375, 0.10905516401327785, 0.07789654572376989, 0.04673792743426194, 0.031158618289507955, 0.031158618289507955, 0.27192051957906005, 0.19034436370534202, 0.16315231174743602, 0.10876820783162401, 0.10876820783162401, 0.054384103915812006, 0.054384103915812006, 0.027192051957906003, 0.31929553228600166, 0.21286368819066778, 0.21286368819066778, 0.10643184409533389, 0.10643184409533389, 0.10643184409533389, 0.33616829991275626, 0.19209617137871787, 0.19209617137871787, 0.0720360642670192, 0.09604808568935894, 0.04802404284467947, 0.024012021422339734, 0.024012021422339734, 0.31431016881482277, 0.18858610128889366, 0.18858610128889366, 0.09429305064444683, 0.06286203376296455, 0.031431016881482275, 0.031431016881482275, 0.06286203376296455, 0.3154808882075225, 0.19717555512970159, 0.15774044410376126, 0.11830533307782096, 0.07887022205188063, 0.039435111025940314, 0.039435111025940314, 0.039435111025940314, 0.3407939421391846, 0.1703969710695923, 0.1703969710695923, 0.1703969710695923, 0.1703969710695923, 0.30215577026075957, 0.18129346215645575, 0.15107788513037979, 0.12086230810430383, 0.12086230810430383, 0.030215577026075958, 0.030215577026075958, 0.060431154052151916, 0.29413199895037506, 0.29413199895037506, 0.14706599947518753, 0.09804399965012503, 0.07353299973759377, 0.024510999912531257, 0.024510999912531257, 0.024510999912531257, 0.26584195309110953, 0.21267356247288763, 0.15950517185466573, 0.10633678123644381, 0.10633678123644381, 0.05316839061822191, 0.05316839061822191, 0.05316839061822191, 0.2968068832455465, 0.2374455065964372, 0.1187227532982186, 0.1187227532982186, 0.1187227532982186, 0.0593613766491093, 0.0593613766491093, 0.28517405955618313, 0.19011603970412208, 0.19011603970412208, 0.09505801985206104, 0.09505801985206104, 0.09505801985206104, 0.09505801985206104, 0.3330616191591755, 0.16653080957958774, 0.13322464766367018, 0.09991848574775264, 0.13322464766367018, 0.033306161915917544, 0.033306161915917544, 0.033306161915917544, 0.30103509847575644, 0.18062105908545387, 0.18062105908545387, 0.060207019695151284, 0.12041403939030257, 0.060207019695151284, 0.060207019695151284, 0.060207019695151284, 0.28129059083417335, 0.23440882569514446, 0.21096794312563, 0.11720441284757223, 0.07032264770854334, 0.023440882569514446, 0.023440882569514446, 0.023440882569514446, 0.2760966091064477, 0.2760966091064477, 0.1840644060709651, 0.07362576242838605, 0.07362576242838605, 0.05521932182128953, 0.03681288121419302, 0.01840644060709651, 0.4015204354136261, 0.20076021770681304, 0.1505701632801098, 0.05019005442670326, 0.10038010885340652, 0.05019005442670326, 0.05019005442670326, 0.36698753632735115, 0.19572668604125393, 0.1712608502860972, 0.07339750726547023, 0.09786334302062696, 0.02446583575515674, 0.02446583575515674, 0.02446583575515674, 0.32828059771680185, 0.1969683586300811, 0.15319761226784084, 0.08754149272448049, 0.1094268659056006, 0.043770746362240244, 0.043770746362240244, 0.021885373181120122, 0.29502160464276606, 0.2528756611223709, 0.21072971760197576, 0.0842918870407903, 0.0842918870407903, 0.04214594352039515, 0.04214594352039515, 0.04214594352039515, 0.2606941072050734, 0.2606941072050734, 0.17379607147004894, 0.08689803573502447, 0.08689803573502447, 0.08689803573502447, 0.28342858786307507, 0.18036364682195688, 0.18036364682195688, 0.12883117630139776, 0.12883117630139776, 0.05153247052055911, 0.05153247052055911, 0.025766235260279553, 0.2790016617100761, 0.15942952097718635, 0.23914428146577954, 0.07971476048859318, 0.11957214073288977, 0.03985738024429659, 0.03985738024429659, 0.03985738024429659, 0.2938487289592112, 0.183655455599507, 0.2203865467194084, 0.0734621822398028, 0.1101932733597042, 0.0367310911199014, 0.0367310911199014, 0.0367310911199014, 0.2596404086628725, 0.3894606129943088, 0.12982020433143626, 0.06491010216571813, 0.06491010216571813, 0.021636700721906044, 0.021636700721906044, 0.021636700721906044, 0.2517009886712352, 0.2517009886712352, 0.1258504943356176, 0.1258504943356176, 0.1258504943356176, 0.31005504048983096, 0.13288073163849898, 0.13288073163849898, 0.13288073163849898, 0.13288073163849898, 0.044293577212832995, 0.044293577212832995, 0.044293577212832995, 0.3016983018938401, 0.2514152515782001, 0.15084915094692006, 0.10056610063128005, 0.07542457547346003, 0.050283050315640024, 0.050283050315640024, 0.050283050315640024, 0.4021035294342431, 0.18277433156101958, 0.10966459893661175, 0.10966459893661175, 0.10966459893661175, 0.036554866312203914, 0.036554866312203914, 0.036554866312203914, 0.30551178795628536, 0.17457816454644878, 0.19640043511475486, 0.13093362340983658, 0.08728908227322439, 0.021822270568306098, 0.043644541136612196, 0.043644541136612196, 0.31930024185207107, 0.1719308994588075, 0.1719308994588075, 0.12280778532771963, 0.0982462282621757, 0.04912311413108785, 0.04912311413108785, 0.04912311413108785, 0.25330051126453224, 0.1899753834483992, 0.1899753834483992, 0.12665025563226612, 0.12665025563226612, 0.03166256390806653, 0.03166256390806653, 0.03166256390806653, 0.31731613215261145, 0.21154408810174097, 0.14102939206782733, 0.10577204405087048, 0.14102939206782733, 0.03525734801695683, 0.03525734801695683, 0.03525734801695683, 0.3144145717669453, 0.19650910735434082, 0.15720728588347266, 0.07860364294173633, 0.07860364294173633, 0.039301821470868165, 0.039301821470868165, 0.039301821470868165, 0.2966139495277675, 0.23069973852159692, 0.09887131650925582, 0.09887131650925582, 0.1318284220123411, 0.032957105503085275, 0.032957105503085275, 0.032957105503085275, 0.28166619159763145, 0.1877774610650876, 0.1877774610650876, 0.0938887305325438, 0.0938887305325438, 0.21724025162719193, 0.21724025162719193, 0.21724025162719193, 0.16293018872039394, 0.10862012581359597, 0.05431006290679798, 0.05431006290679798, 0.05431006290679798, 0.26846651862485427, 0.17897767908323617, 0.17897767908323617, 0.17897767908323617, 0.08948883954161808, 0.08948883954161808, 0.3087202873852322, 0.21224519757734717, 0.17365516165419315, 0.07718007184630805, 0.09647508980788508, 0.03859003592315403, 0.03859003592315403, 0.03859003592315403, 0.3084986467747646, 0.19631732067485017, 0.14022665762489298, 0.11218132609991438, 0.11218132609991438, 0.028045331524978595, 0.028045331524978595, 0.028045331524978595, 0.19734943166464508, 0.19734943166464508, 0.19734943166464508, 0.19734943166464508, 0.3216262968754637, 0.21441753125030913, 0.21441753125030913, 0.10720876562515456, 0.10720876562515456, 0.38205128036249186, 0.19102564018124593, 0.16980056904999638, 0.06367521339374865, 0.08490028452499819, 0.021225071131249548, 0.021225071131249548, 0.042450142262499095, 0.2907305260351727, 0.19382035069011513, 0.19382035069011513, 0.09691017534505757, 0.09691017534505757, 0.048455087672528784, 0.024227543836264392, 0.048455087672528784, 0.23107853897908492, 0.23107853897908492, 0.11553926948954246, 0.11553926948954246, 0.11553926948954246, 0.28324989200914197, 0.18883326133942796, 0.09441663066971398, 0.09441663066971398, 0.09441663066971398, 0.27311197874709336, 0.23409598178322288, 0.15606398785548192, 0.11704799089161144, 0.07803199392774096, 0.03901599696387048, 0.03901599696387048, 0.03901599696387048, 0.44996587114417397, 0.16362395314333597, 0.12271796485750198, 0.12271796485750198, 0.08181197657166799, 0.04090598828583399, 0.04090598828583399, 0.04090598828583399, 0.340894630532513, 0.20832449643653572, 0.1515087246811169, 0.09469295292569806, 0.09469295292569806, 0.037877181170279224, 0.037877181170279224, 0.018938590585139612, 0.3537727924430778, 0.16648131409086014, 0.16648131409086014, 0.12486098556814511, 0.08324065704543007, 0.041620328522715036, 0.041620328522715036, 0.041620328522715036, 0.3328969960036761, 0.23158051895907902, 0.17368538921930926, 0.057895129739769756, 0.08684269460965463, 0.043421347304827315, 0.043421347304827315, 0.028947564869884878, 0.21388644185408381, 0.23765160206009311, 0.19012128164807449, 0.09506064082403724, 0.11882580103004656, 0.04753032041201862, 0.04753032041201862, 0.04753032041201862, 0.27462924254134, 0.23237858984267232, 0.16900261079467077, 0.10562663174666924, 0.10562663174666924, 0.06337597904800155, 0.04225065269866769, 0.04225065269866769, 0.300603574662258, 0.300603574662258, 0.16396558617941348, 0.08198279308970674, 0.08198279308970674, 0.027327597696568912, 0.027327597696568912, 0.027327597696568912, 0.2033824100622372, 0.2711765467496496, 0.1355882733748248, 0.1355882733748248, 0.0677941366874124, 0.0677941366874124, 0.0677941366874124, 0.22364309909837288, 0.22364309909837288, 0.22364309909837288, 0.11182154954918644, 0.11182154954918644, 0.3218224558563493, 0.2633092820642858, 0.117026347584127, 0.08776976068809525, 0.08776976068809525, 0.02925658689603175, 0.02925658689603175, 0.02925658689603175, 0.3189711137928701, 0.30125049635993284, 0.15948555689643504, 0.05316185229881168, 0.0708824697317489, 0.03544123486587445, 0.03544123486587445, 0.03544123486587445, 0.2850706164940473, 0.22805649319523785, 0.17104236989642838, 0.11402824659761893, 0.11402824659761893, 0.05701412329880946, 0.05701412329880946, 0.05701412329880946, 0.2866843490701683, 0.20477453505012025, 0.1638196280400962, 0.0819098140200481, 0.0819098140200481, 0.04095490701002405, 0.04095490701002405, 0.04095490701002405, 0.23879157370649357, 0.23879157370649357, 0.1591943824709957, 0.07959719123549786, 0.1591943824709957, 0.07959719123549786, 0.07959719123549786, 0.2551436143816983, 0.2551436143816983, 0.17860053006718882, 0.10205744575267932, 0.10205744575267932, 0.02551436143816983, 0.05102872287633966, 0.05102872287633966, 0.36106381907497426, 0.19694390131362233, 0.16411991776135193, 0.09847195065681116, 0.06564796710454078, 0.03282398355227039, 0.06564796710454078, 0.03282398355227039, 0.34291116805256516, 0.17145558402628258, 0.17145558402628258, 0.17145558402628258, 0.17145558402628258, 0.3421428427271129, 0.22809522848474192, 0.22809522848474192, 0.11404761424237096, 0.11404761424237096, 0.2973676714831102, 0.22302575361233265, 0.11151287680616633, 0.11151287680616633, 0.11151287680616633, 0.03717095893538878, 0.03717095893538878, 0.03717095893538878, 0.27608517415264244, 0.27608517415264244, 0.13804258707632122, 0.09202839138421415, 0.09202839138421415, 0.046014195692107074, 0.046014195692107074, 0.046014195692107074, 0.35435866721471393, 0.20249066697983653, 0.1518680002348774, 0.12655666686239783, 0.0759340001174387, 0.05062266674495913, 0.025311333372479566, 0.025311333372479566, 0.32415595751806653, 0.216103971678711, 0.144069314452474, 0.1080519858393555, 0.072034657226237, 0.0360173286131185, 0.0360173286131185, 0.0360173286131185, 0.39595595541141587, 0.19797797770570794, 0.14848348327928096, 0.09898898885285397, 0.09898898885285397, 0.049494494426426984, 0.049494494426426984, 0.049494494426426984, 0.24260850987149393, 0.19408680789719515, 0.19408680789719515, 0.14556510592289637, 0.14556510592289637, 0.04852170197429879, 0.04852170197429879, 0.04852170197429879, 0.2408491429002061, 0.2408491429002061, 0.16056609526680407, 0.08028304763340204, 0.08028304763340204, 0.30872802916317627, 0.23154602187238219, 0.23154602187238219, 0.07718200729079407, 0.07718200729079407, 0.07718200729079407, 0.4069527718348922, 0.18086789859328545, 0.13565092394496409, 0.09043394929664272, 0.09043394929664272, 0.04521697464832136, 0.04521697464832136, 0.04521697464832136, 0.31465587067590434, 0.2622132255632536, 0.15732793533795217, 0.07866396766897608, 0.07866396766897608, 0.026221322556325363, 0.026221322556325363, 0.026221322556325363, 0.36349431926905185, 0.18174715963452592, 0.1557832796867365, 0.10385551979115767, 0.07789163984336825, 0.05192775989557884, 0.02596387994778942, 0.02596387994778942, 0.26884027441159286, 0.13442013720579643, 0.13442013720579643, 0.13442013720579643, 0.13442013720579643, 0.26909140046711943, 0.227692723472178, 0.16559470797976583, 0.10349669248735363, 0.1448953694822951, 0.04139867699494146, 0.02069933849747073, 0.02069933849747073, 0.3134480243893985, 0.15672401219469925, 0.15672401219469925, 0.10448267479646617, 0.10448267479646617, 0.052241337398233084, 0.052241337398233084, 0.052241337398233084, 0.43817159941129075, 0.19916890882331398, 0.11950134529398838, 0.0796675635293256, 0.0796675635293256, 0.0398337817646628, 0.0398337817646628, 0.0398337817646628, 0.27648369495470393, 0.22464300215069694, 0.19008254028135893, 0.10368138560801396, 0.08640115467334497, 0.03456046186933799, 0.03456046186933799, 0.03456046186933799, 0.40993306448493905, 0.20496653224246952, 0.1639732257939756, 0.0819866128969878, 0.0819866128969878, 0.0409933064484939, 0.0409933064484939, 0.0409933064484939, 0.2585520978676855, 0.2585520978676855, 0.17236806524512369, 0.08618403262256184, 0.08618403262256184, 0.24951286012181606, 0.24951286012181606, 0.24951286012181606, 0.08317095337393868, 0.08317095337393868, 0.08317095337393868, 0.40401491926814476, 0.1945257018698475, 0.14963515528449806, 0.08978109317069884, 0.07481757764224903, 0.029927031056899613, 0.029927031056899613, 0.029927031056899613, 0.4275345355367753, 0.18322908665861798, 0.14251151184559177, 0.10179393703256555, 0.061076362219539326, 0.020358787406513108, 0.040717574813026215, 0.020358787406513108, 0.2457121239642626, 0.2457121239642626, 0.1228560619821313, 0.1228560619821313, 0.1228560619821313, 0.1228560619821313, 0.38393461691270797, 0.19196730845635399, 0.19196730845635399, 0.19196730845635399, 0.19196730845635399, 0.2547294304327725, 0.2183395117995193, 0.18194959316626608, 0.07277983726650643, 0.14555967453301286, 0.036389918633253214, 0.036389918633253214, 0.036389918633253214, 0.2704607339738002, 0.21636858717904014, 0.16227644038428013, 0.10818429358952007, 0.10818429358952007, 0.054092146794760036, 0.054092146794760036, 0.054092146794760036, 0.3121163268449808, 0.3121163268449808, 0.2080775512299872, 0.1040387756149936, 0.1040387756149936, 0.24569897379617808, 0.24569897379617808, 0.16379931586411872, 0.08189965793205936, 0.08189965793205936, 0.08189965793205936, 0.28570917777373706, 0.19999642444161594, 0.17142550666424222, 0.11428367110949482, 0.11428367110949482, 0.028570917777373705, 0.05714183555474741, 0.028570917777373705, 0.4119449078404869, 0.22885828213360382, 0.1373149692801623, 0.045771656426720764, 0.09154331285344153, 0.045771656426720764, 0.045771656426720764, 0.045771656426720764, 0.34345701354004265, 0.22897134236002845, 0.11448567118001422, 0.11448567118001422, 0.11448567118001422, 0.3176004258801286, 0.16715811888427823, 0.16715811888427823, 0.10029487133056693, 0.11701068321899476, 0.050147435665283464, 0.050147435665283464, 0.03343162377685564, 0.31470318743140946, 0.15735159371570473, 0.15735159371570473, 0.15735159371570473, 0.15735159371570473, 0.2950365729502725, 0.24964633095792288, 0.18156096796939847, 0.06808536298852443, 0.09078048398469923, 0.04539024199234962, 0.02269512099617481, 0.04539024199234962, 0.29788273527306874, 0.19858849018204583, 0.19858849018204583, 0.09929424509102291, 0.09929424509102291, 0.09929424509102291, 0.3433488495026655, 0.22889923300177697, 0.15259948866785134, 0.07629974433392567, 0.07629974433392567, 0.038149872166962834, 0.038149872166962834, 0.038149872166962834, 0.2767963882163177, 0.2767963882163177, 0.13839819410815885, 0.13839819410815885, 0.13839819410815885, 0.35761226361637133, 0.20434986492364074, 0.18732070951333735, 0.08514577705151698, 0.08514577705151698, 0.03405831082060679, 0.03405831082060679, 0.03405831082060679, 0.28342559581894805, 0.18895039721263204, 0.18895039721263204, 0.09447519860631602, 0.09447519860631602, 0.09447519860631602, 0.09447519860631602, 0.3399515938282559, 0.15108959725700263, 0.1888619965712533, 0.11331719794275197, 0.07554479862850132, 0.03777239931425066, 0.03777239931425066, 0.03777239931425066, 0.2931462686355372, 0.11725850745421489, 0.23451701490842977, 0.11725850745421489, 0.11725850745421489, 0.05862925372710744, 0.05862925372710744, 0.05862925372710744, 0.32001678975045456, 0.22155008521185315, 0.1969334090772028, 0.0984667045386014, 0.07385002840395105, 0.02461667613465035, 0.02461667613465035, 0.0492333522693007, 0.35481807511226454, 0.17740903755613227, 0.17740903755613227, 0.11827269170408818, 0.05913634585204409, 0.05913634585204409, 0.05913634585204409, 0.05913634585204409, 0.33754381939611455, 0.16877190969805728, 0.16877190969805728, 0.16877190969805728, 0.16877190969805728, 0.27852407562920745, 0.2506716680662867, 0.13926203781460372, 0.11140963025168299, 0.13926203781460372, 0.027852407562920747, 0.027852407562920747, 0.027852407562920747, 0.23959531488762623, 0.15973020992508416, 0.23959531488762623, 0.07986510496254208, 0.07986510496254208, 0.07986510496254208, 0.26476151853351837, 0.24439524787709388, 0.16293016525139592, 0.10183135328212245, 0.12219762393854694, 0.02036627065642449, 0.04073254131284898, 0.04073254131284898, 0.28771783526678785, 0.26374134899455554, 0.19181189017785857, 0.07192945881669696, 0.07192945881669696, 0.04795297254446464, 0.02397648627223232, 0.02397648627223232, 0.26174956737848315, 0.13087478368924158, 0.26174956737848315, 0.13087478368924158, 0.13087478368924158, 0.39510479367112233, 0.2634031957807482, 0.1317015978903741, 0.1317015978903741, 0.1317015978903741, 0.27027909482273627, 0.2027093211170522, 0.2027093211170522, 0.13513954741136813, 0.06756977370568407, 0.06756977370568407, 0.06756977370568407, 0.2228926771648401, 0.27861584645605014, 0.16716950787363008, 0.11144633858242005, 0.055723169291210024, 0.055723169291210024, 0.055723169291210024, 0.055723169291210024, 0.30067862699103565, 0.19134094444884087, 0.19134094444884087, 0.08200326190664609, 0.10933768254219478, 0.05466884127109739, 0.05466884127109739, 0.05466884127109739, 0.3895607982113119, 0.17313813253836086, 0.15149586597106574, 0.08656906626918043, 0.08656906626918043, 0.043284533134590214, 0.043284533134590214, 0.021642266567295107, 0.2932164167197843, 0.2932164167197843, 0.13031840743101528, 0.09773880557326145, 0.06515920371550764, 0.03257960185775382, 0.03257960185775382, 0.03257960185775382, 0.29573570314962355, 0.22748900242278736, 0.15924230169595113, 0.11374450121139368, 0.06824670072683621, 0.04549780048455747, 0.04549780048455747, 0.022748900242278734, 0.16739471461718838, 0.16739471461718838, 0.16739471461718838, 0.16739471461718838, 0.16739471461718838, 0.29952836841125846, 0.20592575328274018, 0.16848470723133288, 0.11232313815422192, 0.09360261512851827, 0.03744104605140731, 0.03744104605140731, 0.03744104605140731, 0.3125844095107206, 0.19891735150682222, 0.1705005870058476, 0.142083822504873, 0.0852502935029238, 0.0284167645009746, 0.0568335290019492, 0.0284167645009746, 0.3311284121796581, 0.16556420608982905, 0.16556420608982905, 0.16556420608982905, 0.2876481386753548, 0.1438240693376774, 0.1438240693376774, 0.1438240693376774, 0.1438240693376774, 0.2668646391313329, 0.2668646391313329, 0.17790975942088863, 0.08895487971044432, 0.08895487971044432, 0.08895487971044432, 0.33901102479620804, 0.16950551239810402, 0.13560440991848322, 0.10170330743886243, 0.10170330743886243, 0.06780220495924161, 0.033901102479620804, 0.033901102479620804, 0.3737725933516696, 0.12459086445055653, 0.12459086445055653, 0.12459086445055653, 0.12459086445055653, 0.30840158956789027, 0.18504095374073418, 0.24672127165431224, 0.12336063582715612, 0.06168031791357806, 0.06168031791357806, 0.06168031791357806, 0.1739170596717382, 0.1739170596717382, 0.1739170596717382, 0.1739170596717382, 0.1739170596717382, 0.3457163278433001, 0.2304775518955334, 0.15365170126368893, 0.07682585063184447, 0.07682585063184447, 0.03841292531592223, 0.03841292531592223, 0.03841292531592223, 0.3098432830180558, 0.1549216415090279, 0.1549216415090279, 0.07746082075451395, 0.07746082075451395, 0.07746082075451395, 0.07746082075451395, 0.2998111466356949, 0.2748268844160537, 0.12492131109820621, 0.07495278665892373, 0.09993704887856497, 0.049968524439282486, 0.024984262219641243, 0.024984262219641243, 0.3350943536530343, 0.19547170629760335, 0.16754717682651715, 0.08377358841325858, 0.13962264735543095, 0.02792452947108619, 0.02792452947108619, 0.02792452947108619, 0.3234938220937345, 0.23526823424998874, 0.17645117568749155, 0.07352132320312148, 0.07352132320312148, 0.04411279392187289, 0.029408529281248593, 0.029408529281248593, 0.27824977813968704, 0.25042480032571834, 0.13912488906984352, 0.11129991125587482, 0.08347493344190612, 0.05564995562793741, 0.027824977813968706, 0.027824977813968706, 0.34949447369007214, 0.19971112782289838, 0.19971112782289838, 0.09985556391144919, 0.09985556391144919, 0.049927781955724594, 0.049927781955724594, 0.049927781955724594, 0.27337026308529305, 0.21869621046823443, 0.16402215785117583, 0.054674052617058606, 0.10934810523411721, 0.054674052617058606, 0.054674052617058606, 0.054674052617058606, 0.28196719588405367, 0.1879781305893691, 0.1879781305893691, 0.09398906529468455, 0.09398906529468455, 0.35915736654336755, 0.23943824436224503, 0.11971912218112252, 0.11971912218112252, 0.11971912218112252, 0.2689403027894898, 0.20170522709211738, 0.20170522709211738, 0.10085261354605869, 0.06723507569737246, 0.03361753784868623, 0.03361753784868623, 0.03361753784868623, 0.27385470835265785, 0.27385470835265785, 0.09128490278421927, 0.09128490278421927, 0.09128490278421927, 0.09128490278421927, 0.26625322918299477, 0.18637726042809635, 0.21300258334639582, 0.10650129167319791, 0.10650129167319791, 0.053250645836598956, 0.026625322918299478, 0.026625322918299478, 0.32570071295835334, 0.20356294559897084, 0.18320665103907377, 0.10178147279948542, 0.08142517823958834, 0.04071258911979417, 0.04071258911979417, 0.020356294559897084, 0.30432703596565924, 0.15216351798282962, 0.17752410431330123, 0.10144234532188642, 0.10144234532188642, 0.05072117266094321, 0.05072117266094321, 0.05072117266094321, 0.43451704153688814, 0.15800619692250478, 0.11850464769187859, 0.07900309846125239, 0.11850464769187859, 0.039501549230626196, 0.039501549230626196, 0.039501549230626196, 0.2767394571897906, 0.24906551147081152, 0.1937176200328534, 0.08302183715693717, 0.08302183715693717, 0.05534789143795811, 0.05534789143795811, 0.027673945718979055, 0.3675379073944051, 0.17501805114019292, 0.15751624602617362, 0.10501083068411575, 0.08750902557009646, 0.035003610228038586, 0.035003610228038586, 0.035003610228038586, 0.26516649184357766, 0.2298109595977673, 0.19445542735195692, 0.08838883061452588, 0.08838883061452588, 0.03535553224581035, 0.03535553224581035, 0.03535553224581035, 0.3941861955779134, 0.1854993861543122, 0.16231196288502317, 0.11593711634644512, 0.06956226980786707, 0.023187423269289024, 0.023187423269289024, 0.023187423269289024, 0.3526516811956019, 0.1627623143979701, 0.1627623143979701, 0.13563526199830842, 0.10850820959864674, 0.027127052399661684, 0.027127052399661684, 0.027127052399661684, 0.30618804644125214, 0.15309402322062607, 0.15309402322062607, 0.15309402322062607, 0.15309402322062607, 0.29601491186082746, 0.259013047878224, 0.14800745593041373, 0.11100559194781029, 0.07400372796520686, 0.03700186398260343, 0.03700186398260343, 0.03700186398260343, 0.30305335961048113, 0.20203557307365408, 0.15152667980524057, 0.15152667980524057, 0.10101778653682704, 0.05050889326841352, 0.05050889326841352, 0.05050889326841352, 0.3108546234786939, 0.15542731173934696, 0.15542731173934696, 0.15542731173934696, 0.15542731173934696, 0.30263221879281105, 0.2269741640946083, 0.15131610939640552, 0.07565805469820276, 0.07565805469820276, 0.07565805469820276, 0.07565805469820276, 0.07565805469820276, 0.275201373333216, 0.275201373333216, 0.183467582222144, 0.091733791111072, 0.091733791111072, 0.022933447777768, 0.045866895555536, 0.045866895555536, 0.2600992617420707, 0.2600992617420707, 0.2600992617420707, 0.13004963087103535, 0.13004963087103535, 0.3424482943990339, 0.22829886293268928, 0.11414943146634464, 0.11414943146634464, 0.11414943146634464, 0.28955906777581664, 0.22751069610957023, 0.16546232444332382, 0.08273116222166191, 0.10341395277707738, 0.041365581110830954, 0.041365581110830954, 0.041365581110830954, 0.40534091264233973, 0.18015151672992877, 0.1351136375474466, 0.09007575836496438, 0.09007575836496438, 0.04503787918248219, 0.04503787918248219, 0.04503787918248219, 0.2557488586707836, 0.2045990869366269, 0.15344931520247018, 0.15344931520247018, 0.10229954346831345, 0.051149771734156725, 0.051149771734156725, 0.051149771734156725, 0.2629872956765862, 0.22541768200850246, 0.15027845467233497, 0.11270884100425123, 0.11270884100425123, 0.03756961366808374, 0.03756961366808374, 0.03756961366808374, 0.37445196113223395, 0.20534462384670893, 0.15702824176513036, 0.08455366864276251, 0.08455366864276251, 0.024158191040789288, 0.03623728656118393, 0.024158191040789288, 0.40800423841002065, 0.18133521707112027, 0.11333451066945018, 0.09066760853556013, 0.09066760853556013, 0.022666902133890034, 0.04533380426778007, 0.04533380426778007, 0.3648469733950984, 0.24323131559673225, 0.12161565779836613, 0.12161565779836613, 0.12161565779836613, 0.2924037669633462, 0.1949358446422308, 0.1949358446422308, 0.0974679223211154, 0.0974679223211154, 0.0487339611605577, 0.0487339611605577, 0.0487339611605577, 0.3488766459836549, 0.2275282473806445, 0.1668540480791393, 0.0910112989522578, 0.0758427491268815, 0.0303370996507526, 0.0303370996507526, 0.0303370996507526, 0.19760996246524976, 0.19760996246524976, 0.19760996246524976, 0.36826546472476157, 0.19829678869794853, 0.1416405633556775, 0.08498433801340652, 0.08498433801340652, 0.05665622534227101, 0.05665622534227101, 0.028328112671135504, 0.285658318480411, 0.1904388789869407, 0.285658318480411, 0.09521943949347035, 0.09521943949347035, 0.2884122663915996, 0.23597367250221785, 0.1835350786128361, 0.1048771877787635, 0.1048771877787635, 0.05243859388938175, 0.026219296944690874, 0.026219296944690874, 0.3628008065802019, 0.18140040329010096, 0.18140040329010096, 0.09070020164505048, 0.09070020164505048, 0.09070020164505048, 0.32763608655281773, 0.28083093133098663, 0.0936103104436622, 0.0936103104436622, 0.0936103104436622, 0.0468051552218311, 0.0468051552218311, 0.0468051552218311, 0.31420096919150453, 0.2827808722723541, 0.12568038767660183, 0.06284019383830092, 0.09426029075745136, 0.03142009691915046, 0.03142009691915046, 0.03142009691915046, 0.37373127485128477, 0.12457709161709492, 0.12457709161709492, 0.12457709161709492, 0.12457709161709492, 0.2873254618807821, 0.23943788490065177, 0.14366273094039106, 0.0957751539602607, 0.0957751539602607, 0.04788757698013035, 0.04788757698013035, 0.04788757698013035, 0.24479082519332404, 0.24479082519332404, 0.24479082519332404, 0.12239541259666202, 0.12239541259666202, 0.34009786774987677, 0.26161374442298213, 0.13080687221149107, 0.07848412332689464, 0.07848412332689464, 0.052322748884596426, 0.026161374442298213, 0.026161374442298213, 0.4447588752405956, 0.2223794376202978, 0.1111897188101489, 0.1111897188101489, 0.1111897188101489, 0.2706167419272156, 0.2367896491863136, 0.2367896491863136, 0.0676541854818039, 0.0676541854818039, 0.03382709274090195, 0.03382709274090195, 0.03382709274090195, 0.29230142831227024, 0.19486761887484683, 0.14615071415613512, 0.09743380943742341, 0.09743380943742341, 0.04871690471871171, 0.04871690471871171, 0.04871690471871171, 0.3364581107718821, 0.22430540718125472, 0.11215270359062736, 0.11215270359062736, 0.11215270359062736, 0.11215270359062736, 0.40750645502984423, 0.1811139800132641, 0.1811139800132641, 0.09055699000663205, 0.09055699000663205, 0.04527849500331602, 0.04527849500331602, 0.04527849500331602, 0.17531514650706753, 0.3155672637127216, 0.17531514650706753, 0.10518908790424052, 0.10518908790424052, 0.03506302930141351, 0.03506302930141351, 0.03506302930141351, 0.34765964100661817, 0.1854184752035297, 0.13906385640264726, 0.11588654700220606, 0.09270923760176485, 0.04635461880088242, 0.02317730940044121, 0.04635461880088242, 0.28368446395471464, 0.14184223197735732, 0.14184223197735732, 0.14184223197735732, 0.14184223197735732, 0.26544868852531295, 0.26544868852531295, 0.13272434426265647, 0.13272434426265647, 0.13272434426265647, 0.2477540278071771, 0.2477540278071771, 0.12387701390358855, 0.12387701390358855, 0.12387701390358855, 0.3229652994970417, 0.2469734643212672, 0.1329857115576054, 0.07599183517577453, 0.07599183517577453, 0.037995917587887264, 0.037995917587887264, 0.037995917587887264, 0.251572180340958, 0.251572180340958, 0.2012577442727664, 0.0503144360681916, 0.1006288721363832, 0.0503144360681916, 0.0503144360681916, 0.0503144360681916, 0.2780021137164949, 0.2780021137164949, 0.13900105685824746, 0.13900105685824746, 0.13900105685824746, 0.3038167006894339, 0.15190835034471695, 0.15190835034471695, 0.15190835034471695, 0.15190835034471695, 0.27069348305174556, 0.2105393757069132, 0.15038526836208085, 0.12030821468966468, 0.09023116101724851, 0.06015410734483234, 0.03007705367241617, 0.03007705367241617, 0.32799612500240183, 0.19679767500144107, 0.13119845000096073, 0.06559922500048036, 0.06559922500048036, 0.06559922500048036, 0.06559922500048036, 0.06559922500048036, 0.3382462613653715, 0.13009471590975827, 0.15611365909170993, 0.15611365909170993, 0.10407577272780662, 0.05203788636390331, 0.026018943181951654, 0.05203788636390331, 0.25604294483542905, 0.25604294483542905, 0.12802147241771453, 0.06401073620885726, 0.12802147241771453, 0.06401073620885726, 0.06401073620885726, 0.06401073620885726, 0.3377595538712082, 0.22517303591413879, 0.22517303591413879, 0.11258651795706939, 0.11258651795706939, 0.4199508047601933, 0.1816003480044079, 0.12485023925303043, 0.09080017400220396, 0.10215019575247945, 0.03405006525082648, 0.02270004350055099, 0.03405006525082648, 0.2949499612302791, 0.20419612700557785, 0.20419612700557785, 0.09075383422470126, 0.09075383422470126, 0.022688458556175316, 0.04537691711235063, 0.04537691711235063, 0.30698401524740915, 0.15349200762370457, 0.15349200762370457, 0.15349200762370457, 0.15349200762370457, 0.4199793958225791, 0.20998969791128955, 0.13999313194085972, 0.06999656597042986, 0.06999656597042986, 0.06999656597042986, 0.2784787825275192, 0.2088590868956394, 0.2088590868956394, 0.0696196956318798, 0.0696196956318798, 0.0696196956318798, 0.0696196956318798, 0.0696196956318798, 0.24683386216854472, 0.24683386216854472, 0.12341693108427236, 0.12341693108427236, 0.12341693108427236, 0.2789915561280452, 0.2169934325440352, 0.15499530896002514, 0.09299718537601508, 0.15499530896002514, 0.030999061792005025, 0.030999061792005025, 0.030999061792005025, 0.4126091057872236, 0.16504364231488944, 0.1375363685957412, 0.11002909487659296, 0.08252182115744472, 0.02750727371914824, 0.02750727371914824, 0.02750727371914824, 0.39337343343094344, 0.18029615698918242, 0.1475150375366038, 0.08195279863144656, 0.08195279863144656, 0.032781119452578625, 0.032781119452578625, 0.032781119452578625, 0.326557528845247, 0.1484352403842032, 0.17812228846104383, 0.08906114423052192, 0.05937409615368128, 0.05937409615368128, 0.05937409615368128, 0.02968704807684064, 0.4086218969745508, 0.2043109484872754, 0.13620729899151693, 0.13620729899151693, 0.06810364949575846, 0.06810364949575846, 0.2670266141967174, 0.1335133070983587, 0.1335133070983587, 0.1335133070983587, 0.1335133070983587, 0.1745492116593773, 0.1745492116593773, 0.1745492116593773, 0.1745492116593773, 0.3914380066117439, 0.17984989492972014, 0.1481116781774166, 0.0740558390887083, 0.08463524467280949, 0.042317622336404744, 0.03173821675230356, 0.042317622336404744, 0.2688768347969307, 0.20912642706427942, 0.17925122319795378, 0.11950081546530253, 0.11950081546530253, 0.059750407732651264, 0.029875203866325632, 0.029875203866325632, 0.2794755423467782, 0.18631702823118548, 0.18631702823118548, 0.09315851411559274, 0.09315851411559274, 0.09315851411559274, 0.2813496583185035, 0.24618095102869056, 0.14067482915925175, 0.10550612186943881, 0.07033741457962588, 0.03516870728981294, 0.03516870728981294, 0.03516870728981294, 0.3926638057909827, 0.14023707349677955, 0.16828448819613545, 0.08414224409806773, 0.08414224409806773, 0.05609482939871182, 0.05609482939871182, 0.02804741469935591, 0.34448107469855493, 0.1476347462993807, 0.1476347462993807, 0.09842316419958713, 0.09842316419958713, 0.049211582099793566, 0.049211582099793566, 0.049211582099793566, 0.38058229516474934, 0.20030647113934175, 0.14021452979753923, 0.09013791201270378, 0.0801225884557367, 0.030045970670901263, 0.04006129422786835, 0.020030647113934177, 0.30721861788672344, 0.2304139634150426, 0.15360930894336172, 0.1152069817075213, 0.1152069817075213, 0.03840232723584043, 0.03840232723584043, 0.03840232723584043, 0.30509778871922233, 0.22882334153941672, 0.15254889435961116, 0.07627444717980558, 0.15254889435961116, 0.07627444717980558, 0.07627444717980558, 0.2955635956110055, 0.18808592447973074, 0.21495534226254942, 0.08060825334845603, 0.08060825334845603, 0.026869417782818678, 0.026869417782818678, 0.026869417782818678, 0.34776680466262827, 0.21168414196855637, 0.19656384611365946, 0.06048118341958753, 0.09072177512938129, 0.045360887564690644, 0.030240591709793766, 0.030240591709793766, 0.2720062148782761, 0.2720062148782761, 0.10880248595131044, 0.10880248595131044, 0.10880248595131044, 0.05440124297565522, 0.05440124297565522, 0.05440124297565522, 0.25875516729346953, 0.17250344486231303, 0.25875516729346953, 0.08625172243115652, 0.08625172243115652, 0.08625172243115652, 0.2660636480612494, 0.19004546290089241, 0.19004546290089241, 0.11402727774053545, 0.07601818516035697, 0.07601818516035697, 0.03800909258017848, 0.03800909258017848, 0.22329438964528894, 0.22329438964528894, 0.22329438964528894, 0.11164719482264447, 0.11164719482264447, 0.3289528626428846, 0.1644764313214423, 0.1644764313214423, 0.1644764313214423, 0.1644764313214423, 0.46175223760363887, 0.23087611880181944, 0.11543805940090972, 0.11543805940090972, 0.11543805940090972, 0.2478417813763357, 0.19827342510106855, 0.14870506882580142, 0.14870506882580142, 0.09913671255053427, 0.049568356275267136, 0.049568356275267136, 0.049568356275267136, 0.2320468906615768, 0.2320468906615768, 0.1160234453307884, 0.1160234453307884, 0.1160234453307884, 0.33940930383138906, 0.22627286922092604, 0.11313643461046302, 0.11313643461046302, 0.11313643461046302, 0.3183532035065452, 0.2728741744341816, 0.1364370872170908, 0.1364370872170908, 0.045479029072363605, 0.045479029072363605, 0.045479029072363605, 0.045479029072363605, 0.3435848657823491, 0.22905657718823272, 0.11452828859411636, 0.11452828859411636, 0.05726414429705818, 0.05726414429705818, 0.05726414429705818, 0.05726414429705818, 0.38948627727232, 0.19474313863616, 0.12982875909077335, 0.12982875909077335, 0.06491437954538667, 0.06491437954538667, 0.33802477294351363, 0.2028148637661082, 0.16901238647175681, 0.13520990917740544, 0.06760495458870272, 0.03380247729435136, 0.03380247729435136, 0.03380247729435136, 0.3919673482267917, 0.19598367411339584, 0.19598367411339584, 0.19598367411339584, 0.19598367411339584, 0.34959130900686874, 0.2039282635873401, 0.14566304541952865, 0.08739782725171719, 0.08739782725171719, 0.02913260908390573, 0.02913260908390573, 0.02913260908390573, 0.273489720540199, 0.22376431680561737, 0.19890161493832656, 0.12431350933645409, 0.09945080746916328, 0.04972540373458164, 0.04972540373458164, 0.02486270186729082, 0.29545753817058046, 0.21666886132509233, 0.15757735369097625, 0.09848584605686016, 0.09848584605686016, 0.03939433842274406, 0.03939433842274406, 0.03939433842274406, 0.31834462575487654, 0.17364252313902356, 0.17364252313902356, 0.11576168209268238, 0.08682126156951178, 0.05788084104634119, 0.028940420523170595, 0.028940420523170595, 0.36161904378193793, 0.2008994687677433, 0.12053968126064599, 0.08035978750709732, 0.16071957501419465, 0.04017989375354866, 0.04017989375354866, 0.04017989375354866, 0.25586180373288425, 0.21931011748532936, 0.18275843123777447, 0.07310337249510979, 0.10965505874266468, 0.07310337249510979, 0.03655168624755489, 0.03655168624755489, 0.28948344066412046, 0.17369006439847226, 0.17369006439847226, 0.11579337626564817, 0.11579337626564817, 0.05789668813282409, 0.05789668813282409, 0.05789668813282409, 0.37759446922838297, 0.1618262010978784, 0.1618262010978784, 0.07192275604350151, 0.10788413406525228, 0.05394206703262614, 0.035961378021750756, 0.035961378021750756, 0.30343994133762237, 0.21674281524115885, 0.1300456891446953, 0.08669712609646353, 0.1300456891446953, 0.043348563048231765, 0.043348563048231765, 0.043348563048231765, 0.27348479093305333, 0.13674239546652667, 0.13674239546652667, 0.13674239546652667, 0.13674239546652667, 0.2702834977922466, 0.2702834977922466, 0.1801889985281644, 0.0900944992640822, 0.0900944992640822, 0.36014744844483715, 0.14092726243493628, 0.2113908936524044, 0.0939515082899575, 0.07829292357496459, 0.04697575414497875, 0.03131716942998584, 0.03131716942998584, 0.2778243589513052, 0.18521623930087014, 0.18521623930087014, 0.09260811965043507, 0.09260811965043507, 0.09260811965043507, 0.33896834841624063, 0.19939314612720038, 0.13957520228904027, 0.09969657306360019, 0.09969657306360019, 0.039878629225440075, 0.039878629225440075, 0.039878629225440075, 0.392607354731549, 0.1963036773657745, 0.1963036773657745, 0.1963036773657745, 0.1963036773657745, 0.3994678600587303, 0.1331559533529101, 0.16644494169113763, 0.09986696501468258, 0.09986696501468258, 0.03328898833822753, 0.03328898833822753, 0.03328898833822753, 0.2724075378196572, 0.21187252941528892, 0.21187252941528892, 0.0908025126065524, 0.12107001680873652, 0.03026750420218413, 0.03026750420218413, 0.03026750420218413, 0.35203154033776096, 0.2112189242026566, 0.15489387774861482, 0.09856883129457307, 0.0704063080675522, 0.02816252322702088, 0.02816252322702088, 0.04224378484053132, 0.3597717687646614, 0.1798858843823307, 0.1798858843823307, 0.10793153062939842, 0.07195435375293228, 0.03597717687646614, 0.03597717687646614, 0.03597717687646614, 0.28686420440633514, 0.2294913635250681, 0.1721185226438011, 0.057372840881267026, 0.11474568176253405, 0.057372840881267026, 0.057372840881267026, 0.057372840881267026, 0.3241089821013829, 0.21607265473425527, 0.21607265473425527, 0.10803632736712764, 0.10803632736712764, 0.33397382249904656, 0.21469745732081563, 0.11927636517823091, 0.11927636517823091, 0.09542109214258473, 0.04771054607129237, 0.04771054607129237, 0.023855273035646184, 0.31759822424307965, 0.15879911212153983, 0.15879911212153983, 0.15879911212153983, 0.15879911212153983, 0.32911579074975406, 0.2516767811615766, 0.13551826677931048, 0.09679876198522178, 0.09679876198522178, 0.03871950479408871, 0.03871950479408871, 0.03871950479408871, 0.2473946975585602, 0.18554602316892016, 0.18554602316892016, 0.1236973487792801, 0.1236973487792801, 0.06184867438964005, 0.06184867438964005, 0.3067488108684514, 0.20449920724563425, 0.10224960362281713, 0.10224960362281713, 0.10224960362281713, 0.10224960362281713, 0.3199877984030714, 0.19199267904184286, 0.19199267904184286, 0.06399755968061428, 0.06399755968061428, 0.06399755968061428, 0.06399755968061428, 0.06399755968061428, 0.4070352320975758, 0.2035176160487879, 0.11629578059930738, 0.08722183544948053, 0.08722183544948053, 0.029073945149826846, 0.029073945149826846, 0.029073945149826846, 0.3017210501814878, 0.2514342084845732, 0.1508605250907439, 0.10057368339382927, 0.10057368339382927, 0.050286841696914636, 0.050286841696914636, 0.050286841696914636, 0.31479103924206087, 0.16788855426243246, 0.23084676211084465, 0.1049303464140203, 0.08394427713121623, 0.041972138565608115, 0.041972138565608115, 0.041972138565608115, 0.320825677715973, 0.1604128388579865, 0.1604128388579865, 0.09624770331479189, 0.12833027108638917, 0.03208256777159729, 0.03208256777159729, 0.03208256777159729, 0.3030887045591206, 0.1632016101472188, 0.1632016101472188, 0.11657257867658485, 0.11657257867658485, 0.04662903147063394, 0.04662903147063394, 0.04662903147063394, 0.28532375815202865, 0.17119425489121717, 0.17119425489121717, 0.11412950326081146, 0.05706475163040573, 0.05706475163040573, 0.05706475163040573, 0.05706475163040573, 0.32276219207334683, 0.17931232892963714, 0.16138109603667342, 0.08965616446481857, 0.10758739735778228, 0.05379369867889114, 0.03586246578592742, 0.03586246578592742, 0.4131933395349021, 0.20659666976745106, 0.10329833488372553, 0.10329833488372553, 0.10329833488372553, 0.3401296926571766, 0.1700648463285883, 0.1700648463285883, 0.1700648463285883, 0.4311154991153484, 0.2155577495576742, 0.1077788747788371, 0.1077788747788371, 0.1077788747788371, 0.2247062776403678, 0.1997389134581047, 0.2247062776403678, 0.09986945672905236, 0.09986945672905236, 0.04993472836452618, 0.04993472836452618, 0.04993472836452618, 0.3323329065957507, 0.1899045180547147, 0.1899045180547147, 0.09495225902735735, 0.09495225902735735, 0.047476129513678675, 0.047476129513678675, 0.047476129513678675, 0.2852710588278736, 0.2852710588278736, 0.13424520415429347, 0.08390325259643341, 0.08390325259643341, 0.03356130103857337, 0.03356130103857337, 0.03356130103857337, 0.3265262591993215, 0.24489469439949113, 0.16326312959966074, 0.08163156479983037, 0.08163156479983037, 0.08163156479983037, 0.08163156479983037, 0.33267240747242965, 0.21623706485707925, 0.19960344448345776, 0.06653448149448593, 0.09980172224172888, 0.033267240747242965, 0.016633620373621483, 0.033267240747242965, 0.3589288062063843, 0.2392858708042562, 0.1196429354021281, 0.1196429354021281, 0.1196429354021281, 0.29605536995276366, 0.21146812139483118, 0.21146812139483118, 0.06344043641844935, 0.1268808728368987, 0.042293624278966234, 0.021146812139483117, 0.021146812139483117, 0.2474206286712342, 0.2474206286712342, 0.1237103143356171, 0.1237103143356171, 0.1237103143356171, 0.0412367714452057, 0.0412367714452057, 0.0412367714452057, 0.3980009829278347, 0.19900049146391735, 0.13266699430927822, 0.06633349715463911, 0.06633349715463911, 0.06633349715463911, 0.06633349715463911, 0.3302431204339221, 0.27019891671866353, 0.09006630557288785, 0.09006630557288785, 0.09006630557288785, 0.030022101857629283, 0.030022101857629283, 0.030022101857629283, 0.2572728250147014, 0.19295461876102604, 0.16079551563418837, 0.1286364125073507, 0.1286364125073507, 0.032159103126837674, 0.032159103126837674, 0.032159103126837674, 0.2578248283281083, 0.17188321888540556, 0.17188321888540556, 0.08594160944270278, 0.08594160944270278, 0.08594160944270278, 0.08594160944270278, 0.2710085201994789, 0.2710085201994789, 0.1806723467996526, 0.0903361733998263, 0.0903361733998263, 0.2729582634750319, 0.13647913173751594, 0.13647913173751594, 0.13647913173751594, 0.13647913173751594, 0.32215239929659595, 0.1812107246043352, 0.20134524956037247, 0.10067262478018624, 0.08053809982414899, 0.020134524956037247, 0.040269049912074494, 0.040269049912074494, 0.33974580327401416, 0.2090743404763164, 0.1568057553572373, 0.07840287767861864, 0.07840287767861864, 0.02613429255953955, 0.02613429255953955, 0.0522685851190791, 0.2723023486288804, 0.22691862385740036, 0.1361511743144402, 0.09076744954296015, 0.1361511743144402, 0.045383724771480075, 0.045383724771480075, 0.045383724771480075, 0.3155500633276883, 0.24542782703264646, 0.21036670888512551, 0.07012223629504184, 0.07012223629504184, 0.03506111814752092, 0.03506111814752092, 0.03506111814752092, 0.3818454192752899, 0.19092270963764496, 0.16154998507800727, 0.08811817367891306, 0.08811817367891306, 0.04405908683945653, 0.029372724559637686, 0.029372724559637686, 0.3169560412967291, 0.15847802064836455, 0.15847802064836455, 0.15847802064836455, 0.15847802064836455, 0.26780219241309605, 0.26780219241309605, 0.13390109620654803, 0.13390109620654803, 0.13390109620654803, 0.23431369235452723, 0.19526141029543936, 0.19526141029543936, 0.11715684617726362, 0.11715684617726362, 0.039052282059087874, 0.039052282059087874, 0.039052282059087874, 0.33319204013882775, 0.21203129827016312, 0.18174111280299696, 0.0757254636679154, 0.09087055640149848, 0.04543527820074924, 0.03029018546716616, 0.03029018546716616, 0.2740412596758304, 0.18269417311722025, 0.18269417311722025, 0.09134708655861012, 0.09134708655861012, 0.09134708655861012, 0.09134708655861012, 0.27783172040079773, 0.1786061059719414, 0.2381414746292552, 0.09922561442885633, 0.09922561442885633, 0.03969024577154253, 0.03969024577154253, 0.03969024577154253, 0.3162509463512679, 0.20330417979724366, 0.20330417979724366, 0.06776805993241455, 0.0903574132432194, 0.0451787066216097, 0.0451787066216097, 0.02258935331080485, 0.36682952878673425, 0.16303534612743745, 0.16303534612743745, 0.1018970913296484, 0.1018970913296484, 0.04075883653185936, 0.04075883653185936, 0.02037941826592968, 0.34025274547741174, 0.17012637273870587, 0.17012637273870587, 0.10632898296169117, 0.08506318636935294, 0.04253159318467647, 0.04253159318467647, 0.021265796592338234, 0.3119709731121091, 0.18718258386726544, 0.21837968117847636, 0.062394194622421816, 0.12478838924484363, 0.031197097311210908, 0.031197097311210908, 0.031197097311210908, 0.2967751184987562, 0.19785007899917081, 0.19785007899917081, 0.09892503949958541, 0.09892503949958541, 0.09892503949958541, 0.4007808989851898, 0.2003904494925949, 0.12023426969555694, 0.08015617979703796, 0.08015617979703796, 0.04007808989851898, 0.04007808989851898, 0.04007808989851898, 0.2923047471279346, 0.19486983141862305, 0.2435872892732788, 0.09743491570931152, 0.07307618678198365, 0.04871745785465576, 0.02435872892732788, 0.02435872892732788, 0.3599086107467661, 0.19195125906494193, 0.14396344429870644, 0.11996953691558869, 0.09597562953247096, 0.04798781476623548, 0.02399390738311774, 0.02399390738311774, 0.37083578629451874, 0.18541789314725937, 0.18541789314725937, 0.30510970382404073, 0.15255485191202037, 0.15255485191202037, 0.15255485191202037, 0.15255485191202037, 0.31257996382548464, 0.19235690081568285, 0.21640151341764322, 0.09617845040784143, 0.07213383780588108, 0.04808922520392071, 0.04808922520392071, 0.024044612601960356, 0.23951357265471818, 0.20529734798975843, 0.18818923565727858, 0.11975678632735909, 0.13686489865983897, 0.03421622466495974, 0.05132433699743961, 0.03421622466495974, 0.34882727547451997, 0.23255151698301332, 0.11627575849150666, 0.11627575849150666, 0.11627575849150666, 0.383293698443473, 0.2146444711283449, 0.1533174793773892, 0.0766587396886946, 0.06132699175095568, 0.03066349587547784, 0.03066349587547784, 0.03066349587547784, 0.4035753343632733, 0.20178766718163665, 0.10089383359081833, 0.10089383359081833, 0.10089383359081833, 0.34057108057447577, 0.17028554028723789, 0.17028554028723789, 0.17028554028723789, 0.17028554028723789, 0.31008498185970934, 0.31008498185970934, 0.12920207577487888, 0.07752124546492734, 0.07752124546492734, 0.051680830309951555, 0.025840415154975777, 0.025840415154975777, 0.2312347775115088, 0.34685216626726323, 0.1156173887557544, 0.1156173887557544, 0.1156173887557544, 0.3500924946957588, 0.2100554968174553, 0.16337649752468744, 0.09335799858553569, 0.09335799858553569, 0.046678999292767843, 0.023339499646383922, 0.023339499646383922, 0.307392538602919, 0.1536962693014595, 0.1536962693014595, 0.1536962693014595, 0.1536962693014595, 0.24593452756504686, 0.2384819661236818, 0.2086717203582216, 0.1192409830618409, 0.08197817585501563, 0.0521679300895554, 0.02235768432409517, 0.029810245765460226, 0.33024471380025844, 0.21015572696380083, 0.12008898683645762, 0.12008898683645762, 0.09006674012734321, 0.06004449341822881, 0.030022246709114405, 0.030022246709114405, 0.31595470743083165, 0.2106364716205544, 0.2106364716205544, 0.1053182358102772, 0.1053182358102772, 0.1053182358102772, 0.319969569315934, 0.159984784657967, 0.159984784657967, 0.159984784657967, 0.0799923923289835, 0.3432668661975435, 0.17163343309877174, 0.17163343309877174, 0.08581671654938587, 0.17163343309877174, 0.08581671654938587, 0.3041222900328118, 0.1520611450164059, 0.1520611450164059, 0.1520611450164059, 0.1520611450164059, 0.267423995657062, 0.3056274236080708, 0.11461028385302657, 0.0764068559020177, 0.0764068559020177, 0.03820342795100885, 0.03820342795100885, 0.03820342795100885, 0.2901656458231631, 0.14508282291158156, 0.14508282291158156, 0.14508282291158156, 0.14508282291158156, 0.28171743313274367, 0.28171743313274367, 0.14085871656637183, 0.14085871656637183, 0.14085871656637183, 0.3001644853429941, 0.18009869120579647, 0.21011513974009588, 0.09004934560289823, 0.12006579413719763, 0.030016448534299408, 0.030016448534299408, 0.030016448534299408, 0.3456564136253885, 0.15711655164790386, 0.1256932413183231, 0.09426993098874233, 0.1256932413183231, 0.031423310329580775, 0.031423310329580775, 0.031423310329580775, 0.2916560057362525, 0.2916560057362525, 0.058331201147250496, 0.058331201147250496, 0.058331201147250496, 0.058331201147250496, 0.058331201147250496, 0.058331201147250496, 0.2535103868472165, 0.21729461729761415, 0.14486307819840943, 0.14486307819840943, 0.10864730864880708, 0.03621576954960236, 0.03621576954960236, 0.03621576954960236, 0.32263577955572204, 0.2150905197038147, 0.19358146773343324, 0.08603620788152588, 0.08603620788152588, 0.04301810394076294, 0.02150905197038147, 0.04301810394076294, 0.4173658884378427, 0.1669463553751371, 0.1669463553751371, 0.08347317768756855, 0.08347317768756855, 0.02782439256252285, 0.02782439256252285, 0.02782439256252285, 0.31434795850720604, 0.1886087751043236, 0.14669571397002948, 0.08382612226858828, 0.12573918340288243, 0.04191306113429414, 0.02095653056714707, 0.04191306113429414, 0.28420298406364786, 0.2526248747232425, 0.12631243736162126, 0.09473432802121595, 0.12631243736162126, 0.031578109340405315, 0.031578109340405315, 0.031578109340405315, 0.3379615489052393, 0.18775641605846627, 0.18775641605846627, 0.07510256642338652, 0.11265384963507977, 0.07510256642338652, 0.03755128321169326, 0.03755128321169326, 0.40625368742351026, 0.1741087231815044, 0.11607248212100292, 0.05803624106050146, 0.11607248212100292, 0.05803624106050146, 0.05803624106050146, 0.2112389813799864, 0.2112389813799864, 0.2112389813799864, 0.1056194906899932, 0.1056194906899932, 0.30279591935926786, 0.18167755161556073, 0.12111836774370716, 0.12111836774370716, 0.12111836774370716, 0.06055918387185358, 0.06055918387185358, 0.06055918387185358, 0.3051586311979937, 0.2179704508557098, 0.1307822705134259, 0.1307822705134259, 0.08718818034228391, 0.04359409017114196, 0.04359409017114196, 0.04359409017114196, 0.39431488634083317, 0.17525106059592585, 0.13143829544694438, 0.10953191287245366, 0.08762553029796293, 0.04381276514898146, 0.04381276514898146, 0.02190638257449073, 0.269157641234847, 0.1345788206174235, 0.1345788206174235, 0.1345788206174235, 0.1345788206174235, 0.26842139271237686, 0.20131604453428265, 0.17894759514158456, 0.08947379757079228, 0.11184224696349035, 0.04473689878539614, 0.04473689878539614, 0.04473689878539614, 0.31242854306296713, 0.26779589405397186, 0.13389794702698593, 0.08926529801799062, 0.08926529801799062, 0.04463264900899531, 0.04463264900899531, 0.04463264900899531, 0.34949838385711196, 0.17474919192855598, 0.26212378789283397, 0.08737459596427799, 0.08737459596427799, 0.37722741376210905, 0.18861370688105453, 0.1714670062555041, 0.08573350312775205, 0.06858680250220164, 0.03429340125110082, 0.03429340125110082, 0.03429340125110082, 0.3370341795822048, 0.1685170897911024, 0.1685170897911024, 0.1685170897911024, 0.1685170897911024, 0.2108299177513996, 0.3162448766270994, 0.1054149588756998, 0.1054149588756998, 0.1054149588756998, 0.2864717182182837, 0.1909811454788558, 0.15915095456571315, 0.0954905727394279, 0.0954905727394279, 0.06366038182628526, 0.03183019091314263, 0.03183019091314263, 0.3236904473262963, 0.23120746237592593, 0.13872447742555555, 0.09248298495037037, 0.09248298495037037, 0.046241492475185185, 0.046241492475185185, 0.046241492475185185, 0.3360242924472794, 0.1960141705942463, 0.14001012185303308, 0.11200809748242646, 0.08400607311181985, 0.05600404874121323, 0.05600404874121323, 0.028002024370606615, 0.3121471866483613, 0.249717749318689, 0.1248588746593445, 0.1248588746593445, 0.06242943732967225, 0.06242943732967225, 0.06242943732967225, 0.06242943732967225, 0.4009505259800332, 0.18868260046119212, 0.1415119503458941, 0.09434130023059606, 0.07075597517294704, 0.04717065011529803, 0.023585325057649015, 0.04717065011529803, 0.34028860402827055, 0.17014430201413527, 0.17014430201413527, 0.08507215100706764, 0.08507215100706764, 0.08507215100706764, 0.08507215100706764, 0.3068500372367691, 0.22502336064029735, 0.20456669149117943, 0.10228334574558971, 0.061370007447353825, 0.04091333829823588, 0.04091333829823588, 0.04091333829823588, 0.3426128994767028, 0.1713064497383514, 0.1713064497383514, 0.1713064497383514, 0.1713064497383514, 0.2438535300903326, 0.2438535300903326, 0.1219267650451663, 0.1219267650451663, 0.1219267650451663, 0.26253160458941865, 0.13126580229470933, 0.26253160458941865, 0.13126580229470933, 0.13126580229470933, 0.2919611530586237, 0.2595210249409988, 0.19464076870574912, 0.0648802562352497, 0.09732038435287456, 0.03244012811762485, 0.03244012811762485, 0.03244012811762485, 0.25000867873297067, 0.25000867873297067, 0.1666724524886471, 0.08333622624432355, 0.1666724524886471, 0.19886954812511365, 0.19886954812511365, 0.19886954812511365, 0.19886954812511365, 0.19886954812511365, 0.30687245864123447, 0.20458163909415633, 0.10229081954707817, 0.10229081954707817, 0.10229081954707817, 0.39919647435388034, 0.19959823717694017, 0.14969867788270513, 0.07484933894135257, 0.07484933894135257, 0.02494977964711752, 0.02494977964711752, 0.02494977964711752, 0.28021748090417503, 0.2490822052481556, 0.15567637828009726, 0.1245411026240778, 0.1245411026240778, 0.03113527565601945, 0.03113527565601945, 0.03113527565601945, 0.3402126285459534, 0.1701063142729767, 0.1701063142729767, 0.1701063142729767, 0.1701063142729767, 0.33110612219465246, 0.19866367331679147, 0.13244244887786097, 0.13244244887786097, 0.06622122443893048, 0.03311061221946524, 0.03311061221946524, 0.03311061221946524, 0.3789602906910085, 0.199452784574215, 0.1396169492019505, 0.079781113829686, 0.079781113829686, 0.039890556914843, 0.0199452784574215, 0.039890556914843, 0.3054247374636533, 0.15271236873182664, 0.22906855309774, 0.07635618436591332, 0.07635618436591332, 0.07635618436591332, 0.07635618436591332, 0.07635618436591332, 0.32219866348179155, 0.21479910898786103, 0.14319940599190736, 0.10739955449393052, 0.10739955449393052, 0.03579985149797684, 0.03579985149797684, 0.03579985149797684, 0.31219523720246106, 0.18731714232147664, 0.18731714232147664, 0.12487809488098443, 0.12487809488098443, 0.06243904744049222, 0.06243904744049222, 0.06243904744049222, 0.37770006720257276, 0.2518000448017152, 0.1259000224008576, 0.1259000224008576, 0.1259000224008576, 0.24910410847179545, 0.24910410847179545, 0.20758675705982954, 0.08303470282393181, 0.08303470282393181, 0.04151735141196591, 0.04151735141196591, 0.04151735141196591, 0.3047540155803458, 0.217681439700247, 0.1306088638201482, 0.0870725758800988, 0.0870725758800988, 0.0435362879400494, 0.0435362879400494, 0.0435362879400494, 0.3096950452543094, 0.1548475226271547, 0.1548475226271547, 0.1548475226271547, 0.1548475226271547, 0.33282121688694294, 0.19018355250682456, 0.1426376643801184, 0.11886472031676534, 0.11886472031676534, 0.04754588812670614, 0.04754588812670614, 0.02377294406335307, 0.30576399503523816, 0.23520307310402935, 0.18816245848322347, 0.0705609219312088, 0.0705609219312088, 0.047040614620805866, 0.047040614620805866, 0.047040614620805866, 0.2672706954231982, 0.17818046361546547, 0.17818046361546547, 0.08909023180773273, 0.08909023180773273, 0.08909023180773273, 0.39512821307066437, 0.13170940435688813, 0.19756410653533218, 0.13170940435688813, 0.06585470217844407, 0.26612534917040714, 0.1774168994469381, 0.1774168994469381, 0.1774168994469381, 0.08870844972346904, 0.2893840919167867, 0.2893840919167867, 0.19292272794452445, 0.09646136397226222, 0.09646136397226222, 0.3383957221970169, 0.2255971481313446, 0.2255971481313446, 0.1127985740656723, 0.1127985740656723, 0.1920899376886358, 0.1920899376886358, 0.1920899376886358, 0.1920899376886358, 0.33685718419351174, 0.16842859209675587, 0.16842859209675587, 0.16842859209675587, 0.16842859209675587, 0.3484839634540449, 0.2144516698178738, 0.16083875236340536, 0.08041937618170268, 0.08041937618170268, 0.05361291745446845, 0.05361291745446845, 0.026806458727234226, 0.2708870076013625, 0.2708870076013625, 0.1625322045608175, 0.108354803040545, 0.108354803040545, 0.0541774015202725, 0.0541774015202725, 0.0541774015202725, 0.37078547290858593, 0.16853885132208452, 0.16853885132208452, 0.1348310810576676, 0.0674155405288338, 0.0337077702644169, 0.0337077702644169, 0.0337077702644169, 0.2526708510884444, 0.2526708510884444, 0.1263354255442222, 0.1263354255442222, 0.1263354255442222, 0.2915931273291627, 0.25271404368527434, 0.17495587639749763, 0.07775816728777672, 0.0971977091097209, 0.03887908364388836, 0.03887908364388836, 0.03887908364388836, 0.418035585096992, 0.209017792548496, 0.104508896274248, 0.052254448137124, 0.104508896274248, 0.052254448137124, 0.052254448137124, 0.3242254400511395, 0.19453526403068372, 0.19453526403068372, 0.08646011734697054, 0.08646011734697054, 0.04323005867348527, 0.021615029336742635, 0.04323005867348527, 0.3496454677050587, 0.15539798564669277, 0.19424748205836595, 0.15539798564669277, 0.07769899282334639, 0.03884949641167319, 0.03884949641167319, 0.03884949641167319, 0.37838979959285707, 0.23123821086230154, 0.14715158873055553, 0.08408662213174602, 0.06306496659880952, 0.04204331106587301, 0.021021655532936504, 0.04204331106587301, 0.23957325058624984, 0.1597155003908332, 0.1597155003908332, 0.1597155003908332, 0.0798577501954166, 0.31298879558639203, 0.31298879558639203, 0.15649439779319602, 0.19685616786701535, 0.19685616786701535, 0.19685616786701535, 0.19685616786701535, 0.19685616786701535, 0.32355397044780837, 0.19911013566018976, 0.17422136870266605, 0.09955506783009488, 0.09955506783009488, 0.04977753391504744, 0.02488876695752372, 0.02488876695752372, 0.35079908811329924, 0.23386605874219948, 0.11693302937109974, 0.11693302937109974, 0.11693302937109974, 0.3064995899576188, 0.2298746924682141, 0.1532497949788094, 0.11493734623410705, 0.0766248974894047, 0.03831244874470235, 0.03831244874470235, 0.03831244874470235, 0.2963502057095828, 0.1481751028547914, 0.2222626542821871, 0.0740875514273957, 0.0740875514273957, 0.0740875514273957, 0.0740875514273957, 0.31874327798659124, 0.15937163899329562, 0.21249551865772748, 0.05312387966443187, 0.10624775932886374, 0.05312387966443187, 0.05312387966443187, 0.05312387966443187], \"Term\": [\"ability\", \"ability\", \"ability\", \"ability\", \"ability\", \"ability\", \"ability\", \"ability\", \"abuse\", \"abuse\", \"abuse\", \"abuse\", \"abuse\", \"abuse\", \"abuse\", \"abuse\", \"achieved\", \"achieved\", \"achieved\", \"achieved\", \"achieved\", \"achieved\", \"achieved\", \"achieved\", \"acid\", \"acid\", \"acid\", \"acid\", \"acid\", \"actions\", \"actions\", \"actions\", \"actions\", \"actions\", \"actions\", \"actions\", \"actions\", \"active\", \"active\", \"active\", \"active\", \"active\", \"active\", \"active\", \"active\", \"acts\", \"acts\", \"acts\", \"acts\", \"acts\", \"additional\", \"additional\", \"additional\", \"additional\", \"additional\", \"additional\", \"additional\", \"additional\", \"addressed\", \"addressed\", \"addressed\", \"addressed\", \"addressed\", \"addressed\", \"addressed\", \"addressed\", \"adequate\", \"adequate\", \"adequate\", \"adequate\", \"adequate\", \"affected\", \"affected\", \"affected\", \"affected\", \"affected\", \"affected\", \"affected\", \"affected\", \"agency\", \"agency\", \"agency\", \"agency\", \"agency\", \"agency\", \"agency\", \"agency\", \"agree\", \"agree\", \"agree\", \"agree\", \"agree\", \"agree\", \"agree\", \"agree\", \"agreed\", \"agreed\", \"agreed\", \"agreed\", \"agreed\", \"agreed\", \"agreed\", \"agreed\", \"agricultural\", \"agricultural\", \"agricultural\", \"agricultural\", \"agricultural\", \"agricultural\", \"agricultural\", \"agricultural\", \"aimed\", \"aimed\", \"aimed\", \"aimed\", \"aimed\", \"aimed\", \"aimed\", \"aimed\", \"aims\", \"aims\", \"aims\", \"aims\", \"aims\", \"alleviation\", \"alleviation\", \"alleviation\", \"alleviation\", \"alleviation\", \"alleviation\", \"alleviation\", \"alliance\", \"alliance\", \"alliance\", \"alliance\", \"alliance\", \"alliance\", \"alliance\", \"allocated\", \"allocated\", \"allocated\", \"allocated\", \"allocated\", \"allocated\", \"allocated\", \"allocated\", \"allocations\", \"allocations\", \"allocations\", \"allocations\", \"allocations\", \"amount\", \"amount\", \"amount\", \"amount\", \"amount\", \"amount\", \"amount\", \"anc\", \"anc\", \"anc\", \"anc\", \"anc\", \"anc\", \"anc\", \"anniversary\", \"anniversary\", \"anniversary\", \"anniversary\", \"anniversary\", \"anniversary\", \"anniversary\", \"anniversary\", \"applies\", \"applies\", \"applies\", \"applies\", \"applies\", \"applies\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"arise\", \"arise\", \"arise\", \"arise\", \"arise\", \"around\", \"around\", \"around\", \"around\", \"around\", \"around\", \"around\", \"around\", \"asgisa\", \"asgisa\", \"asgisa\", \"asgisa\", \"asgisa\", \"asgisa\", \"asgisa\", \"asgisa\", \"attend\", \"attend\", \"attend\", \"attend\", \"attend\", \"attend\", \"attend\", \"attend\", \"attitudes\", \"attitudes\", \"attitudes\", \"attitudes\", \"attitudes\", \"attracting\", \"attracting\", \"attracting\", \"attracting\", \"attracting\", \"au\", \"au\", \"au\", \"au\", \"au\", \"au\", \"au\", \"au\", \"authorities\", \"authorities\", \"authorities\", \"authorities\", \"authorities\", \"authorities\", \"authorities\", \"authorities\", \"available\", \"available\", \"available\", \"available\", \"available\", \"available\", \"available\", \"available\", \"aware\", \"aware\", \"aware\", \"aware\", \"aware\", \"aware\", \"aware\", \"aware\", \"bank\", \"bank\", \"bank\", \"bank\", \"bank\", \"bank\", \"bank\", \"bank\", \"basis\", \"basis\", \"basis\", \"basis\", \"basis\", \"basis\", \"basis\", \"basis\", \"battle\", \"battle\", \"battle\", \"battle\", \"battle\", \"battle\", \"believe\", \"believe\", \"believe\", \"believe\", \"believe\", \"believe\", \"believe\", \"believe\", \"belongs\", \"belongs\", \"belongs\", \"belongs\", \"belongs\", \"belongs\", \"belongs\", \"belongs\", \"benefit\", \"benefit\", \"benefit\", \"benefit\", \"benefit\", \"benefit\", \"benefit\", \"benefit\", \"benefits\", \"benefits\", \"benefits\", \"benefits\", \"benefits\", \"benefits\", \"benefits\", \"benefits\", \"bill\", \"bill\", \"bill\", \"bill\", \"bill\", \"bill\", \"bill\", \"bill\", \"body\", \"body\", \"body\", \"body\", \"body\", \"bold\", \"bold\", \"bold\", \"bold\", \"bold\", \"bold\", \"born\", \"born\", \"born\", \"born\", \"born\", \"brics\", \"brics\", \"brics\", \"brics\", \"brics\", \"brics\", \"brics\", \"broad\", \"broad\", \"broad\", \"broad\", \"broad\", \"broad\", \"broad\", \"broad\", \"broadband\", \"broadband\", \"broadband\", \"broadband\", \"broadband\", \"broadband\", \"broadband\", \"broadband\", \"broaden\", \"broaden\", \"broaden\", \"broaden\", \"broaden\", \"brought\", \"brought\", \"brought\", \"brought\", \"brought\", \"brought\", \"brought\", \"brought\", \"businesses\", \"businesses\", \"businesses\", \"businesses\", \"businesses\", \"businesses\", \"businesses\", \"businesses\", \"cabinet\", \"cabinet\", \"cabinet\", \"cabinet\", \"cabinet\", \"cabinet\", \"cabinet\", \"cabinet\", \"calendar\", \"calendar\", \"calendar\", \"calendar\", \"calendar\", \"calendar\", \"capital\", \"capital\", \"capital\", \"capital\", \"capital\", \"capital\", \"capital\", \"capital\", \"capture\", \"capture\", \"capture\", \"capture\", \"capture\", \"capture\", \"capture\", \"capture\", \"carry\", \"carry\", \"carry\", \"carry\", \"carry\", \"carry\", \"carry\", \"carry\", \"catalyst\", \"catalyst\", \"catalyst\", \"catalyst\", \"catalyst\", \"cent\", \"cent\", \"cent\", \"cent\", \"cent\", \"cent\", \"cent\", \"cent\", \"centre\", \"centre\", \"centre\", \"centre\", \"centre\", \"centre\", \"centre\", \"centre\", \"centres\", \"centres\", \"centres\", \"centres\", \"centres\", \"centres\", \"centres\", \"centres\", \"certainty\", \"certainty\", \"certainty\", \"certainty\", \"certainty\", \"certainty\", \"certainty\", \"challenging\", \"challenging\", \"challenging\", \"challenging\", \"challenging\", \"challenging\", \"challenging\", \"changes\", \"changes\", \"changes\", \"changes\", \"changes\", \"changes\", \"changes\", \"changes\", \"changing\", \"changing\", \"changing\", \"changing\", \"changing\", \"changing\", \"changing\", \"changing\", \"chief\", \"chief\", \"chief\", \"chief\", \"chief\", \"chief\", \"chief\", \"chief\", \"child\", \"child\", \"child\", \"child\", \"child\", \"child\", \"child\", \"child\", \"childhood\", \"childhood\", \"childhood\", \"childhood\", \"childhood\", \"childhood\", \"childhood\", \"civil\", \"civil\", \"civil\", \"civil\", \"civil\", \"civil\", \"civil\", \"civil\", \"clear\", \"clear\", \"clear\", \"clear\", \"clear\", \"clear\", \"clear\", \"clear\", \"colleges\", \"colleges\", \"colleges\", \"colleges\", \"colleges\", \"colleges\", \"colleges\", \"colleges\", \"comes\", \"comes\", \"comes\", \"comes\", \"comes\", \"comes\", \"coming\", \"coming\", \"coming\", \"coming\", \"coming\", \"coming\", \"coming\", \"coming\", \"commitments\", \"commitments\", \"commitments\", \"commitments\", \"commitments\", \"commitments\", \"commitments\", \"commitments\", \"committee\", \"committee\", \"committee\", \"committee\", \"committee\", \"committee\", \"committee\", \"committee\", \"compatriots\", \"compatriots\", \"compatriots\", \"compatriots\", \"compatriots\", \"compatriots\", \"compatriots\", \"compatriots\", \"compensation\", \"compensation\", \"compensation\", \"compensation\", \"compensation\", \"competitiveness\", \"competitiveness\", \"competitiveness\", \"competitiveness\", \"competitiveness\", \"competitiveness\", \"competitiveness\", \"competitiveness\", \"complete\", \"complete\", \"complete\", \"complete\", \"complete\", \"complete\", \"complete\", \"complete\", \"concerns\", \"concerns\", \"concerns\", \"concerns\", \"concerns\", \"concerns\", \"concerns\", \"concerns\", \"conference\", \"conference\", \"conference\", \"conference\", \"conference\", \"conference\", \"conference\", \"conference\", \"confidence\", \"confidence\", \"confidence\", \"confidence\", \"confidence\", \"confidence\", \"confidence\", \"confidence\", \"confident\", \"confident\", \"confident\", \"confident\", \"confident\", \"confident\", \"confident\", \"confident\", \"conflict\", \"conflict\", \"conflict\", \"conflict\", \"conflict\", \"conflict\", \"conflict\", \"conflict\", \"confront\", \"confront\", \"confront\", \"confront\", \"confront\", \"confront\", \"confront\", \"confront\", \"congratulate\", \"congratulate\", \"congratulate\", \"congratulate\", \"congratulate\", \"congratulate\", \"congratulate\", \"congratulate\", \"consequence\", \"consequence\", \"consequence\", \"consequence\", \"consequence\", \"consultations\", \"consultations\", \"consultations\", \"consultations\", \"consultations\", \"consultations\", \"consultations\", \"consultations\", \"contain\", \"contain\", \"contain\", \"contain\", \"contain\", \"contain\", \"context\", \"context\", \"context\", \"context\", \"context\", \"context\", \"context\", \"context\", \"continued\", \"continued\", \"continued\", \"continued\", \"continued\", \"continued\", \"continued\", \"continued\", \"contractors\", \"contractors\", \"contractors\", \"contractors\", \"controls\", \"controls\", \"controls\", \"controls\", \"controls\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"councillors\", \"councillors\", \"councillors\", \"councillors\", \"councillors\", \"councils\", \"councils\", \"councils\", \"councils\", \"councils\", \"courts\", \"courts\", \"courts\", \"courts\", \"courts\", \"courts\", \"courts\", \"courts\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"crimes\", \"crimes\", \"crimes\", \"crimes\", \"crimes\", \"crimes\", \"crimes\", \"crimes\", \"criminal\", \"criminal\", \"criminal\", \"criminal\", \"criminal\", \"criminal\", \"criminal\", \"criminal\", \"crisis\", \"crisis\", \"crisis\", \"crisis\", \"crisis\", \"crisis\", \"crisis\", \"crisis\", \"cup\", \"cup\", \"cup\", \"cup\", \"cup\", \"cup\", \"cup\", \"cup\", \"current\", \"current\", \"current\", \"current\", \"current\", \"current\", \"current\", \"current\", \"currently\", \"currently\", \"currently\", \"currently\", \"currently\", \"currently\", \"currently\", \"currently\", \"cut\", \"cut\", \"cut\", \"cut\", \"cut\", \"cut\", \"cut\", \"dealt\", \"dealt\", \"dealt\", \"dealt\", \"dealt\", \"debt\", \"debt\", \"debt\", \"debt\", \"debt\", \"debt\", \"debt\", \"debt\", \"decade\", \"decade\", \"decade\", \"decade\", \"decade\", \"decade\", \"decade\", \"decade\", \"decades\", \"decades\", \"decades\", \"decades\", \"decades\", \"decades\", \"decades\", \"decades\", \"decisive\", \"decisive\", \"decisive\", \"decisive\", \"decisive\", \"decisive\", \"decisive\", \"decisive\", \"deeds\", \"deeds\", \"deeds\", \"deeds\", \"deeds\", \"deeds\", \"deeds\", \"defence\", \"defence\", \"defence\", \"defence\", \"defence\", \"defence\", \"defence\", \"defence\", \"demand\", \"demand\", \"demand\", \"demand\", \"demand\", \"demand\", \"demand\", \"demand\", \"deserves\", \"deserves\", \"deserves\", \"deserves\", \"deserves\", \"devastation\", \"devastation\", \"devastation\", \"devastation\", \"devastation\", \"developing\", \"developing\", \"developing\", \"developing\", \"developing\", \"developing\", \"developing\", \"developing\", \"developmental\", \"developmental\", \"developmental\", \"developmental\", \"developmental\", \"developmental\", \"developmental\", \"developmental\", \"difficult\", \"difficult\", \"difficult\", \"difficult\", \"difficult\", \"difficult\", \"difficult\", \"difficult\", \"direct\", \"direct\", \"direct\", \"direct\", \"direct\", \"direct\", \"direct\", \"direct\", \"disabilities\", \"disabilities\", \"disabilities\", \"disabilities\", \"disabilities\", \"disabilities\", \"disabilities\", \"disabilities\", \"disability\", \"disability\", \"disability\", \"disability\", \"disability\", \"disability\", \"disability\", \"disability\", \"discuss\", \"discuss\", \"discuss\", \"discuss\", \"discuss\", \"diversity\", \"diversity\", \"diversity\", \"diversity\", \"diversity\", \"diversity\", \"dr\", \"dr\", \"dr\", \"dr\", \"dr\", \"dr\", \"dr\", \"dr\", \"drive\", \"drive\", \"drive\", \"drive\", \"drive\", \"drive\", \"drive\", \"drive\", \"early\", \"early\", \"early\", \"early\", \"early\", \"early\", \"early\", \"early\", \"earnings\", \"earnings\", \"earnings\", \"earnings\", \"earnings\", \"eastern\", \"eastern\", \"eastern\", \"eastern\", \"eastern\", \"eastern\", \"eastern\", \"eastern\", \"effectiveness\", \"effectiveness\", \"effectiveness\", \"effectiveness\", \"effectiveness\", \"effectiveness\", \"effectiveness\", \"effectiveness\", \"election\", \"election\", \"election\", \"election\", \"election\", \"election\", \"election\", \"election\", \"elections\", \"elections\", \"elections\", \"elections\", \"elections\", \"elections\", \"elections\", \"elections\", \"elements\", \"elements\", \"elements\", \"elements\", \"elements\", \"elements\", \"elements\", \"elements\", \"engagements\", \"engagements\", \"engagements\", \"engagements\", \"engagements\", \"ensured\", \"ensured\", \"ensured\", \"ensured\", \"ensured\", \"ensured\", \"eskom\", \"eskom\", \"eskom\", \"eskom\", \"eskom\", \"eskom\", \"eskom\", \"eskom\", \"establish\", \"establish\", \"establish\", \"establish\", \"establish\", \"establish\", \"establish\", \"establish\", \"evolution\", \"evolution\", \"evolution\", \"evolution\", \"evolution\", \"evolution\", \"evolved\", \"evolved\", \"evolved\", \"evolved\", \"evolved\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"exchange\", \"exchange\", \"exchange\", \"exchange\", \"exchange\", \"exchange\", \"exchange\", \"exchange\", \"expectancy\", \"expectancy\", \"expectancy\", \"expectancy\", \"expectancy\", \"expectations\", \"expectations\", \"expectations\", \"expectations\", \"expectations\", \"expectations\", \"extend\", \"extend\", \"extend\", \"extend\", \"extend\", \"extend\", \"extend\", \"extend\", \"extension\", \"extension\", \"extension\", \"extension\", \"extension\", \"extension\", \"extension\", \"extension\", \"eyes\", \"eyes\", \"eyes\", \"eyes\", \"eyes\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"faith\", \"faith\", \"faith\", \"faith\", \"faith\", \"farmers\", \"farmers\", \"farmers\", \"farmers\", \"farmers\", \"farmers\", \"farmers\", \"farmers\", \"farms\", \"farms\", \"farms\", \"farms\", \"farms\", \"farms\", \"faster\", \"faster\", \"faster\", \"faster\", \"faster\", \"faster\", \"faster\", \"faster\", \"favourable\", \"favourable\", \"favourable\", \"favourable\", \"favourable\", \"fellow\", \"fellow\", \"fellow\", \"fellow\", \"fellow\", \"fellow\", \"fellow\", \"fellow\", \"field\", \"field\", \"field\", \"field\", \"field\", \"field\", \"field\", \"finalised\", \"finalised\", \"finalised\", \"finalised\", \"finalised\", \"finalised\", \"finalised\", \"finalised\", \"financing\", \"financing\", \"financing\", \"financing\", \"financing\", \"financing\", \"financing\", \"financing\", \"find\", \"find\", \"find\", \"find\", \"find\", \"find\", \"find\", \"find\", \"firmly\", \"firmly\", \"firmly\", \"firmly\", \"firmly\", \"firmly\", \"firmly\", \"firmly\", \"focuses\", \"focuses\", \"focuses\", \"focuses\", \"focuses\", \"food\", \"food\", \"food\", \"food\", \"food\", \"food\", \"food\", \"food\", \"formal\", \"formal\", \"formal\", \"formal\", \"formal\", \"formal\", \"former\", \"former\", \"former\", \"former\", \"former\", \"former\", \"former\", \"former\", \"foundation\", \"foundation\", \"foundation\", \"foundation\", \"foundation\", \"foundation\", \"foundation\", \"foundation\", \"frames\", \"frames\", \"frames\", \"frames\", \"frames\", \"frene\", \"frene\", \"frene\", \"frene\", \"frene\", \"fulfil\", \"fulfil\", \"fulfil\", \"fulfil\", \"fulfil\", \"fulfil\", \"fulfil\", \"functioning\", \"functioning\", \"functioning\", \"functioning\", \"functioning\", \"functioning\", \"functioning\", \"functioning\", \"funding\", \"funding\", \"funding\", \"funding\", \"funding\", \"funding\", \"funding\", \"funding\", \"funds\", \"funds\", \"funds\", \"funds\", \"funds\", \"funds\", \"funds\", \"funds\", \"gauteng\", \"gauteng\", \"gauteng\", \"gauteng\", \"gauteng\", \"gauteng\", \"gauteng\", \"gauteng\", \"general\", \"general\", \"general\", \"general\", \"general\", \"general\", \"general\", \"general\", \"george\", \"george\", \"george\", \"george\", \"george\", \"governance\", \"governance\", \"governance\", \"governance\", \"governance\", \"governance\", \"governance\", \"governance\", \"group\", \"group\", \"group\", \"group\", \"group\", \"group\", \"group\", \"group\", \"groupings\", \"groupings\", \"groupings\", \"groupings\", \"grows\", \"grows\", \"grows\", \"grows\", \"grows\", \"guest\", \"guest\", \"guest\", \"guest\", \"guest\", \"guest\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"hardship\", \"hardship\", \"hardship\", \"hardship\", \"hardship\", \"head\", \"head\", \"head\", \"head\", \"head\", \"head\", \"head\", \"healthier\", \"healthier\", \"healthier\", \"healthier\", \"healthier\", \"historic\", \"historic\", \"historic\", \"historic\", \"historic\", \"historic\", \"historic\", \"historic\", \"historical\", \"historical\", \"historical\", \"historical\", \"historical\", \"historical\", \"historical\", \"host\", \"host\", \"host\", \"host\", \"host\", \"host\", \"host\", \"host\", \"house\", \"house\", \"house\", \"house\", \"house\", \"house\", \"house\", \"house\", \"households\", \"households\", \"households\", \"households\", \"households\", \"households\", \"households\", \"households\", \"houses\", \"houses\", \"houses\", \"houses\", \"houses\", \"houses\", \"houses\", \"houses\", \"huge\", \"huge\", \"huge\", \"huge\", \"huge\", \"huge\", \"huge\", \"huge\", \"hundred\", \"hundred\", \"hundred\", \"hundred\", \"hundred\", \"hundred\", \"hundred\", \"hundred\", \"hydrogen\", \"hydrogen\", \"hydrogen\", \"hydrogen\", \"hydrogen\", \"ideals\", \"ideals\", \"ideals\", \"ideals\", \"ideals\", \"immediate\", \"immediate\", \"immediate\", \"immediate\", \"immediate\", \"immediate\", \"immediate\", \"immediate\", \"impetus\", \"impetus\", \"impetus\", \"impetus\", \"impetus\", \"impetus\", \"implemented\", \"implemented\", \"implemented\", \"implemented\", \"implemented\", \"implemented\", \"implemented\", \"implemented\", \"implementing\", \"implementing\", \"implementing\", \"implementing\", \"implementing\", \"implementing\", \"implementing\", \"implementing\", \"improvement\", \"improvement\", \"improvement\", \"improvement\", \"improvement\", \"improvement\", \"improvement\", \"improvement\", \"improvements\", \"improvements\", \"improvements\", \"improvements\", \"improvements\", \"improvements\", \"improvements\", \"improvements\", \"inclusive\", \"inclusive\", \"inclusive\", \"inclusive\", \"inclusive\", \"inclusive\", \"inclusive\", \"inclusive\", \"increased\", \"increased\", \"increased\", \"increased\", \"increased\", \"increased\", \"increased\", \"increased\", \"indeed\", \"indeed\", \"indeed\", \"indeed\", \"indeed\", \"indeed\", \"indeed\", \"indeed\", \"industries\", \"industries\", \"industries\", \"industries\", \"industries\", \"industries\", \"industries\", \"industries\", \"inequality\", \"inequality\", \"inequality\", \"inequality\", \"inequality\", \"inequality\", \"inequality\", \"inequality\", \"inflows\", \"inflows\", \"inflows\", \"inflows\", \"inflows\", \"informed\", \"informed\", \"informed\", \"informed\", \"informed\", \"informed\", \"informed\", \"informed\", \"institution\", \"institution\", \"institution\", \"institution\", \"institution\", \"institution\", \"institution\", \"institution\", \"integral\", \"integral\", \"integral\", \"integral\", \"integral\", \"intensified\", \"intensified\", \"intensified\", \"intensified\", \"intensified\", \"intensified\", \"intensified\", \"intensified\", \"intensify\", \"intensify\", \"intensify\", \"intensify\", \"intensify\", \"intensify\", \"intensify\", \"intensify\", \"interactions\", \"interactions\", \"interactions\", \"interactions\", \"interactions\", \"intervene\", \"intervene\", \"intervene\", \"intervene\", \"intervene\", \"investments\", \"investments\", \"investments\", \"investments\", \"investments\", \"investments\", \"investments\", \"investments\", \"investors\", \"investors\", \"investors\", \"investors\", \"investors\", \"investors\", \"investors\", \"investors\", \"involvement\", \"involvement\", \"involvement\", \"involvement\", \"involvement\", \"involvement\", \"involvement\", \"involvement\", \"joint\", \"joint\", \"joint\", \"joint\", \"joint\", \"joint\", \"joint\", \"joint\", \"key\", \"key\", \"key\", \"key\", \"key\", \"key\", \"key\", \"key\", \"kwazulunatal\", \"kwazulunatal\", \"kwazulunatal\", \"kwazulunatal\", \"kwazulunatal\", \"kwazulunatal\", \"kwazulunatal\", \"kwazulunatal\", \"languages\", \"languages\", \"languages\", \"languages\", \"languages\", \"largest\", \"largest\", \"largest\", \"largest\", \"largest\", \"largest\", \"largest\", \"largest\", \"law\", \"law\", \"law\", \"law\", \"law\", \"law\", \"law\", \"law\", \"leaks\", \"leaks\", \"leaks\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"leave\", \"leave\", \"leave\", \"leave\", \"leave\", \"led\", \"led\", \"led\", \"led\", \"led\", \"led\", \"led\", \"led\", \"left\", \"left\", \"left\", \"left\", \"left\", \"left\", \"legal\", \"legal\", \"legal\", \"legal\", \"legal\", \"legal\", \"legal\", \"legal\", \"liberation\", \"liberation\", \"liberation\", \"liberation\", \"liberation\", \"liberation\", \"liberation\", \"liberation\", \"licence\", \"licence\", \"licence\", \"licence\", \"licence\", \"line\", \"line\", \"line\", \"line\", \"line\", \"line\", \"line\", \"line\", \"livestock\", \"livestock\", \"livestock\", \"livestock\", \"livestock\", \"living\", \"living\", \"living\", \"living\", \"living\", \"living\", \"living\", \"living\", \"located\", \"located\", \"located\", \"located\", \"located\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"machel\", \"machel\", \"machel\", \"machel\", \"machel\", \"machel\", \"madiba\", \"madiba\", \"madiba\", \"madiba\", \"madiba\", \"madiba\", \"madiba\", \"madiba\", \"mandate\", \"mandate\", \"mandate\", \"mandate\", \"mandate\", \"mandate\", \"mandate\", \"mandate\", \"manufacturing\", \"manufacturing\", \"manufacturing\", \"manufacturing\", \"manufacturing\", \"manufacturing\", \"manufacturing\", \"manufacturing\", \"maputo\", \"maputo\", \"maputo\", \"maputo\", \"maputo\", \"marks\", \"marks\", \"marks\", \"marks\", \"marks\", \"maths\", \"maths\", \"maths\", \"maths\", \"maths\", \"matters\", \"matters\", \"matters\", \"matters\", \"matters\", \"matters\", \"matters\", \"matters\", \"media\", \"media\", \"media\", \"media\", \"media\", \"media\", \"media\", \"media\", \"medicines\", \"medicines\", \"medicines\", \"medicines\", \"medicines\", \"meerkat\", \"meerkat\", \"meerkat\", \"meerkat\", \"meerkat\", \"meeting\", \"meeting\", \"meeting\", \"meeting\", \"meeting\", \"meeting\", \"meeting\", \"meeting\", \"mere\", \"mere\", \"mere\", \"mere\", \"mere\", \"mere\", \"mere\", \"mere\", \"millions\", \"millions\", \"millions\", \"millions\", \"millions\", \"millions\", \"millions\", \"millions\", \"mind\", \"mind\", \"mind\", \"mind\", \"mind\", \"mind\", \"mind\", \"mind\", \"minimise\", \"minimise\", \"minimise\", \"minimise\", \"minimise\", \"mining\", \"mining\", \"mining\", \"mining\", \"mining\", \"mining\", \"mining\", \"mining\", \"ministers\", \"ministers\", \"ministers\", \"ministers\", \"ministers\", \"ministers\", \"ministers\", \"ministers\", \"miss\", \"miss\", \"miss\", \"miss\", \"miss\", \"mogoeng\", \"mogoeng\", \"mogoeng\", \"mogoeng\", \"mogoeng\", \"mogoeng\", \"moral\", \"moral\", \"moral\", \"moral\", \"moral\", \"moral\", \"moral\", \"moral\", \"morality\", \"morality\", \"morality\", \"morality\", \"morality\", \"movement\", \"movement\", \"movement\", \"movement\", \"movement\", \"movement\", \"movement\", \"movement\", \"municipal\", \"municipal\", \"municipal\", \"municipal\", \"municipal\", \"municipal\", \"municipal\", \"municipal\", \"municipalities\", \"municipalities\", \"municipalities\", \"municipalities\", \"municipalities\", \"municipalities\", \"municipalities\", \"municipalities\", \"municipality\", \"municipality\", \"municipality\", \"municipality\", \"municipality\", \"municipality\", \"municipality\", \"municipality\", \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", \"nationally\", \"nationally\", \"nationally\", \"nationally\", \"nationally\", \"nd\", \"nd\", \"nd\", \"nd\", \"necessary\", \"necessary\", \"necessary\", \"necessary\", \"necessary\", \"necessary\", \"necessary\", \"necessary\", \"negotiations\", \"negotiations\", \"negotiations\", \"negotiations\", \"negotiations\", \"negotiations\", \"negotiations\", \"negotiations\", \"neither\", \"neither\", \"neither\", \"neither\", \"neither\", \"neither\", \"north\", \"north\", \"north\", \"north\", \"north\", \"north\", \"north\", \"north\", \"northern\", \"northern\", \"northern\", \"northern\", \"northern\", \"northern\", \"northern\", \"northern\", \"nuclear\", \"nuclear\", \"nuclear\", \"nuclear\", \"nuclear\", \"nuclear\", \"nuclear\", \"nuclear\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"numbers\", \"numbers\", \"numbers\", \"numbers\", \"numbers\", \"numbers\", \"numbers\", \"numbers\", \"nutrition\", \"nutrition\", \"nutrition\", \"nutrition\", \"nutrition\", \"nutrition\", \"nutrition\", \"objective\", \"objective\", \"objective\", \"objective\", \"objective\", \"objective\", \"objective\", \"objective\", \"objectives\", \"objectives\", \"objectives\", \"objectives\", \"objectives\", \"objectives\", \"objectives\", \"objectives\", \"obligations\", \"obligations\", \"obligations\", \"obligations\", \"obligations\", \"obligations\", \"obligations\", \"obligations\", \"obstacles\", \"obstacles\", \"obstacles\", \"obstacles\", \"obstacles\", \"obstacles\", \"occasion\", \"occasion\", \"occasion\", \"occasion\", \"occasion\", \"occasion\", \"occasion\", \"occasion\", \"occupy\", \"occupy\", \"occupy\", \"occupy\", \"occupy\", \"offering\", \"offering\", \"offering\", \"offering\", \"offering\", \"oil\", \"oil\", \"oil\", \"oil\", \"oil\", \"operations\", \"operations\", \"operations\", \"operations\", \"operations\", \"operations\", \"operations\", \"operations\", \"opposition\", \"opposition\", \"opposition\", \"opposition\", \"opposition\", \"orders\", \"orders\", \"orders\", \"orders\", \"orders\", \"ordinary\", \"ordinary\", \"ordinary\", \"ordinary\", \"ordinary\", \"ordinary\", \"ordinary\", \"ordinary\", \"outcomes\", \"outcomes\", \"outcomes\", \"outcomes\", \"outcomes\", \"outcomes\", \"outcomes\", \"outcomes\", \"pain\", \"pain\", \"pain\", \"pain\", \"pain\", \"pain\", \"pandemic\", \"pandemic\", \"pandemic\", \"pandemic\", \"pandemic\", \"pandemic\", \"pandemic\", \"pandemic\", \"parameters\", \"parameters\", \"parameters\", \"parameters\", \"parameters\", \"participate\", \"participate\", \"participate\", \"participate\", \"participate\", \"participate\", \"participate\", \"participate\", \"particularly\", \"particularly\", \"particularly\", \"particularly\", \"particularly\", \"particularly\", \"particularly\", \"particularly\", \"parties\", \"parties\", \"parties\", \"parties\", \"parties\", \"parties\", \"parties\", \"parties\", \"partnerships\", \"partnerships\", \"partnerships\", \"partnerships\", \"partnerships\", \"partnerships\", \"partnerships\", \"partnerships\", \"party\", \"party\", \"party\", \"party\", \"party\", \"party\", \"party\", \"party\", \"path\", \"path\", \"path\", \"path\", \"path\", \"path\", \"path\", \"path\", \"patriotism\", \"patriotism\", \"patriotism\", \"patriotism\", \"patriotism\", \"patriotism\", \"patriotism\", \"patriotism\", \"per\", \"per\", \"per\", \"per\", \"per\", \"per\", \"per\", \"per\", \"percent\", \"percent\", \"percent\", \"percent\", \"percent\", \"percent\", \"percent\", \"percent\", \"petroleum\", \"petroleum\", \"petroleum\", \"petroleum\", \"petroleum\", \"pilot\", \"pilot\", \"pilot\", \"pilot\", \"pilot\", \"plan\", \"plan\", \"plan\", \"plan\", \"plan\", \"plan\", \"plan\", \"plan\", \"plays\", \"plays\", \"plays\", \"plays\", \"plays\", \"plays\", \"pleased\", \"pleased\", \"pleased\", \"pleased\", \"pleased\", \"pleased\", \"pleased\", \"pleased\", \"plumbers\", \"plumbers\", \"plumbers\", \"plumbers\", \"plumbers\", \"position\", \"position\", \"position\", \"position\", \"position\", \"position\", \"position\", \"position\", \"positive\", \"positive\", \"positive\", \"positive\", \"positive\", \"positive\", \"positive\", \"positive\", \"possible\", \"possible\", \"possible\", \"possible\", \"possible\", \"possible\", \"possible\", \"possible\", \"potential\", \"potential\", \"potential\", \"potential\", \"potential\", \"potential\", \"potential\", \"potential\", \"practice\", \"practice\", \"practice\", \"practice\", \"practice\", \"practice\", \"practice\", \"practice\", \"preferential\", \"preferential\", \"preferential\", \"preferential\", \"preferential\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"preserve\", \"preserve\", \"preserve\", \"preserve\", \"preserve\", \"presidential\", \"presidential\", \"presidential\", \"presidential\", \"presidential\", \"presidential\", \"presidential\", \"presidential\", \"presidents\", \"presidents\", \"presidents\", \"presidents\", \"presidents\", \"presidents\", \"presidents\", \"pretoria\", \"pretoria\", \"pretoria\", \"pretoria\", \"pretoria\", \"pretoria\", \"prevent\", \"prevent\", \"prevent\", \"prevent\", \"prevent\", \"prevent\", \"prevent\", \"prevent\", \"prevention\", \"prevention\", \"prevention\", \"prevention\", \"prevention\", \"prevention\", \"prevention\", \"prevention\", \"principle\", \"principle\", \"principle\", \"principle\", \"principle\", \"principle\", \"principle\", \"principle\", \"priority\", \"priority\", \"priority\", \"priority\", \"priority\", \"priority\", \"priority\", \"priority\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"procurement\", \"procurement\", \"procurement\", \"procurement\", \"procurement\", \"procurement\", \"procurement\", \"procurement\", \"producers\", \"producers\", \"producers\", \"producers\", \"producers\", \"producers\", \"producers\", \"producers\", \"project\", \"project\", \"project\", \"project\", \"project\", \"project\", \"project\", \"project\", \"promotes\", \"promotes\", \"promotes\", \"promotes\", \"promotes\", \"prospects\", \"prospects\", \"prospects\", \"prospects\", \"proteas\", \"proteas\", \"proteas\", \"proteas\", \"proteas\", \"proud\", \"proud\", \"proud\", \"proud\", \"proud\", \"proud\", \"proud\", \"proud\", \"pursuit\", \"pursuit\", \"pursuit\", \"pursuit\", \"pursuit\", \"pursuit\", \"pursuit\", \"pursuit\", \"question\", \"question\", \"question\", \"question\", \"question\", \"question\", \"question\", \"question\", \"raising\", \"raising\", \"raising\", \"raising\", \"raising\", \"raising\", \"raising\", \"rand\", \"rand\", \"rand\", \"rand\", \"rand\", \"rand\", \"rand\", \"rand\", \"ranks\", \"ranks\", \"ranks\", \"ranks\", \"ranks\", \"rates\", \"rates\", \"rates\", \"rates\", \"rates\", \"rates\", \"rates\", \"rates\", \"rather\", \"rather\", \"rather\", \"rather\", \"rather\", \"rather\", \"rather\", \"rather\", \"reading\", \"reading\", \"reading\", \"reading\", \"reading\", \"reading\", \"reading\", \"ready\", \"ready\", \"ready\", \"ready\", \"ready\", \"ready\", \"ready\", \"ready\", \"received\", \"received\", \"received\", \"received\", \"received\", \"received\", \"received\", \"received\", \"recently\", \"recently\", \"recently\", \"recently\", \"recently\", \"recently\", \"recently\", \"recession\", \"recession\", \"recession\", \"recession\", \"recession\", \"recognised\", \"recognised\", \"recognised\", \"recognised\", \"recognised\", \"reconstruction\", \"reconstruction\", \"reconstruction\", \"reconstruction\", \"reconstruction\", \"reconstruction\", \"reconstruction\", \"reconstruction\", \"recovery\", \"recovery\", \"recovery\", \"recovery\", \"recovery\", \"recovery\", \"recovery\", \"recovery\", \"redistribution\", \"redistribution\", \"redistribution\", \"redistribution\", \"redistribution\", \"redistribution\", \"redistribution\", \"redistribution\", \"reduction\", \"reduction\", \"reduction\", \"reduction\", \"reduction\", \"reduction\", \"reduction\", \"reduction\", \"reform\", \"reform\", \"reform\", \"reform\", \"reform\", \"reform\", \"reform\", \"reform\", \"refurbishment\", \"refurbishment\", \"refurbishment\", \"refurbishment\", \"refurbishment\", \"refused\", \"refused\", \"refused\", \"refused\", \"refused\", \"related\", \"related\", \"related\", \"related\", \"related\", \"related\", \"related\", \"related\", \"relations\", \"relations\", \"relations\", \"relations\", \"relations\", \"relations\", \"relations\", \"relations\", \"relationship\", \"relationship\", \"relationship\", \"relationship\", \"relationship\", \"relationship\", \"relationship\", \"republic\", \"republic\", \"republic\", \"republic\", \"republic\", \"republic\", \"republic\", \"republic\", \"respond\", \"respond\", \"respond\", \"respond\", \"respond\", \"respond\", \"respond\", \"respond\", \"rest\", \"rest\", \"rest\", \"rest\", \"rest\", \"rest\", \"rest\", \"rest\", \"restructuring\", \"restructuring\", \"restructuring\", \"restructuring\", \"restructuring\", \"restructuring\", \"restructuring\", \"restructuring\", \"results\", \"results\", \"results\", \"results\", \"results\", \"results\", \"results\", \"results\", \"rich\", \"rich\", \"rich\", \"rich\", \"rich\", \"rich\", \"rise\", \"rise\", \"rise\", \"rise\", \"rise\", \"rise\", \"rise\", \"rise\", \"road\", \"road\", \"road\", \"road\", \"road\", \"road\", \"road\", \"road\", \"roads\", \"roads\", \"roads\", \"roads\", \"roads\", \"roads\", \"roads\", \"roads\", \"robotics\", \"robotics\", \"robotics\", \"room\", \"room\", \"room\", \"room\", \"room\", \"sanitation\", \"sanitation\", \"sanitation\", \"sanitation\", \"sanitation\", \"sanitation\", \"sanitation\", \"sanitation\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"scaling\", \"scaling\", \"scaling\", \"scaling\", \"scaling\", \"second\", \"second\", \"second\", \"second\", \"second\", \"second\", \"second\", \"second\", \"secured\", \"secured\", \"secured\", \"secured\", \"secured\", \"sefako\", \"sefako\", \"sefako\", \"sefako\", \"sefako\", \"serious\", \"serious\", \"serious\", \"serious\", \"serious\", \"serious\", \"serious\", \"serious\", \"seriously\", \"seriously\", \"seriously\", \"seriously\", \"seriously\", \"serve\", \"serve\", \"serve\", \"serve\", \"serve\", \"serve\", \"serve\", \"serve\", \"setas\", \"setas\", \"setas\", \"setas\", \"setas\", \"shall\", \"shall\", \"shall\", \"shall\", \"shall\", \"shall\", \"shall\", \"shall\", \"shared\", \"shared\", \"shared\", \"shared\", \"shared\", \"shared\", \"shared\", \"shared\", \"shortage\", \"shortage\", \"shortage\", \"shortage\", \"shortage\", \"shortage\", \"shows\", \"shows\", \"shows\", \"shows\", \"shows\", \"slow\", \"slow\", \"slow\", \"slow\", \"slow\", \"slow\", \"smme\", \"smme\", \"smme\", \"smme\", \"smme\", \"solutions\", \"solutions\", \"solutions\", \"solutions\", \"solutions\", \"solutions\", \"solutions\", \"solutions\", \"someone\", \"someone\", \"someone\", \"someone\", \"someone\", \"somewhat\", \"somewhat\", \"somewhat\", \"somewhat\", \"somewhat\", \"speak\", \"speak\", \"speak\", \"speak\", \"speak\", \"speak\", \"speak\", \"speak\", \"specific\", \"specific\", \"specific\", \"specific\", \"specific\", \"specific\", \"specific\", \"specific\", \"speech\", \"speech\", \"speech\", \"speech\", \"speech\", \"speech\", \"speech\", \"speech\", \"spending\", \"spending\", \"spending\", \"spending\", \"spending\", \"spending\", \"spending\", \"spending\", \"spirit\", \"spirit\", \"spirit\", \"spirit\", \"spirit\", \"spirit\", \"spirit\", \"spirit\", \"stakeholders\", \"stakeholders\", \"stakeholders\", \"stakeholders\", \"stakeholders\", \"stakeholders\", \"stakeholders\", \"stakeholders\", \"started\", \"started\", \"started\", \"started\", \"started\", \"started\", \"started\", \"started\", \"starting\", \"starting\", \"starting\", \"starting\", \"starting\", \"starting\", \"starting\", \"starting\", \"stations\", \"stations\", \"stations\", \"stations\", \"stations\", \"stations\", \"stations\", \"stations\", \"story\", \"story\", \"story\", \"story\", \"story\", \"story\", \"story\", \"streets\", \"streets\", \"streets\", \"streets\", \"streets\", \"strengthened\", \"strengthened\", \"strengthened\", \"strengthened\", \"strengthened\", \"strengthened\", \"strengthened\", \"strengthened\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structures\", \"structures\", \"structures\", \"structures\", \"structures\", \"structures\", \"structures\", \"structures\", \"struggled\", \"struggled\", \"struggled\", \"struggled\", \"struggled\", \"students\", \"students\", \"students\", \"students\", \"students\", \"students\", \"students\", \"students\", \"sudan\", \"sudan\", \"sudan\", \"sudan\", \"sudan\", \"sudan\", \"sudan\", \"sudan\", \"sugar\", \"sugar\", \"sugar\", \"sugar\", \"sugar\", \"supply\", \"supply\", \"supply\", \"supply\", \"supply\", \"supply\", \"supply\", \"supply\", \"surpassed\", \"surpassed\", \"surpassed\", \"surpassed\", \"surpassed\", \"syndicates\", \"syndicates\", \"syndicates\", \"syndicates\", \"syndicates\", \"systems\", \"systems\", \"systems\", \"systems\", \"systems\", \"systems\", \"systems\", \"systems\", \"teams\", \"teams\", \"teams\", \"teams\", \"teams\", \"teams\", \"teams\", \"teams\", \"technical\", \"technical\", \"technical\", \"technical\", \"technical\", \"technical\", \"technical\", \"technical\", \"technologies\", \"technologies\", \"technologies\", \"technologies\", \"technologies\", \"technologies\", \"technologies\", \"technologies\", \"technology\", \"technology\", \"technology\", \"technology\", \"technology\", \"technology\", \"technology\", \"technology\", \"telescope\", \"telescope\", \"telescope\", \"telescope\", \"telescope\", \"telescope\", \"telescope\", \"terms\", \"terms\", \"terms\", \"terms\", \"terms\", \"terms\", \"terms\", \"terms\", \"terrorism\", \"terrorism\", \"terrorism\", \"terrorism\", \"terrorism\", \"testing\", \"testing\", \"testing\", \"testing\", \"testing\", \"thorough\", \"thorough\", \"thorough\", \"thorough\", \"thorough\", \"thousand\", \"thousand\", \"thousand\", \"thousand\", \"thousand\", \"thousand\", \"thousand\", \"thousand\", \"tide\", \"tide\", \"tide\", \"tide\", \"tide\", \"tone\", \"tone\", \"tone\", \"tone\", \"tone\", \"tons\", \"tons\", \"tons\", \"tons\", \"tons\", \"total\", \"total\", \"total\", \"total\", \"total\", \"total\", \"total\", \"total\", \"town\", \"town\", \"town\", \"town\", \"town\", \"town\", \"town\", \"town\", \"transferred\", \"transferred\", \"transferred\", \"transferred\", \"transferred\", \"transition\", \"transition\", \"transition\", \"transition\", \"transition\", \"transition\", \"transition\", \"transition\", \"transport\", \"transport\", \"transport\", \"transport\", \"transport\", \"transport\", \"transport\", \"transport\", \"trends\", \"trends\", \"trends\", \"trends\", \"trends\", \"trends\", \"trends\", \"trends\", \"turn\", \"turn\", \"turn\", \"turn\", \"turn\", \"turn\", \"turn\", \"turn\", \"turned\", \"turned\", \"turned\", \"turned\", \"turned\", \"turned\", \"turned\", \"turned\", \"twenty\", \"twenty\", \"twenty\", \"twenty\", \"twenty\", \"undertaken\", \"undertaken\", \"undertaken\", \"undertaken\", \"undertaken\", \"undertaken\", \"undertaken\", \"undertaken\", \"unions\", \"unions\", \"unions\", \"unions\", \"unions\", \"unions\", \"unions\", \"unions\", \"upliftment\", \"upliftment\", \"upliftment\", \"upliftment\", \"upliftment\", \"urban\", \"urban\", \"urban\", \"urban\", \"urban\", \"urban\", \"urban\", \"urban\", \"urgent\", \"urgent\", \"urgent\", \"urgent\", \"urgent\", \"urgent\", \"urgent\", \"urgent\", \"utilise\", \"utilise\", \"utilise\", \"utilise\", \"utilise\", \"utilise\", \"vaccine\", \"vaccine\", \"vaccine\", \"vaccine\", \"vaccine\", \"vaccines\", \"vaccines\", \"vaccines\", \"vaccines\", \"vaccines\", \"valued\", \"valued\", \"valued\", \"valued\", \"valued\", \"van\", \"van\", \"van\", \"van\", \"van\", \"victories\", \"victories\", \"victories\", \"victories\", \"vigour\", \"vigour\", \"vigour\", \"vigour\", \"vigour\", \"vision\", \"vision\", \"vision\", \"vision\", \"vision\", \"vision\", \"vision\", \"vision\", \"visit\", \"visit\", \"visit\", \"visit\", \"visit\", \"visit\", \"visit\", \"visit\", \"vital\", \"vital\", \"vital\", \"vital\", \"vital\", \"vital\", \"vital\", \"vital\", \"voters\", \"voters\", \"voters\", \"voters\", \"voters\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"weapons\", \"weapons\", \"weapons\", \"weapons\", \"weapons\", \"weapons\", \"weapons\", \"week\", \"week\", \"week\", \"week\", \"week\", \"week\", \"week\", \"week\", \"weeks\", \"weeks\", \"weeks\", \"weeks\", \"weeks\", \"weeks\", \"weeks\", \"weeks\", \"welcome\", \"welcome\", \"welcome\", \"welcome\", \"welcome\", \"welcome\", \"welcome\", \"welcome\", \"welfare\", \"welfare\", \"welfare\", \"welfare\", \"welfare\", \"welllocated\", \"welllocated\", \"welllocated\", \"wetlands\", \"wetlands\", \"wetlands\", \"wetlands\", \"wetlands\", \"white\", \"white\", \"white\", \"white\", \"white\", \"white\", \"white\", \"white\", \"wife\", \"wife\", \"wife\", \"wife\", \"wife\", \"words\", \"words\", \"words\", \"words\", \"words\", \"words\", \"words\", \"words\", \"worst\", \"worst\", \"worst\", \"worst\", \"worst\", \"worst\", \"worst\", \"zimbabwe\", \"zimbabwe\", \"zimbabwe\", \"zimbabwe\", \"zimbabwe\", \"zimbabwe\", \"zimbabwe\", \"zimbabwe\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [5, 6, 9, 8, 1, 4, 2, 7, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el3926773574000003654059862\", ldavis_el3926773574000003654059862_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el3926773574000003654059862\", ldavis_el3926773574000003654059862_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el3926773574000003654059862\", ldavis_el3926773574000003654059862_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: true\n",
    "#| output: true\n",
    "\n",
    "# Enable the automatic display of visualizations in the Jupyter notebook\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "# Display the visualization\n",
    "pyLDAvis.display(vis_data_speeches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "23777ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el3926773574060481815930721\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el3926773574060481815930721_data = {\"mdsDat\": {\"x\": [0.0032438677983513153, -0.0032438677983513153], \"y\": [0.0, 0.0], \"topics\": [1, 2], \"cluster\": [1, 1], \"Freq\": [52.74620697666148, 47.25379302333852]}, \"tinfo\": {\"Term\": [\"require\", \"introduction\", \"block\", \"retrenchment\", \"introduce\", \"central\", \"jobs\", \"efforts\", \"laid\", \"built\", \"alive\", \"saw\", \"limiting\", \"leading\", \"plays\", \"put\", \"home\", \"comfort\", \"capacity\", \"femicide\", \"china\", \"intelligence\", \"audits\", \"families\", \"boost\", \"asserted\", \"making\", \"proposals\", \"functional\", \"healthy\", \"saw\", \"functional\", \"removal\", \"audits\", \"tolerated\", \"aid\", \"strikes\", \"nonracial\", \"israelpalestine\", \"upswing\", \"families\", \"counts\", \"break\", \"farmer\", \"relations\", \"peaceloving\", \"expansion\", \"procured\", \"arise\", \"retrenchments\", \"rd\", \"period\", \"depend\", \"taxi\", \"exclusive\", \"institute\", \"directorate\", \"volunteers\", \"unit\", \"census\", \"line\", \"govern\", \"outside\", \"sporting\", \"subject\", \"phased\", \"met\", \"water\", \"cannabis\", \"extension\", \"responses\", \"introducing\", \"highly\", \"positions\", \"proposal\", \"echelon\", \"well\", \"gone\", \"budget\", \"depends\", \"reforms\", \"gang\", \"standards\", \"various\", \"railways\", \"skilled\", \"wish\", \"reverse\", \"market\", \"economic\", \"literacy\", \"phase\", \"allocated\", \"introduce\", \"planning\", \"finally\", \"starts\", \"present\", \"guests\", \"amendments\", \"establishment\", \"maintenance\", \"accepted\", \"dealing\", \"unity\", \"reinforce\", \"laws\", \"greater\", \"lost\", \"intelligence\", \"continued\", \"considering\", \"efforts\", \"retrenchment\", \"comfort\", \"introduction\", \"built\", \"making\", \"laid\", \"guarantee\", \"fighting\", \"leading\", \"red\", \"require\", \"block\", \"virus\", \"central\", \"reducing\", \"jobs\", \"else\", \"hundreds\", \"allowed\", \"informed\", \"alive\", \"permit\", \"opportunity\", \"son\", \"disciplinary\", \"private\", \"pieces\", \"healthy\", \"plays\", \"boost\", \"scale\", \"limiting\", \"home\", \"capacity\", \"proposals\", \"put\", \"introduce\", \"china\", \"femicide\", \"asserted\", \"intelligence\", \"infrastructural\", \"professionals\", \"developing\", \"finally\", \"signs\", \"railways\", \"phase\", \"laws\", \"immediate\", \"greater\", \"presidency\", \"supported\", \"alongside\", \"maintenance\", \"governing\", \"wish\", \"continued\", \"governments\", \"currently\", \"agreement\", \"establishment\", \"reforms\", \"present\", \"planning\", \"bringing\", \"unity\", \"allow\"], \"Freq\": [132.0, 92.0, 129.0, 84.0, 289.0, 99.0, 100.0, 54.0, 63.0, 56.0, 86.0, 30.0, 115.0, 65.0, 77.0, 100.0, 89.0, 38.0, 82.0, 89.0, 85.0, 141.0, 54.0, 73.0, 60.0, 75.0, 33.0, 65.0, 28.0, 52.0, 24.43461460076709, 21.388827022737875, 7.403828905752598, 38.676421864017215, 8.443800186808332, 10.893009761956172, 5.937140714293396, 7.171008993097654, 5.858081838013106, 14.394225239245314, 50.694297824455646, 9.445221509532146, 8.228766344000139, 40.89659609814097, 34.7095673948407, 18.97952088408282, 23.699510941757236, 11.712653300402085, 6.92425008891528, 5.729551834792501, 6.919223301029021, 52.15635093660963, 23.563189688175243, 42.59729808000477, 5.692189920252652, 37.686669289895825, 9.21630368108237, 18.61216490886841, 13.886697598439543, 10.337331968892954, 42.67122932427475, 48.33463533120107, 31.943704769892754, 39.730477985540126, 89.22513411023802, 90.25555103560643, 24.01766498550298, 63.69714918117181, 45.659452409341355, 59.180799247132406, 48.72860748778588, 54.819085859817406, 67.26624442186511, 51.65200030242284, 38.52682585665053, 39.54976531523364, 51.54792916639813, 41.56111720453748, 51.27717686149329, 67.9947157045177, 98.29083084244562, 53.93088415204186, 76.36970519497501, 68.95635860412567, 150.36303610846778, 54.491074094589656, 99.86903971706066, 72.69659215729781, 72.39481986646467, 64.33525079391096, 72.71051364695248, 102.90984509530804, 61.41765859996343, 130.80629012567448, 75.69584642274452, 98.86736586731544, 61.88521529705288, 75.5646657192218, 60.94373455487581, 58.88120718959288, 75.20830758748697, 77.03516973565608, 61.136188481543336, 65.04884048417408, 66.57605056838274, 64.64340376750249, 69.17981584827125, 66.73092714079084, 62.70094925049101, 64.39407708855802, 62.77381038025448, 12.803353525773591, 36.52418487307067, 55.08123107114024, 25.287115696483397, 60.15097554577428, 36.751632016586164, 21.763523197196918, 40.54958448066972, 9.13617114832364, 10.032656108787517, 40.57253317679448, 19.152847689357966, 81.92849374427789, 79.5435794691056, 10.857421914027567, 61.071790484502124, 22.90444432484959, 61.013134525120265, 8.828935921974344, 24.854814705415947, 12.829173795469918, 13.813612829446818, 52.78438435860808, 7.782758802847659, 12.721406909607648, 5.765713933421574, 4.77129046949516, 30.570076375404085, 19.65863139695347, 31.460577770968698, 46.00183808512812, 36.14076484367343, 16.605711159922738, 66.9709254463061, 51.847573426069175, 47.94222440906446, 38.50517342550988, 57.8763069979249, 159.15583777945076, 49.478577494252555, 51.23862660864944, 43.92382827523071, 77.2159473375659, 40.11498682805621, 45.23902689034617, 72.03589143137745, 102.84007198356903, 56.56163103010536, 136.13266889486047, 101.12447476832895, 74.93364515264014, 52.97748312183585, 70.82857617780736, 61.89648013256477, 60.776085604139766, 62.7160747161312, 71.73628013579761, 56.91477335501109, 80.89840072236358, 63.3767128443952, 58.10046594331007, 55.43087912555326, 59.88678480407778, 67.13940304206217, 73.08219547913315, 65.33309217558661, 63.768817778572604, 59.487034286600085, 60.38953566407897, 58.06961482007104], \"Total\": [132.0, 92.0, 129.0, 84.0, 289.0, 99.0, 100.0, 54.0, 63.0, 56.0, 86.0, 30.0, 115.0, 65.0, 77.0, 100.0, 89.0, 38.0, 82.0, 89.0, 85.0, 141.0, 54.0, 73.0, 60.0, 75.0, 33.0, 65.0, 28.0, 52.0, 30.508235362313215, 28.361650510686648, 10.318467681208649, 54.65992141814982, 12.046097022428581, 15.5815838304824, 8.500468296976912, 10.269547192734333, 8.48225508558863, 20.851870061134964, 73.79729436374642, 13.769328979528092, 12.003006300267902, 59.65470023111614, 50.78853370404565, 27.855822090569212, 34.881685726215274, 17.265144309786066, 10.215665486658214, 8.45509737856474, 10.216022712558901, 77.11030586094923, 34.85696908292557, 63.01550473833947, 8.448430539714144, 55.94968457222795, 13.718138110694156, 27.771169770911705, 20.743378404289466, 15.465995966473796, 64.55028594615128, 73.2987505189733, 48.69302298067583, 60.90340227196, 139.28253601832958, 140.96303061002845, 36.46497624051749, 100.6835722824201, 71.22571551985243, 93.67426642419629, 76.40050007786664, 86.7062483537142, 108.99475992810262, 83.04431436343272, 60.64520566188379, 62.37910373038186, 83.02643821945077, 65.83228719476807, 82.95482050740256, 113.65506201960508, 171.37302632157878, 88.0388317508569, 130.50698149168014, 116.89604742716594, 286.4957050033282, 89.67621568962713, 180.76744043942423, 126.73290494265552, 126.64748473988453, 109.87370679992239, 129.7580633075745, 204.034319863637, 104.71829418576567, 289.96212790512527, 139.46466420131713, 201.70743785088447, 106.33533446649292, 140.89775789480842, 104.64160299146741, 99.67749612671568, 142.34771062954914, 148.77144987145368, 106.19585177959846, 117.55890967632473, 126.9655862324617, 122.02037652546352, 144.1134610009114, 137.55950331859822, 118.58910593474464, 141.6100244261239, 126.15052322464967, 19.160863804612585, 54.91159906605357, 84.39085731750708, 38.77882436287245, 92.59317699012355, 56.766383674471626, 33.97322468372819, 63.38932675709984, 14.395653933861709, 16.069771270743708, 65.3004941667898, 30.850620230793098, 132.69144558165215, 129.51389649140788, 17.76188071853018, 99.96933600962893, 37.5108305995013, 100.01668139281155, 14.478111656204993, 40.80515145477057, 21.066402711665546, 22.711148234391473, 86.90315520253904, 12.849073001913432, 21.090494935251463, 9.558935656538276, 7.911574409010203, 50.74594360662885, 32.633833961805806, 52.43442538926284, 77.22088198009703, 60.73911196447018, 27.711972073932117, 115.62104120183167, 89.06740276223661, 82.45193375163346, 65.84873762876623, 100.86276338608026, 289.96212790512527, 85.87260513302661, 89.22834832635814, 75.88890199835296, 141.6100244261239, 69.2525013244492, 79.36945231469684, 133.40907860605517, 201.70743785088447, 103.12978067365827, 286.4957050033282, 204.034319863637, 144.1134610009114, 96.41999831009336, 137.55950331859822, 116.97898751286397, 115.38172529103596, 120.59946180167829, 148.77144987145368, 106.85993101849544, 180.76744043942423, 126.15052322464967, 110.36435505359788, 103.40449916001768, 117.50212987473182, 142.34771062954914, 171.37302632157878, 140.89775789480842, 139.46466420131713, 119.54318720004991, 126.9655862324617, 116.07516831124187], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -7.7596, -7.8927, -8.9536, -7.3003, -8.8221, -8.5675, -9.1743, -8.9855, -9.1878, -8.2887, -7.0298, -8.7101, -8.8479, -7.2445, -7.4086, -8.0122, -7.7901, -8.4949, -9.0205, -9.2099, -9.0213, -7.0013, -7.7959, -7.2038, -9.2165, -7.3263, -8.7346, -8.0318, -8.3246, -8.6198, -7.202, -7.0774, -7.4916, -7.2735, -6.4644, -6.4529, -7.7768, -6.8014, -7.1344, -6.875, -7.0693, -6.9515, -6.7469, -7.011, -7.3042, -7.278, -7.0131, -7.2284, -7.0183, -6.7361, -6.3676, -6.9679, -6.62, -6.7221, -5.9425, -6.9575, -6.3517, -6.6693, -6.6734, -6.7915, -6.6691, -6.3217, -6.8379, -6.0819, -6.6289, -6.3618, -6.8303, -6.6306, -6.8456, -6.8801, -6.6353, -6.6113, -6.8425, -6.7804, -6.7572, -6.7867, -6.7189, -6.7549, -6.8172, -6.7906, -6.816, -8.2959, -7.2476, -6.8368, -7.6153, -6.7488, -7.2414, -7.7654, -7.1431, -8.6334, -8.5398, -7.1425, -7.8932, -6.4398, -6.4693, -8.4608, -6.7336, -7.7143, -6.7345, -8.6676, -7.6326, -8.2939, -8.22, -6.8794, -8.7937, -8.3023, -9.0937, -9.283, -7.4256, -7.8671, -7.3969, -7.0169, -7.2582, -8.0359, -6.6414, -6.8973, -6.9756, -7.1948, -6.7873, -5.7757, -6.9441, -6.9091, -7.0632, -6.499, -7.1539, -7.0337, -6.5684, -6.2124, -6.8103, -5.932, -6.2293, -6.529, -6.8757, -6.5854, -6.7202, -6.7384, -6.707, -6.5726, -6.8041, -6.4524, -6.6965, -6.7834, -6.8305, -6.7532, -6.6388, -6.554, -6.6661, -6.6904, -6.7599, -6.7448, -6.784], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.4177, 0.3575, 0.3077, 0.2938, 0.2844, 0.2817, 0.2808, 0.2805, 0.2695, 0.2691, 0.2642, 0.2627, 0.2622, 0.2622, 0.259, 0.256, 0.2532, 0.2517, 0.2508, 0.2505, 0.25, 0.2487, 0.2481, 0.2481, 0.2448, 0.2445, 0.2419, 0.2395, 0.2384, 0.2368, 0.2258, 0.2233, 0.2181, 0.2125, 0.1943, 0.1938, 0.2221, 0.1818, 0.195, 0.1805, 0.19, 0.1812, 0.157, 0.1648, 0.186, 0.184, 0.163, 0.1797, 0.1586, 0.1259, 0.0838, 0.1496, 0.1038, 0.1119, -0.005, 0.1415, 0.0463, 0.0839, 0.0804, 0.1045, 0.0605, -0.0448, 0.1061, -0.1564, 0.0286, -0.0734, 0.0984, 0.0166, 0.0991, 0.1133, 0.0017, -0.0185, 0.0875, 0.0479, -0.0059, 0.0044, -0.0942, -0.0837, 0.0024, -0.1484, -0.0583, 0.3465, 0.3419, 0.323, 0.3221, 0.3183, 0.3149, 0.3043, 0.3029, 0.295, 0.2785, 0.2737, 0.2729, 0.2675, 0.2622, 0.2574, 0.2568, 0.2563, 0.2554, 0.255, 0.2539, 0.2537, 0.2524, 0.2511, 0.2483, 0.2441, 0.2441, 0.2439, 0.2428, 0.2428, 0.2388, 0.2316, 0.2305, 0.2375, 0.2036, 0.2086, 0.2074, 0.2131, 0.1942, 0.1498, 0.1983, 0.1949, 0.2028, 0.1432, 0.2036, 0.1875, 0.1334, 0.076, 0.149, 0.0055, 0.0477, 0.0956, 0.1508, 0.0858, 0.1131, 0.1086, 0.0958, 0.0202, 0.1197, -0.0544, 0.0613, 0.108, 0.1261, 0.0756, -0.0019, -0.1026, -0.0189, -0.0329, 0.0517, 0.0065, 0.057]}, \"token.table\": {\"Topic\": [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2], \"Freq\": [0.5744103840006947, 0.4237453652464141, 0.49360807384371147, 0.5106290419072878, 0.7059616095303866, 0.32089164069563025, 0.3912401099909273, 0.6098742891035043, 0.5825152183226807, 0.4106254817684471, 0.4996762084762164, 0.4996762084762164, 0.37975159354425475, 0.6170963395094139, 0.4809308361208032, 0.5223903909588035, 0.5919089292230602, 0.4113265440363638, 0.6852221237218551, 0.29366662445222363, 0.42166903403997735, 0.5797949218049688, 0.7135026723080882, 0.29271904504947205, 0.38605895857142297, 0.6176943337142768, 0.41159640290137833, 0.5926988201779848, 0.6664996918164946, 0.3332498459082473, 0.5019106601164383, 0.4935454824478309, 0.6147924820770236, 0.385752145616956, 0.35232119267435713, 0.6517942064475607, 0.645834157849613, 0.3650366979149986, 0.4244897409614315, 0.5821573590328204, 0.6465797625757413, 0.3232898812878707, 0.3901196262446273, 0.6101871077159555, 0.4192256650911176, 0.5706127108184657, 0.33523450526381704, 0.6446817408919558, 0.31313828338760086, 0.6784662806731352, 0.49940339833398223, 0.49940339833398223, 0.6536266228645553, 0.2905007212731357, 0.4641964362277928, 0.531891749844346, 0.5529142808398332, 0.45083779822324865, 0.6885280227005228, 0.3155753437377396, 0.598301552008922, 0.4047334028295648, 0.4572402465961663, 0.5396934058184257, 0.656065708580666, 0.3644809492114811, 0.37919127659134566, 0.6319854609855761, 0.6412403771123426, 0.368713216839597, 0.5824869467318746, 0.41866249296353486, 0.32779959619000837, 0.6738102810572394, 0.4144186854249418, 0.6216280281374127, 0.5268788635117759, 0.47067845140385317, 0.7101910788986628, 0.3550955394493314, 0.6880401419924164, 0.31535173174652414, 0.6298421354358229, 0.36295987465793184, 0.6910822468452746, 0.3116645426949278, 0.6872886770222044, 0.31849963081516786, 0.42587362326838857, 0.5715672312286267, 0.3733718357848363, 0.6222863929747272, 0.49080986330899395, 0.5106405648568321, 0.7404364563369545, 0.2468121521123182, 0.6133657038159688, 0.38619322092116554, 0.6379848215776087, 0.36456275518720493, 0.6548542732331467, 0.34106993397559726, 0.46790222980160767, 0.5334085419738328, 0.4711666187397776, 0.5255319978251366, 0.48706195052785944, 0.5161402759325078, 0.34732704905047157, 0.6251886882908488, 0.5829421401827531, 0.4204828552137892, 0.40050024090280645, 0.5912146413327143, 0.6147084506098819, 0.38533962575544833, 0.4154157284542208, 0.583827510259986, 0.392107354820991, 0.6126677419077985, 0.4459655751259094, 0.5496784995737953, 0.3962811526354844, 0.6164373485440869, 0.41875743757087536, 0.5775964656150006, 0.6791816663585315, 0.3217176314329886, 0.4519454061205106, 0.5437468167387394, 0.45178313784089347, 0.5483474726465807, 0.6343256806087376, 0.36906221417235646, 0.3455978187616705, 0.6479959101781322, 0.7073590618836745, 0.35367953094183724, 0.3899349534187107, 0.6098982604754193, 0.3628371080218787, 0.6467965838650881, 0.4787894171770924, 0.5204232795403178, 0.38284549480047236, 0.6278666114727747, 0.4237982938975967, 0.5794792998191629, 0.6661473201818375, 0.3408195591628006, 0.5625854620453379, 0.4392790594052638, 0.5312460997443278, 0.47221875532829133, 0.5175724244573272, 0.48396382546659167, 0.3532193399865135, 0.6475687899752748, 0.5685071452297493, 0.426380358922312, 0.6581657928884861, 0.32908289644424304, 0.6816269372570267, 0.2921258302530115, 0.3793177933737578, 0.6163914142323564, 0.6571783397530983, 0.34912599299383346, 0.6820836210909239, 0.32309224156938504, 0.6743586271564023, 0.324210878440578, 0.38913313040212477, 0.6226130086433996, 0.5048170330797209, 0.4950147605927361, 0.6384652742674304, 0.36179698875154387, 0.39835956802424816, 0.6128608738834587, 0.5449409026668867, 0.45889760224579934, 0.4014458162753174, 0.5956937918924065, 0.6261717060174489, 0.3732946708950176, 0.5393982213452975, 0.4613274261505833, 0.47016990973658196, 0.5300097164303288, 0.39412017155569135, 0.6108862659113216, 0.695041975015423, 0.3475209875077115, 0.4283763968181524, 0.5669687604946135, 0.6430846358644958, 0.36276569202612585, 0.4100306394971035, 0.592266479273594, 0.42632185116132054, 0.575038775985037, 0.5235680583702204, 0.4747017062556665, 0.6851981634099799, 0.2936563557471342, 0.38897111015040065, 0.615870924404801, 0.39988450696155536, 0.6131562440077182, 0.5718519542048849, 0.42597135364241423, 0.5326979136671951, 0.46713509352354027, 0.6891319250118854, 0.31503173714829047, 0.678395302119128, 0.2907408437653406, 0.38435032323630064, 0.6179750295171893, 0.641357058527885, 0.36648974773022003, 0.34363912065606994, 0.6517293667615119, 0.7096310936892491, 0.3548155468446246, 0.5760145720089921, 0.4260929710751448, 0.7866728348912363, 0.19666820872280907, 0.3969403538172368, 0.6134532740811841, 0.4557364487055957, 0.5527016505578501, 0.6021663557580987, 0.39029300836173064, 0.41845662987217774, 0.6276849448082666, 0.6567777580205244, 0.3448083229607753, 0.5823443246585627, 0.41377096752055764, 0.5830611274330141, 0.41378531624278414, 0.7058434653692934, 0.3529217326846467, 0.6389889396348125, 0.35898255035663623, 0.47667860626342157, 0.5286799087648857, 0.6823717461051808, 0.3173822074907818, 0.6641155209944625, 0.33205776049723124, 0.6749141690972084, 0.3374570845486042, 0.5277020489420612, 0.47256899905259214, 0.6714026108427602, 0.28774397607546864, 0.5902680331684578, 0.41062124046501414, 0.39410241015171393, 0.6193037873812648, 0.6841627542784002, 0.3240770941318738, 0.6356548397039221, 0.36748795420382996, 0.6263065249475902, 0.3733750437187557, 0.5531969681979888, 0.4480895442403709], \"Term\": [\"accepted\", \"accepted\", \"agreement\", \"agreement\", \"aid\", \"aid\", \"alive\", \"alive\", \"allocated\", \"allocated\", \"allow\", \"allow\", \"allowed\", \"allowed\", \"alongside\", \"alongside\", \"amendments\", \"amendments\", \"arise\", \"arise\", \"asserted\", \"asserted\", \"audits\", \"audits\", \"block\", \"block\", \"boost\", \"boost\", \"break\", \"break\", \"bringing\", \"bringing\", \"budget\", \"budget\", \"built\", \"built\", \"cannabis\", \"cannabis\", \"capacity\", \"capacity\", \"census\", \"census\", \"central\", \"central\", \"china\", \"china\", \"comfort\", \"comfort\", \"considering\", \"considering\", \"continued\", \"continued\", \"counts\", \"counts\", \"currently\", \"currently\", \"dealing\", \"dealing\", \"depend\", \"depend\", \"depends\", \"depends\", \"developing\", \"developing\", \"directorate\", \"directorate\", \"disciplinary\", \"disciplinary\", \"echelon\", \"echelon\", \"economic\", \"economic\", \"efforts\", \"efforts\", \"else\", \"else\", \"establishment\", \"establishment\", \"exclusive\", \"exclusive\", \"expansion\", \"expansion\", \"extension\", \"extension\", \"families\", \"families\", \"farmer\", \"farmer\", \"femicide\", \"femicide\", \"fighting\", \"fighting\", \"finally\", \"finally\", \"functional\", \"functional\", \"gang\", \"gang\", \"gone\", \"gone\", \"govern\", \"govern\", \"governing\", \"governing\", \"governments\", \"governments\", \"greater\", \"greater\", \"guarantee\", \"guarantee\", \"guests\", \"guests\", \"healthy\", \"healthy\", \"highly\", \"highly\", \"home\", \"home\", \"hundreds\", \"hundreds\", \"immediate\", \"immediate\", \"informed\", \"informed\", \"infrastructural\", \"infrastructural\", \"institute\", \"institute\", \"intelligence\", \"intelligence\", \"introduce\", \"introduce\", \"introducing\", \"introducing\", \"introduction\", \"introduction\", \"israelpalestine\", \"israelpalestine\", \"jobs\", \"jobs\", \"laid\", \"laid\", \"laws\", \"laws\", \"leading\", \"leading\", \"limiting\", \"limiting\", \"line\", \"line\", \"literacy\", \"literacy\", \"lost\", \"lost\", \"maintenance\", \"maintenance\", \"making\", \"making\", \"market\", \"market\", \"met\", \"met\", \"nonracial\", \"nonracial\", \"opportunity\", \"opportunity\", \"outside\", \"outside\", \"peaceloving\", \"peaceloving\", \"period\", \"period\", \"permit\", \"permit\", \"phase\", \"phase\", \"phased\", \"phased\", \"pieces\", \"pieces\", \"planning\", \"planning\", \"plays\", \"plays\", \"positions\", \"positions\", \"present\", \"present\", \"presidency\", \"presidency\", \"private\", \"private\", \"procured\", \"procured\", \"professionals\", \"professionals\", \"proposal\", \"proposal\", \"proposals\", \"proposals\", \"put\", \"put\", \"railways\", \"railways\", \"rd\", \"rd\", \"red\", \"red\", \"reducing\", \"reducing\", \"reforms\", \"reforms\", \"reinforce\", \"reinforce\", \"relations\", \"relations\", \"removal\", \"removal\", \"require\", \"require\", \"responses\", \"responses\", \"retrenchment\", \"retrenchment\", \"retrenchments\", \"retrenchments\", \"reverse\", \"reverse\", \"saw\", \"saw\", \"scale\", \"scale\", \"signs\", \"signs\", \"skilled\", \"skilled\", \"son\", \"son\", \"sporting\", \"sporting\", \"standards\", \"standards\", \"starts\", \"starts\", \"strikes\", \"strikes\", \"subject\", \"subject\", \"supported\", \"supported\", \"taxi\", \"taxi\", \"tolerated\", \"tolerated\", \"unit\", \"unit\", \"unity\", \"unity\", \"upswing\", \"upswing\", \"various\", \"various\", \"virus\", \"virus\", \"volunteers\", \"volunteers\", \"water\", \"water\", \"well\", \"well\", \"wish\", \"wish\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el3926773574060481815930721\", ldavis_el3926773574060481815930721_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el3926773574060481815930721\", ldavis_el3926773574060481815930721_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el3926773574060481815930721\", ldavis_el3926773574060481815930721_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: true\n",
    "#| output: true\n",
    "\n",
    "# Display the visualization\n",
    "pyLDAvis.display(vis_data_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f4a303f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 6.5\n",
    "\n",
    "# Function to calculate coherence scores\n",
    "def calculate_coherence(model, metric='u_mass'):\n",
    "    coherence = tp.coherence.Coherence(model, coherence=metric)\n",
    "    return coherence.get_score()\n",
    "\n",
    "# Prepare the data for the CTM model\n",
    "tokenized_docs = [text.split() for text in sona_speeches_clean['speech']]  # Ensure the texts are tokenized\n",
    "tokenized_sentences = [text.split() for text in sona_sentences_alltogether['sentence']]  # Ensure the texts are tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b35c49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of topic numbers you want to test\n",
    "topic_numbers = range(2, 12, 1)  # for example from 2 to 20 by step of 2\n",
    "\n",
    "# Store coherence scores for plotting\n",
    "coherence_scores = []\n",
    "coherence_scores_sentences = []\n",
    "\n",
    "for k in topic_numbers:\n",
    "    # Initialize CTM with the current number of topics\n",
    "    ctm = tp.CTModel(k=k)\n",
    "    ctms = tp.CTModel(k=k)\n",
    "\n",
    "    # Add documents to the model\n",
    "    for tokens in tokenized_docs:\n",
    "        ctm.add_doc(tokens)\n",
    "\n",
    "    # Add sentences to the model\n",
    "    for tokens in tokenized_sentences:\n",
    "        ctms.add_doc(tokens)    \n",
    "\n",
    "    # Train the model\n",
    "    ctm.train(0)\n",
    "    ctms.train(0)\n",
    "\n",
    "    for _ in range(100):\n",
    "        ctm.train(10)\n",
    "        ctms.train(10)\n",
    "\n",
    "    # Calculate and store the coherence score\n",
    "    score = calculate_coherence(ctm)\n",
    "    score_sentences = calculate_coherence(ctms)\n",
    "\n",
    "    coherence_scores.append(score)\n",
    "    coherence_scores_sentences.append(score_sentences)\n",
    "\n",
    "    #(f\"Topics: {k}, Coherence Score: {score}\")\n",
    "\n",
    "# Save the coherence scores to a csv\n",
    "pd.DataFrame({\n",
    "    'topic_number': topic_numbers,\n",
    "    'bow_coherence_values': coherence_scores,\n",
    "    'bow_coherence_values_sentences': coherence_scores_sentences\n",
    "}).to_csv('data/saved_ctm_coherence_values.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "88f0ac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the saved values\n",
    "coherence_values = pd.read_csv('data/saved_ctm_coherence_values.csv')\n",
    "\n",
    "topic_numbers = coherence_values['topic_number']\n",
    "coherence_scores = coherence_values['bow_coherence_values']\n",
    "coherence_scores_sentences = coherence_values['bow_coherence_values_sentences']\n",
    "\n",
    "# Plot the speech coherence scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(topic_numbers, coherence_scores,  color='midnightblue')\n",
    "plt.xlabel('Number of Topics')\n",
    "plt.ylabel('Coherence Score')\n",
    "plt.xticks(topic_numbers)\n",
    "plt.savefig(f'ctm_plots/words_coherence_plots.png', bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Plot the sentence coherence scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(topic_numbers, coherence_scores_sentences, color='lightsteelblue')\n",
    "plt.xlabel('Number of Topics')\n",
    "plt.ylabel('Coherence Score')\n",
    "plt.xticks(topic_numbers)\n",
    "plt.savefig(f'ctm_plots/sentences_coherence_plots.png', bbox_inches='tight')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "619ccdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set the number of topics based on the plots\n",
    "\n",
    "# Run 7\n",
    "\n",
    "# Train the models with the optimal number of topics\n",
    "ctm = tp.CTModel(k=2)\n",
    "ctms = tp.CTModel(k=3)\n",
    "\n",
    "# Add documents to the model\n",
    "for tokens in tokenized_docs:\n",
    "    ctm.add_doc(tokens)\n",
    "\n",
    "# Add sentences to the model\n",
    "for tokens in tokenized_sentences:\n",
    "    ctms.add_doc(tokens)\n",
    "\n",
    "# Train the model\n",
    "ctm.train(0)\n",
    "ctms.train(0)\n",
    "\n",
    "for _ in range(100):\n",
    "    ctm.train(10)\n",
    "    ctms.train(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7566606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 8\n",
    "\n",
    "# Function to plot the top words for one topic\n",
    "def plot_top_words_for_topic(model, modtype, topic_num, color, top_n=10):\n",
    "    # Extract the top words for this topic\n",
    "    top_words = model.get_topic_words(topic_num, top_n=top_n)\n",
    "    words, weights = zip(*top_words)\n",
    "\n",
    "    # Create a bar chart for the top words in this topic\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(words, weights, color=color)\n",
    "    plt.xlabel('Weight')\n",
    "    plt.gca().invert_yaxis()  # Highest weights on top\n",
    "    plt.savefig(f'ctm_plots/{modtype}_{topic_num+1}.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Plot the top words for each topic for the CTModel of documents\n",
    "i = 0\n",
    "colours = ['midnightblue', 'lightsteelblue']\n",
    "\n",
    "for k in range(ctm.k):\n",
    "    plot_top_words_for_topic(ctm, 'words', k, colours[i])\n",
    "    i+=1\n",
    "\n",
    "    if i == 2:\n",
    "        i = 0\n",
    "\n",
    "i = 0\n",
    "# Plot the top words for each topic for the CTModel of sentences\n",
    "for k in range(ctms.k):\n",
    "    plot_top_words_for_topic(ctms, 'sentences', k, colours[i])\n",
    "    i+=1\n",
    "\n",
    "    if i == 2:\n",
    "        i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "07aacd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: true\n",
    "\n",
    "# Note that ATM only works for BoW. Raw word counts (BoW) is standard because these models are based on the assumption that the data is generated from a multinomial distribution, which does not hold with TF-IDF weights.\n",
    "\n",
    "texts = sona_speeches_clean['speech']\n",
    "sentences = sona_sentences_alltogether['sentence']\n",
    "\n",
    "# Further process tokens using gensim's simple_preprocess\n",
    "tokenized_texts = [simple_preprocess(doc, deacc=True) for doc in texts]  # deacc=True removes punctuations\n",
    "tokenized_sentences = [simple_preprocess(doc, deacc=True) for doc in sentences]  # deacc=True removes punctuations\n",
    "\n",
    "# Create a Gensim dictionary from the tokenized documents\n",
    "dictionary = corpora.Dictionary(tokenized_texts)\n",
    "dictionary.filter_extremes(no_below=3, no_above=0.7)\n",
    "\n",
    "dict_sentences = corpora.Dictionary(tokenized_sentences)\n",
    "dict_sentences.filter_extremes(no_below=3, no_above=0.7)\n",
    "\n",
    "# Create a BOW corpus\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in tokenized_texts]\n",
    "bow_corpus_sentences = [dict_sentences.doc2bow(text) for text in tokenized_sentences]\n",
    "\n",
    "# Prepare the data for the AuthorTopicModel\n",
    "# Create a mapping of authors to documents\n",
    "author2doc = {author: [] for author in sona_speeches_clean['president'].unique()}\n",
    "for i, row in sona_speeches_clean.iterrows():\n",
    "    author2doc[row['president']].append(i)\n",
    "\n",
    "# Create a mapping of authors to sentences\n",
    "author2sent = {author: [] for author in sona_sentences_alltogether['president'].unique()}\n",
    "for i, row in sona_sentences_alltogether.iterrows():\n",
    "    author2sent[row['president']].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d1423db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of topic numbers you want to test\n",
    "topic_numbers = range(2, 12, 1)  # for example from 2 to 20 by step of 2\n",
    "\n",
    "# Store coherence scores for plotting\n",
    "coherence_scores = []\n",
    "coherence_scores_sentences = []\n",
    "\n",
    "for num_topics in topic_numbers:\n",
    "    # Author-Topic LDA model with the current number of topics\n",
    "    author_topic_model = AuthorTopicModel(corpus=bow_corpus, author2doc=author2doc, id2word=dictionary, num_topics=num_topics)\n",
    "    author_topic_model_sentences = AuthorTopicModel(corpus=bow_corpus_sentences, author2doc=author2sent, id2word=dict_sentences, num_topics=num_topics)\n",
    "\n",
    "    # Train the model\n",
    "    author_topic_model.update(bow_corpus, author2doc=author2doc)\n",
    "    author_topic_model_sentences.update(bow_corpus_sentences, author2doc=author2sent)\n",
    "\n",
    "    # Compute coherence score\n",
    "    cm = CoherenceModel(model=author_topic_model, texts=tokenized_docs, dictionary=dictionary, coherence='u_mass')\n",
    "    cm_sentences = CoherenceModel(model=author_topic_model_sentences, texts=tokenized_sentences, dictionary=dict_sentences, coherence='u_mass')\n",
    "\n",
    "    coherence = cm.get_coherence()\n",
    "    coherence_sentences = cm_sentences.get_coherence()\n",
    "\n",
    "    coherence_scores.append(coherence)\n",
    "    coherence_scores_sentences.append(coherence_sentences)\n",
    "\n",
    "# Save the coherence scores to a csv\n",
    "pd.DataFrame({\n",
    "    'topic_number': topic_numbers,\n",
    "    'bow_coherence_values': coherence_scores,\n",
    "    'bow_coherence_values_sentences': coherence_scores_sentences\n",
    "}).to_csv('data/saved_atm_coherence_values.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3f729efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the saved values\n",
    "coherence_values = pd.read_csv('data/saved_atm_coherence_values.csv')\n",
    "\n",
    "topic_numbers = coherence_values['topic_number']\n",
    "coherence_scores = coherence_values['bow_coherence_values']\n",
    "coherence_scores_sentences = coherence_values['bow_coherence_values_sentences']\n",
    "\n",
    "# Plot the speech coherence scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(topic_numbers, coherence_scores,  color='midnightblue')\n",
    "plt.xlabel('Number of Topics')\n",
    "plt.ylabel('Coherence Score')\n",
    "plt.xticks(topic_numbers)\n",
    "plt.savefig(f'atm_plots/words_coherence_plots.png', bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Plot the sentence coherence scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(topic_numbers, coherence_scores_sentences, color='lightsteelblue')\n",
    "plt.xlabel('Number of Topics')\n",
    "plt.ylabel('Coherence Score')\n",
    "plt.xticks(topic_numbers)\n",
    "plt.savefig(f'atm_plots/sentences_coherence_plots.png', bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c923a9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of topics based on the plots\n",
    "\n",
    "# Author-Topic LDA model with the current number of topics\n",
    "author_topic_model = AuthorTopicModel(corpus=bow_corpus, author2doc=author2doc, id2word=dictionary, num_topics=2)\n",
    "author_topic_model_sentences = AuthorTopicModel(corpus=bow_corpus_sentences, author2doc=author2sent, id2word=dict_sentences, num_topics=3)\n",
    "\n",
    "# Train the model\n",
    "author_topic_model.update(bow_corpus, author2doc=author2doc)\n",
    "author_topic_model_sentences.update(bow_corpus_sentences, author2doc=author2sent)\n",
    "\n",
    "# Save the models\n",
    "author_topic_model.save('data/author_topic_model')\n",
    "author_topic_model_sentences.save('data/author_topic_model_sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b9d931e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the models\n",
    "author_topic_model = AuthorTopicModel.load('data/author_topic_model')\n",
    "author_topic_model_sentences = AuthorTopicModel.load('data/author_topic_model_sentences')\n",
    "\n",
    "colours = ['midnightblue', 'lightsteelblue', 'darkgray']\n",
    "\n",
    "# Function to plot the top words for one topic in an AuthorTopicModel\n",
    "def plot_top_words_for_author_topic_model(model, modtype, topic_num, colour, top_n=10):\n",
    "    # Extract the top words for this topic\n",
    "    top_words = model.get_topic_terms(topic_num, topn=top_n)\n",
    "    words, weights = zip(*[(model.id2word[word_id], weight) for word_id, weight in top_words])\n",
    "\n",
    "    # Create a bar chart for the top words in this topic\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(words, weights, color=colour)\n",
    "    plt.xlabel('Weight')\n",
    "    plt.gca().invert_yaxis()  # Highest weights on top\n",
    "    plt.savefig(f'atm_plots/{modtype}_{topic_num+1}.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Plot the top words for each topic for the AuthorTopicModel of documents\n",
    "i = 0\n",
    "for k in range(author_topic_model.num_topics):\n",
    "    plot_top_words_for_author_topic_model(author_topic_model, \"words\",k, colours[i])\n",
    "\n",
    "    i += 1\n",
    "\n",
    "    if i == 3:\n",
    "        i = 0\n",
    "\n",
    "i = 0\n",
    "# Plot the top words for each topic for the AuthorTopicModel of sentences\n",
    "for k in range(author_topic_model_sentences.num_topics):\n",
    "    plot_top_words_for_author_topic_model(author_topic_model_sentences, \"sentences\", k, colours[i])\n",
    "\n",
    "    i += 1\n",
    "\n",
    "    if i == 3:\n",
    "        i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ac4631cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: true\n",
    "\n",
    "# Load the models\n",
    "author_topic_model = AuthorTopicModel.load('data/author_topic_model')\n",
    "author_topic_model_sentences = AuthorTopicModel.load('data/author_topic_model_sentences')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "# Assuming sona_speeches_clean and the topic models are already defined\n",
    "# Define the topic labels\n",
    "topic_labels_words = ['General national agenda', 'Economic reform agenda']\n",
    "topic_labels_sents = ['Social cohesion and confidence', 'Prospective planning', 'Land and people']\n",
    "\n",
    "# Function to show topics for each author\n",
    "def show_author(name, model, topic_labels):\n",
    "    if name not in model.author2doc:\n",
    "        print(f\"No topics found for {name}\")\n",
    "        return np.array([]), []\n",
    "\n",
    "    topics_data = model[name]\n",
    "    doc_ids = pd.Series(model.author2doc[name]).unique()\n",
    "\n",
    "    topics = []\n",
    "    for topic in topics_data:\n",
    "        if topic[0] < len(topic_labels):\n",
    "            topics.append((topic_labels[topic[0]], topic[1]))\n",
    "        else:\n",
    "            print(f\"Topic index out of range for {name}: {topic[0]}\")\n",
    "\n",
    "    return doc_ids, topics\n",
    "\n",
    "\n",
    "# Style function for the DataFrame\n",
    "def style_df(df):\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns[1:]\n",
    "    format_dict = {col: \"{:.2f}\" for col in numeric_cols}\n",
    "    styles = [\n",
    "        dict(selector=\"th\", props=[(\"text-align\", \"center\")]),\n",
    "        dict(selector=\"td\", props=[(\"text-align\", \"center\")]),\n",
    "        dict(selector=\"\", props=[(\"margin\", \"auto\"), (\"border\", \"1px solid black\")])\n",
    "    ]\n",
    "    return df.style.set_table_styles(styles).format(format_dict).hide()\n",
    "\n",
    "# Retrieve the unique presidents\n",
    "presidents = sona_speeches_clean['president'].unique()\n",
    "\n",
    "# Create a DataFrame to store the information\n",
    "df = pd.DataFrame(columns=['President', 'Speech IDs', 'Word-Based Topics', 'Sentence-Based Topics'])\n",
    "\n",
    "# Populate the DataFrame\n",
    "rows = []\n",
    "for president in presidents:\n",
    "    doc_ids, word_topics = show_author(president, author_topic_model, topic_labels_words)\n",
    "    _, sent_topics = show_author(president, author_topic_model_sentences, topic_labels_sents)\n",
    "    rows.append({'President': president, 'Speech IDs': doc_ids, \n",
    "                 'Word-Based Topics': word_topics, 'Sentence-Based Topics': sent_topics})\n",
    "\n",
    "df = pd.concat([df, pd.DataFrame(rows)], ignore_index=True)\n",
    "\n",
    "\n",
    "# Function to format topics for readability\n",
    "def format_topics(topic_list):\n",
    "    return '; '.join([f\"{topic[0]} ({topic[1]:.2f})\" for topic in topic_list])\n",
    "\n",
    "# Applying formatting to each row\n",
    "for idx, row in df.iterrows():\n",
    "    # Format document IDs as a comma-separated string\n",
    "    df.at[idx, 'Speech IDs'] = ', '.join(map(str, row['Speech IDs']))\n",
    "    \n",
    "    # Format topics\n",
    "    df.at[idx, 'Word-Based Topics'] = format_topics(row['Word-Based Topics'])\n",
    "    df.at[idx, 'Sentence-Based Topics'] = format_topics(row['Sentence-Based Topics'])\n",
    "\n",
    "# Apply the styling function after these modifications\n",
    "styled_df = style_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "atm-table",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_90958 th {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_90958 td {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_90958  {\n",
       "  margin: auto;\n",
       "  border: 1px solid black;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_90958\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_90958_level0_col0\" class=\"col_heading level0 col0\" >President</th>\n",
       "      <th id=\"T_90958_level0_col1\" class=\"col_heading level0 col1\" >Speech IDs</th>\n",
       "      <th id=\"T_90958_level0_col2\" class=\"col_heading level0 col2\" >Word-Based Topics</th>\n",
       "      <th id=\"T_90958_level0_col3\" class=\"col_heading level0 col3\" >Sentence-Based Topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_90958_row0_col0\" class=\"data row0 col0\" >Mandela</td>\n",
       "      <td id=\"T_90958_row0_col1\" class=\"data row0 col1\" >4, 16, 0, 23, 31, 21, 15</td>\n",
       "      <td id=\"T_90958_row0_col2\" class=\"data row0 col2\" >General national agenda (0.52); Economic reform agenda (0.48)</td>\n",
       "      <td id=\"T_90958_row0_col3\" class=\"data row0 col3\" >Social cohesion and confidence (1.00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_90958_row1_col0\" class=\"data row1 col0\" >Ramaphosa</td>\n",
       "      <td id=\"T_90958_row1_col1\" class=\"data row1 col1\" >7, 26, 3, 24, 8, 1, 35</td>\n",
       "      <td id=\"T_90958_row1_col2\" class=\"data row1 col2\" >General national agenda (0.30); Economic reform agenda (0.70)</td>\n",
       "      <td id=\"T_90958_row1_col3\" class=\"data row1 col3\" >Social cohesion and confidence (0.66); Land and people (0.34)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_90958_row2_col0\" class=\"data row2 col0\" >Mbeki</td>\n",
       "      <td id=\"T_90958_row2_col1\" class=\"data row2 col1\" >9, 14, 22, 34, 32, 28, 29, 2, 12, 25</td>\n",
       "      <td id=\"T_90958_row2_col2\" class=\"data row2 col2\" >General national agenda (0.33); Economic reform agenda (0.67)</td>\n",
       "      <td id=\"T_90958_row2_col3\" class=\"data row2 col3\" >Social cohesion and confidence (1.00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_90958_row3_col0\" class=\"data row3 col0\" >Zuma</td>\n",
       "      <td id=\"T_90958_row3_col1\" class=\"data row3 col1\" >13, 5, 6, 20, 19, 30, 27, 33, 11, 10</td>\n",
       "      <td id=\"T_90958_row3_col2\" class=\"data row3 col2\" >General national agenda (0.47); Economic reform agenda (0.53)</td>\n",
       "      <td id=\"T_90958_row3_col3\" class=\"data row3 col3\" >Social cohesion and confidence (1.00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_90958_row4_col0\" class=\"data row4 col0\" >deKlerk</td>\n",
       "      <td id=\"T_90958_row4_col1\" class=\"data row4 col1\" >17</td>\n",
       "      <td id=\"T_90958_row4_col2\" class=\"data row4 col2\" >General national agenda (0.56); Economic reform agenda (0.44)</td>\n",
       "      <td id=\"T_90958_row4_col3\" class=\"data row4 col3\" >Social cohesion and confidence (0.02); Land and people (0.98)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_90958_row5_col0\" class=\"data row5 col0\" > Motlanthe</td>\n",
       "      <td id=\"T_90958_row5_col1\" class=\"data row5 col1\" >18</td>\n",
       "      <td id=\"T_90958_row5_col2\" class=\"data row5 col2\" >General national agenda (0.55); Economic reform agenda (0.45)</td>\n",
       "      <td id=\"T_90958_row5_col3\" class=\"data row5 col3\" >Social cohesion and confidence (0.17); Prospective planning (0.83)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b33bafe0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: true\n",
    "#| output: true\n",
    "#| label: atm-table\n",
    "#| tbl-cap: 'Table 3: ATM topics for each president.'\n",
    "\n",
    "\n",
    "styled_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (scientificProject)",
   "language": "python",
   "name": "scientificproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}