{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa4e1b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# imports\n",
    "import os\n",
    "import sys\n",
    "import types\n",
    "import json\n",
    "\n",
    "# figure size/format\n",
    "fig_width = 7\n",
    "fig_height = 5\n",
    "fig_format = 'retina'\n",
    "fig_dpi = 96\n",
    "\n",
    "# matplotlib defaults / format\n",
    "try:\n",
    "  import matplotlib.pyplot as plt\n",
    "  plt.rcParams['figure.figsize'] = (fig_width, fig_height)\n",
    "  plt.rcParams['figure.dpi'] = fig_dpi\n",
    "  plt.rcParams['savefig.dpi'] = fig_dpi\n",
    "  from IPython.display import set_matplotlib_formats\n",
    "  set_matplotlib_formats(fig_format)\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# plotly use connected mode\n",
    "try:\n",
    "  import plotly.io as pio\n",
    "  pio.renderers.default = \"notebook_connected\"\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# enable pandas latex repr when targeting pdfs\n",
    "try:\n",
    "  import pandas as pd\n",
    "  if fig_format == 'pdf':\n",
    "    pd.set_option('display.latex.repr', True)\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "\n",
    "\n",
    "# output kernel dependencies\n",
    "kernel_deps = dict()\n",
    "for module in list(sys.modules.values()):\n",
    "  # Some modules play games with sys.modules (e.g. email/__init__.py\n",
    "  # in the standard library), and occasionally this can cause strange\n",
    "  # failures in getattr.  Just ignore anything that's not an ordinary\n",
    "  # module.\n",
    "  if not isinstance(module, types.ModuleType):\n",
    "    continue\n",
    "  path = getattr(module, \"__file__\", None)\n",
    "  if not path:\n",
    "    continue\n",
    "  if path.endswith(\".pyc\") or path.endswith(\".pyo\"):\n",
    "    path = path[:-1]\n",
    "  if not os.path.exists(path):\n",
    "    continue\n",
    "  kernel_deps[path] = os.stat(path).st_mtime\n",
    "print(json.dumps(kernel_deps))\n",
    "\n",
    "# set run_path if requested\n",
    "if r'/Users/jared/Library/Group Containers/UBF8T346G9.OneDriveStandaloneSuite/OneDrive.noindex/OneDrive/Documents/University stuff/Masters Year/DS4I/Assignment2_code/project':\n",
    "  os.chdir(r'/Users/jared/Library/Group Containers/UBF8T346G9.OneDriveStandaloneSuite/OneDrive.noindex/OneDrive/Documents/University stuff/Masters Year/DS4I/Assignment2_code/project')\n",
    "\n",
    "# reset state\n",
    "%reset\n",
    "\n",
    "def ojs_define(**kwargs):\n",
    "  import json\n",
    "  try:\n",
    "    # IPython 7.14 preferred import\n",
    "    from IPython.display import display, HTML\n",
    "  except:\n",
    "    from IPython.core.display import display, HTML\n",
    "\n",
    "  # do some minor magic for convenience when handling pandas\n",
    "  # dataframes\n",
    "  def convert(v):\n",
    "    try:\n",
    "      import pandas as pd\n",
    "    except ModuleNotFoundError: # don't do the magic when pandas is not available\n",
    "      return v\n",
    "    if type(v) == pd.Series:\n",
    "      v = pd.DataFrame(v)\n",
    "    if type(v) == pd.DataFrame:\n",
    "      j = json.loads(v.T.to_json(orient='split'))\n",
    "      return dict((k,v) for (k,v) in zip(j[\"index\"], j[\"data\"]))\n",
    "    else:\n",
    "      return v\n",
    "  \n",
    "  v = dict(contents=list(dict(name=key, value=convert(value)) for (key, value) in kwargs.items()))\n",
    "  display(HTML('<script type=\"ojs-define\">' + json.dumps(v) + '</script>'), metadata=dict(ojs_define = True))\n",
    "globals()[\"ojs_define\"] = ojs_define\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f2d8004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 1\n",
    "\n",
    "# Loading in the necessary libraries\n",
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from itertools import cycle\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet, stopwords, words\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from ast import literal_eval\n",
    "from collections import defaultdict\n",
    "import pyLDAvis.gensim_models\n",
    "import gensim\n",
    "from gensim.models import LsiModel, TfidfModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim import corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from plsa import Corpus, Pipeline, Visualize\n",
    "from plsa.pipeline import DEFAULT_PIPELINE\n",
    "from plsa.algorithms import PLSA\n",
    "from gensim.models import AuthorTopicModel\n",
    "from gensim.models import LdaModel\n",
    "import tqdm\n",
    "\n",
    "# Global params\n",
    "plt.rcParams['xtick.labelsize'] = 18\n",
    "plt.rcParams['ytick.labelsize'] = 18\n",
    "\n",
    "# Set the global label sizes for the plots\n",
    "plt.rcParams['axes.labelsize'] = 20\n",
    "\n",
    "# Set the global legend size\n",
    "plt.rcParams['legend.fontsize'] = 18\n",
    "\n",
    "# Unzip the file and get the list of filenames\n",
    "with zipfile.ZipFile(\"data/speeches.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"data\")\n",
    "\n",
    "filenames = os.listdir(\"data\")\n",
    "filenames = [filename for filename in filenames if filename.endswith('.txt')]\n",
    "\n",
    "# Read the content of each speech file and extract the date from the first line\n",
    "speeches = []\n",
    "dates = []\n",
    "for filename in filenames:\n",
    "    with open(os.path.join(\"data\", filename), 'r', encoding='utf-8') as file:\n",
    "        # Extract date from the first line\n",
    "        date = file.readline().strip()\n",
    "        dates.append(date)\n",
    "        \n",
    "        # Read the rest of the file\n",
    "        speeches.append(file.read())\n",
    "\n",
    "# Create DataFrame\n",
    "sona = pd.DataFrame({'filename': filenames, 'speech': speeches, 'date': dates})\n",
    "\n",
    "# Extract year and president for each speech\n",
    "sona['year'] = sona['filename'].str[:4]\n",
    "sona['president'] = sona['filename'].str.split('_').str[-1].str.split('.').str[0]\n",
    "\n",
    "# Clean the sona dataset by removing unnecessary text\n",
    "replace_reg = r'(http.*?(\\s|.$))|(www.*?(\\s|.$))|&amp;|&lt;|&gt;|\\n'\n",
    "sona['speech'] = sona['speech'].str.replace(replace_reg, ' ')\n",
    "\n",
    "# Split speeches into sentences\n",
    "sona_sentences = sona.copy()\n",
    "\n",
    "import itertools\n",
    "\n",
    "# Replace new lines with space and split into sentences based on regular expression\n",
    "sona_sentences['speech'] = sona_sentences['speech'].str.replace('\\n', ' ').str.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s')\n",
    "\n",
    "# Flatten the list of sentence fragments to avoid nested lists\n",
    "sona_sentences['speech'] = sona_sentences['speech'].apply(lambda sentences: list(itertools.chain.from_iterable(sentence.split('.') for sentence in sentences)))\n",
    "\n",
    "# Remove empty strings from the list of sentences\n",
    "sona_sentences['speech'] = sona_sentences['speech'].apply(lambda sentences: [sentence.strip() for sentence in sentences if sentence.strip()])\n",
    "\n",
    "# Make a csv of the speeches\n",
    "sona.to_csv('data/sona_speeches.csv', index=False)\n",
    "\n",
    "# Make a csv of the sentences\n",
    "sona_sentences.to_csv('data/sona_sentences_untransformed.csv', index=False)\n",
    "\n",
    "\n",
    "# Make sure to download the necessary NLTK corpus if you haven't already\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('words')\n",
    "\n",
    "# Read in the sona speeches dataset\n",
    "sona_speeches_df = pd.read_csv('data/sona_speeches.csv')\n",
    "sona_sentences_clean = pd.read_csv('data/sona_sentences_untransformed.csv')\n",
    "sona_sentences_clean['speech'] = sona_sentences_clean['speech'].apply(literal_eval)\n",
    "\n",
    "# Initialize the WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "english_words = set(words.words())\n",
    "additional_words = {\n",
    "    'honourable', 'member', 'chairperson',\n",
    "    'south', 'africa', 'african', 'africans', 'year',\n",
    "    'madame', 'madam', 'soes', 'ms', 'madams', 'madames', 'mw',\n",
    "    'compatriotsthe',\n",
    "    'also'\n",
    "}\n",
    "\n",
    "# Function to convert NLTK's part-of-speech tags to WordNet's part-of-speech tags\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map NLTK part of speech tags to WordNet part of speech tags.\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": nltk.corpus.wordnet.ADJ,\n",
    "                \"N\": nltk.corpus.wordnet.NOUN,\n",
    "                \"V\": nltk.corpus.wordnet.VERB,\n",
    "                \"R\": nltk.corpus.wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, nltk.corpus.wordnet.NOUN)\n",
    "\n",
    "# Clean the text, convert to lowercase, and lemmatize each word\n",
    "def clean_text(text):\n",
    "    # Remove special characters: keep only letters, numbers, and basic punctuation\n",
    "    text = re.sub(r'[.;]', ' ', text)  # Replaces periods with spaces\n",
    "    text = re.sub(r'[^a-zA-Z ]', '', text)\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    \n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Remove additional words\n",
    "    words = [word for word in words if word not in additional_words]\n",
    "\n",
    "    # Lemmatize each word with the correct POS tag\n",
    "    lemmatized_words = []\n",
    "    for word, tag in nltk.pos_tag(words):\n",
    "        wntag = get_wordnet_pos(tag)\n",
    "        lemmatized_word = lemmatizer.lemmatize(word, wntag)\n",
    "        # Only append the lemmatized word if it is in the set of English words\n",
    "        if lemmatized_word in english_words:\n",
    "            lemmatized_words.append(lemmatized_word)\n",
    "    \n",
    "    # Join the lemmatized words back into one string\n",
    "    text = ' '.join(words)\n",
    "    return text\n",
    "\n",
    "def clean_text_no_word_removals(text):\n",
    "    # Remove special characters: keep only letters, numbers, and basic punctuation\n",
    "    text = re.sub(r'[.;]', ' ', text)  # Replaces periods with spaces\n",
    "    text = re.sub(r'[^a-zA-Z ]', '', text)\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the speech column\n",
    "tempdf = sona_speeches_df.copy()\n",
    "sona_speeches_df['speech'] = tempdf['speech'].apply(clean_text)\n",
    "sona_speeches_df['speech_untrans'] = tempdf['speech'].apply(clean_text_no_word_removals)\n",
    "\n",
    "def clean_speeches(speeches):\n",
    "    # The input is expected to be a list of strings\n",
    "    return [clean_text(sentence) for sentence in speeches]\n",
    "\n",
    "# Apply the cleaning to the sentences too\n",
    "sona_sentences_clean['sentence'] = sona_sentences_clean['speech'].apply(lambda speeches: [clean_text(sentence) for sentence in speeches])\n",
    "\n",
    "# Apply the cleaning to sentences that need to keep their words\n",
    "sona_sentences_clean['sent_untrans'] = sona_sentences_clean['speech'].apply(lambda speeches: [clean_text_no_word_removals(sentence) for sentence in speeches])\n",
    "\n",
    "# Make a csv of the speeches\n",
    "sona_speeches_df.to_csv('data/sona_speeches_adapted.csv', index=False)\n",
    "\n",
    "# Remove the speech column from the sentences DataFrame\n",
    "sona_sentences_clean.drop(columns=['speech'], inplace=True)\n",
    "\n",
    "# Make a csv of the sentences\n",
    "sona_sentences_clean.to_csv('data/sona_sentences_clean.csv', index=False)\n",
    "\n",
    "\n",
    "# Run 2\n",
    "\n",
    "sona_sentences_clean = pd.read_csv('data/sona_sentences_clean.csv')\n",
    "sona_sentences_clean['sentence'] = sona_sentences_clean['sentence'].apply(literal_eval)\n",
    "sona_sentences_clean['sent_untrans'] = sona_sentences_clean['sent_untrans'].apply(literal_eval)\n",
    "\n",
    "# Make the sentences into a single column\n",
    "sona_sentences_alltogether = sona_sentences_clean.explode('sentence')\n",
    "sona_sentences_all_untrans = sona_sentences_clean.explode('sent_untrans')\n",
    "\n",
    "# Drop the other columns\n",
    "sona_sentences_alltogether.drop(columns=['sent_untrans'], inplace=True)\n",
    "sona_sentences_all_untrans.drop(columns=['sentence'], inplace=True)\n",
    "\n",
    "# Make a csv of the sentences\n",
    "sona_sentences_all_untrans.to_csv('data/sona_sentiment_sentences.csv', index=False)\n",
    "\n",
    "# Speeches\n",
    "sona_speeches_clean = pd.read_csv('data/sona_speeches_adapted.csv')\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "max_features = 2000\n",
    "\n",
    "bow_vectorizer = CountVectorizer(max_features=max_features)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "\n",
    "# Transformed on the words\n",
    "bow_matrix_words = bow_vectorizer.fit_transform(sona_speeches_clean['speech'])\n",
    "tfidf_matrix_words = tfidf_vectorizer.fit_transform(sona_speeches_clean['speech'])\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "cmap = plt.cm.cividis\n",
    "\n",
    "norm = plt.Normalize(0, 100)\n",
    "\n",
    "# Define a colour map based on cividis\n",
    "# Define a new colormap using a smaller slice of the cividis colormap, this time stopping well before the yellows\n",
    "cividis_modified = cmap(np.linspace(0, 0.4, cmap.N))  # Using only 40% of the colormap range\n",
    "\n",
    "# Create a new colormap from the data\n",
    "cividis_no_yellow_light = LinearSegmentedColormap.from_list('cividis_no_yellow_light', cividis_modified)\n",
    "\n",
    "# Let's pick three colors from the modified colormap\n",
    "colormap = [cividis_no_yellow_light(norm(0)), \n",
    "          cividis_no_yellow_light(norm(50)), \n",
    "          cividis_no_yellow_light(norm(100))]\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to count words in speeches excluding stopwords\n",
    "def get_word_frequencies(speeches, stopwords):\n",
    "    word_counts = Counter()\n",
    "    for speech in speeches:\n",
    "        words = speech.lower().split()\n",
    "        # Remove stopwords from the count\n",
    "        words = [word.strip('.,!?\"\\'-()') for word in words if word.strip('.,!?\"\\'-()') not in stopwords]\n",
    "        word_counts.update(words)\n",
    "    return word_counts\n",
    "\n",
    "# Get the word frequencies excluding stopwords\n",
    "word_frequencies = get_word_frequencies(sona_speeches_clean['speech'], ENGLISH_STOP_WORDS)\n",
    "\n",
    "# Get the top 10 most frequent words across all speeches\n",
    "top_10_words = word_frequencies.most_common(10)\n",
    "\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar([word for word, count in top_10_words], [count for word, count in top_10_words], color=colormap[2])\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks()\n",
    "plt.yticks()\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig(f'saved_plots/overall_top_words.png', bbox_inches='tight')\n",
    "plt.close()  # Close the figure to avoid displaying it in the notebook\n",
    "\n",
    "\n",
    "# Function to get top N frequent words for each president\n",
    "def get_top_words_by_president(speeches_df, n, stopwords):\n",
    "    presidents = speeches_df['president'].unique()\n",
    "    top_words_by_president = {}\n",
    "    for president in presidents:\n",
    "        president_speeches = speeches_df[speeches_df['president'] == president]['speech']\n",
    "        word_frequencies = get_word_frequencies(president_speeches, stopwords)\n",
    "        top_words_by_president[president] = word_frequencies.most_common(n)\n",
    "    return top_words_by_president\n",
    "\n",
    "# Get the top 10 most frequent words for each president\n",
    "top_10_words_by_president = get_top_words_by_president(sona_speeches_clean, 10, ENGLISH_STOP_WORDS)\n",
    "\n",
    "\n",
    "# Plot the word frequencies for each president\n",
    "for president, top_words in top_10_words_by_president.items():\n",
    "    \n",
    "    # Individual plot for each president\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar([word for word, count in top_words], [count for word, count in top_words], color=colormap[0])\n",
    "    plt.xlabel('Words')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Save the plot as a PNG file\n",
    "    plt.savefig(f'saved_plots/{president}_top_words.png', bbox_inches='tight')\n",
    "    plt.close()  # Close the figure to avoid displaying it in the notebook\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.tokenize import treebank\n",
    "from afinn import Afinn\n",
    "\n",
    "from dateutil import parser\n",
    "\n",
    "# Function to parse date strings based on the described rule\n",
    "def parse_date(date_str):\n",
    "    # Split the string by comma and take the last part\n",
    "    date_part = date_str.split(',')[-1].strip()\n",
    "    # Parse the date part into a datetime object\n",
    "    return parser.parse(date_part)\n",
    "\n",
    "# Define a function to get Bing lexicon sentiment scores\n",
    "def get_bing_sentiment(text):\n",
    "    tokenizer = treebank.TreebankWordTokenizer()\n",
    "    tokens = tokenizer.tokenize(text.lower())\n",
    "    pos_score = sum(1 for word in tokens if word in positive_words)\n",
    "    neg_score = sum(1 for word in tokens if word in negative_words)\n",
    "    compound_score = pos_score - neg_score\n",
    "    return compound_score\n",
    "\n",
    "\n",
    "# Load the AFINN lexicon\n",
    "afinn = Afinn()\n",
    "\n",
    "# Define a function to get AFINN sentiment scores\n",
    "def get_afinn_sentiment(text):\n",
    "    return afinn.score(text)\n",
    "\n",
    "# Load positive and negative words\n",
    "positive_words = set(opinion_lexicon.positive())\n",
    "negative_words = set(opinion_lexicon.negative())\n",
    "\n",
    "# Apply Bing sentiment analysis\n",
    "sona_speeches_clean['bing_sentiment'] = sona_speeches_clean['speech_untrans'].apply(get_bing_sentiment)\n",
    "sona_sentences_all_untrans['bing_sentiment'] = sona_sentences_all_untrans['sent_untrans'].apply(get_bing_sentiment)\n",
    "\n",
    "# Apply AFINN sentiment analysis\n",
    "sona_speeches_clean['afinn_sentiment'] = sona_speeches_clean['speech_untrans'].apply(lambda text: get_afinn_sentiment(text))\n",
    "sona_sentences_all_untrans['afinn_sentiment'] = sona_sentences_all_untrans['sent_untrans'].apply(lambda text: get_afinn_sentiment(text))\n",
    "\n",
    "# Convert the date strings to datetime objects\n",
    "sona_speeches_clean['date'] = sona_speeches_clean['date'].apply(parse_date)\n",
    "sona_sentences_all_untrans['date'] = sona_sentences_all_untrans['date'].apply(parse_date)\n",
    "\n",
    "# Sort the DataFrames by date in ascending order\n",
    "sona_speeches_clean.sort_values('date', ascending=True, inplace=True)\n",
    "#sona_sentences_all_untrans.sort_values('date', ascending=True, inplace=True)\n",
    "\n",
    "# Create a new variable which is the date as a string\n",
    "sona_speeches_clean['date_str'] = sona_speeches_clean['date'].dt.strftime('%Y-%m-%d')\n",
    "sona_sentences_all_untrans['date_str'] = sona_sentences_all_untrans['date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# For plotting sentiment scores of speeches by each president\n",
    "def plot_speeches_by_president(df, lexicon):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    presidents = df['president'].unique()\n",
    "\n",
    "    lexicon_lab = lexicon\n",
    "\n",
    "    if lexicon == 'afinn':\n",
    "        lexicon_lab = 'AFINN'\n",
    "\n",
    "    colors = ['lightsteelblue', colormap[1], 'midnightblue', 'lightgray', 'darkgray',  'dimgray']\n",
    "\n",
    "    for idx, president in enumerate(presidents):\n",
    "        president_df = df[df['president'] == president]\n",
    "        plt.bar(president_df['date_str'], president_df[f'{lexicon}_sentiment'], label=president, color=colors[idx])\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel(f'Sentiment Score')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks()\n",
    "    plt.legend(loc =\"upper left\")\n",
    "    plt.savefig(f'sentiment_plots/speech_{lexicon}_all.png', bbox_inches='tight')\n",
    "    plt.close()  # Close the figure to avoid displaying it in the notebook\n",
    "\n",
    "\n",
    "# For plotting sentiment scores of sentences by each president\n",
    "def plot_sentences_by_president(df, lexicon):\n",
    "    #plt.figure(figsize=(10, 6))\n",
    "\n",
    "    presidents = df['president'].unique()\n",
    "\n",
    "    colors = [colormap[1],  'dimgray', 'midnightblue', 'darkgray', 'lightsteelblue', 'lightgray']\n",
    "\n",
    "    lexicon_lab = lexicon\n",
    "\n",
    "    if lexicon == 'afinn':\n",
    "        lexicon_lab = 'AFINN'\n",
    "    \n",
    "    # Create a copy of the DataFrame\n",
    "    df = df.copy()\n",
    "\n",
    "    # Add a column for the sentence number\n",
    "    df['sentence_num'] = df.groupby('date_str').cumcount() + 1\n",
    "    \n",
    "    i = 0\n",
    "\n",
    "    for idx, president in enumerate(presidents):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        president_df = df[df['president'] == president]\n",
    "        plt.bar(president_df['sentence_num'], president_df[f'{lexicon}_sentiment'], label=president, color=colors[i])\n",
    "        plt.xlabel('Sentence')\n",
    "        plt.ylabel(f'Sentiment Score')\n",
    "        plt.xticks()\n",
    "        plt.savefig(f'sentiment_plots/sent_{lexicon}_{president}.png', bbox_inches='tight')\n",
    "        plt.close()  # Close the figure to avoid displaying it in the notebook\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    \n",
    "# Assuming 'date' is a column in datetime format and 'president' is the name of each president\n",
    "plot_speeches_by_president(sona_speeches_clean, 'bing')\n",
    "plot_speeches_by_president(sona_speeches_clean, 'afinn')\n",
    "\n",
    "plot_sentences_by_president(sona_sentences_all_untrans, 'bing')\n",
    "plot_sentences_by_president(sona_sentences_all_untrans, 'afinn')\n",
    "\n",
    "# Function to calculate word sentiments across all speeches of a president\n",
    "def calculate_word_sentiments(president_speeches, lexicon):\n",
    "    # Combine all speeches into one large text\n",
    "    all_speeches = ' '.join(president_speeches)\n",
    "    # Tokenize the text into words and filter out stopwords and non-alphabetic tokens\n",
    "    words = [word for word in word_tokenize(all_speeches.lower()) if word.isalpha() and word not in stopwords.words('english')]\n",
    "    # Get sentiment score for each word\n",
    "    word_sentiments = defaultdict(int)\n",
    "    for word in words:\n",
    "        # Get the sentiment score for the word\n",
    "        if lexicon == 'bing':\n",
    "            sentiment = get_bing_sentiment(word)\n",
    "        elif lexicon == 'afinn':\n",
    "            sentiment = get_afinn_sentiment(word)\n",
    "\n",
    "        word_sentiments[word] += sentiment\n",
    "    return word_sentiments\n",
    "\n",
    "# Function to plot the top positive and negative words\n",
    "def plot_top_words(word_sentiments, president, lexicon):\n",
    "    # Sort words by sentiment score\n",
    "    sorted_words = sorted(word_sentiments.items(), key=lambda kv: kv[1])\n",
    "    # Select the top 10 positive and negative words\n",
    "    top_positive_words = sorted_words[-10:]\n",
    "    top_negative_words = sorted_words[:10]\n",
    "\n",
    "    # Words and their sentiment scores for plotting\n",
    "    words_positive, scores_positive = zip(*top_positive_words)\n",
    "    words_negative, scores_negative = zip(*top_negative_words)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot the top negative words\n",
    "    ax.barh(range(10), scores_negative, color=colormap[2], label='Negative')\n",
    "    # Plot the top positive words\n",
    "    ax.barh(range(10, 20), scores_positive, color=colormap[0], label='Positive')\n",
    "\n",
    "    # Add the word labels\n",
    "    ax.set_yticks(range(20))\n",
    "    ax.set_yticklabels(words_negative + words_positive)\n",
    "    \n",
    "    # Set the labels and title\n",
    "    ax.set_xlabel(f'Contribution to Sentiment Score')\n",
    "    ax.legend(loc = \"lower right\")\n",
    "\n",
    "    # Adjust the view so negative words are at the bottom and positive at the top\n",
    "    ax.set_ylim(-1, 20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    # Save the plot as a PNG file\n",
    "    plt.savefig(f'sentiment_plots/word_contr_{lexicon}_{president}.png', bbox_inches='tight')\n",
    "    plt.close()  # Close the figure to avoid displaying it in the notebook\n",
    "\n",
    "# Aggregate the speeches by president and calculate the top words\n",
    "presidents_speeches = sona_speeches_clean.groupby('president')['speech_untrans'].apply(list)\n",
    "for president, speeches in presidents_speeches.items():\n",
    "    word_sentiments_bing = calculate_word_sentiments(speeches, 'bing')\n",
    "    word_sentiments_afinn = calculate_word_sentiments(speeches, 'afinn')\n",
    "    plot_top_words(word_sentiments_bing, president, 'bing')\n",
    "    plot_top_words(word_sentiments_bing, president, 'AFINN')\n",
    "\n",
    "\n",
    "# Function to calculate word sentiments across all speeches\n",
    "def calculate_word_sentiments(speeches, lexicon):\n",
    "    # Combine all speeches into one large text\n",
    "    all_speeches = ' '.join(speeches)\n",
    "    # Tokenize the text into words and filter out stopwords and non-alphabetic tokens\n",
    "    words = [word for word in word_tokenize(all_speeches.lower()) if word.isalpha() and word not in stopwords.words('english')]\n",
    "    # Get sentiment score for each word\n",
    "    word_sentiments = defaultdict(int)\n",
    "    for word in words:\n",
    "        # Get the sentiment score for the word\n",
    "        if lexicon == 'bing':\n",
    "            sentiment = get_bing_sentiment(word)\n",
    "        elif lexicon == 'afinn':\n",
    "            sentiment = get_afinn_sentiment(word)\n",
    "\n",
    "        word_sentiments[word] += sentiment\n",
    "    return word_sentiments\n",
    "\n",
    "# Function to plot the top positive and negative words\n",
    "def plot_top_words(word_sentiments, lexicon):\n",
    "    # Sort words by sentiment score\n",
    "    sorted_words = sorted(word_sentiments.items(), key=lambda kv: kv[1])\n",
    "    # Select the top 10 positive and negative words\n",
    "    top_positive_words = sorted_words[-10:]\n",
    "    top_negative_words = sorted_words[:10]\n",
    "\n",
    "    # Words and their sentiment scores for plotting\n",
    "    words_positive, scores_positive = zip(*top_positive_words)\n",
    "    words_negative, scores_negative = zip(*top_negative_words)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot the top negative words\n",
    "    ax.barh(range(10), scores_negative, color=colormap[2], label='Negative')\n",
    "    # Plot the top positive words\n",
    "    ax.barh(range(10, 20), scores_positive, color=colormap[0], label='Positive')\n",
    "\n",
    "    # Add the word labels\n",
    "    ax.set_yticks(range(20))\n",
    "    ax.set_yticklabels(words_negative + words_positive)\n",
    "    # ax.yticks(fontsize=16)\n",
    "\n",
    "    # Set the labels and title\n",
    "    ax.set_xlabel(f'Contribution to Sentiment Score')\n",
    "    ax.legend()\n",
    "    # ax.xticks(fontsize=16)\n",
    "\n",
    "    # Adjust the view so negative words are at the bottom and positive at the top\n",
    "    ax.set_ylim(-1, 20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'sentiment_plots/word_contr_{lexicon}_all.png', bbox_inches='tight')\n",
    "    plt.close()  # Close the figure to avoid displaying it in the notebook\n",
    "\n",
    "# Calculate the word sentiments across all speeches for each lexicon\n",
    "all_speeches = sona_speeches_clean['speech_untrans'].tolist()\n",
    "word_sentiments_bing = calculate_word_sentiments(all_speeches, 'bing')\n",
    "word_sentiments_afinn = calculate_word_sentiments(all_speeches, 'afinn')\n",
    "\n",
    "# Plot the top words for each lexicon\n",
    "plot_top_words(word_sentiments_bing, 'bing')\n",
    "plot_top_words(word_sentiments_afinn, 'AFINN')\n",
    "\n",
    "\n",
    "texts = sona_speeches_clean['speech']\n",
    "sentences = sona_sentences_alltogether['sentence']\n",
    "\n",
    "# Further process tokens using gensim's simple_preprocess\n",
    "tokenized_texts = [simple_preprocess(doc, deacc=True) for doc in texts]  # deacc=True removes punctuations\n",
    "tokenized_sentences = [simple_preprocess(doc, deacc=True) for doc in sentences]  # deacc=True removes punctuations\n",
    "\n",
    "# Create a Gensim dictionary from the tokenized documents\n",
    "dictionary = corpora.Dictionary(tokenized_texts)\n",
    "dict_sentences = corpora.Dictionary(tokenized_sentences)\n",
    "\n",
    "#dictionary.filter_extremes(no_below=2, no_above=0.7)\n",
    "#dict_sentences.filter_extremes(no_below=2, no_above=0.7)\n",
    "\n",
    "# Create a BOW corpus\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in tokenized_texts]\n",
    "bow_corpus_sentences = [dict_sentences.doc2bow(text) for text in tokenized_sentences]\n",
    "\n",
    "# Create a TF-IDF corpus\n",
    "tfidf = TfidfModel(bow_corpus)\n",
    "tfidf_corpus = tfidf[bow_corpus]\n",
    "\n",
    "tfidf_sentences = TfidfModel(bow_corpus_sentences)\n",
    "tfidf_corpus_sentences = tfidf_sentences[bow_corpus_sentences]\n",
    "\n",
    "\n",
    "# Define the function to compute coherence values\n",
    "def compute_coherence_values(dictionary, corpus, texts, start, limit, step, coherence='u_mass'):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = LsiModel(corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=tokenized_texts, dictionary=dictionary, coherence=coherence)\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "    return model_list, coherence_values\n",
    "\n",
    "# Set parameters\n",
    "start, limit, step = 2, 20, 1\n",
    "\n",
    "# Compute coherence values for BOW\n",
    "bow_model_list, bow_coherence_values = compute_coherence_values(dictionary=dictionary, corpus=bow_corpus, texts=texts, start=start, limit=limit, step=step)\n",
    "\n",
    "bow_model_list_sentences, bow_coherence_values_sentences = compute_coherence_values(dictionary=dict_sentences, corpus=bow_corpus_sentences, texts=sentences, start=start, limit=limit, step=step)\n",
    "\n",
    "# Compute coherence values for TF-IDF\n",
    "tfidf_model_list, tfidf_coherence_values = compute_coherence_values(dictionary=dictionary, corpus=tfidf_corpus, texts=tokenized_texts, start=start, limit=limit, step=step)\n",
    "\n",
    "tfidf_model_list_sentences, tfidf_coherence_values_sentences = compute_coherence_values(dictionary=dict_sentences, corpus=tfidf_corpus_sentences, texts=sentences, start=start, limit=limit, step=step)\n",
    "\n",
    "# Save the to csv\n",
    "coherence_df = pd.DataFrame({'bow_coherence_values': bow_coherence_values, 'tfidf_coherence_values': tfidf_coherence_values, 'bow_coherence_values_sentences': bow_coherence_values_sentences, 'tfidf_coherence_values_sentences': tfidf_coherence_values_sentences})\n",
    "\n",
    "coherence_df.to_csv('lsa_plots/coherence_values.csv', index=False)\n",
    "\n",
    "\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "# Read in the coherence values\n",
    "coherence_df = pd.read_csv('lsa_plots/coherence_values.csv')\n",
    "\n",
    "# Extract the coherence values\n",
    "bow_coherence_values = coherence_df['bow_coherence_values']\n",
    "tfidf_coherence_values = coherence_df['tfidf_coherence_values']\n",
    "bow_coherence_values_sentences = coherence_df['bow_coherence_values_sentences']\n",
    "tfidf_coherence_values_sentences = coherence_df['tfidf_coherence_values_sentences']\n",
    "\n",
    "# Plotting the coherence values\n",
    "x = range(start, limit, step)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, bow_coherence_values, label='BoW', color='midnightblue')\n",
    "plt.plot(x, tfidf_coherence_values, label='tf-idf', color='darkgray')\n",
    "plt.xlabel(\"Number of Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend(loc='lower left')\n",
    "plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.savefig(f'lsa_plots/words_coherence_plots.png', bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Plotting the coherence values\n",
    "x = range(start, limit, step)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, bow_coherence_values_sentences, label='BoW', color='midnightblue')\n",
    "plt.plot(x, tfidf_coherence_values_sentences, label='tf-idf', color='darkgray')\n",
    "plt.xlabel(\"Number of Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.savefig(f'lsa_plots/sentence_coherence_plots.png', bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# TODO: Set the number of topics based on the plots\n",
    "lsa_bow_words = LsiModel(corpus=bow_corpus, num_topics=3, id2word=dictionary)\n",
    "lsa_bow_sentences = LsiModel(corpus=bow_corpus_sentences, num_topics=2, id2word=dict_sentences)\n",
    "\n",
    "lsa_tfidf_words = LsiModel(corpus=tfidf_corpus, num_topics=3, id2word=dictionary)\n",
    "lsa_tfidf_sentences = LsiModel(corpus=tfidf_corpus_sentences, num_topics=2, id2word=dict_sentences)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to plot the top words for each topic in a single LSA model\n",
    "def plot_top_words_for_each_topic(model, fiton, lexicon, num_words=10):\n",
    "\n",
    "    colors = ['lightsteelblue', 'midnightblue', 'lightgray', 'darkgray', 'dimgray']\n",
    "    \n",
    "    j = 0\n",
    "\n",
    "    for i in range(model.num_topics):\n",
    "        # Extract the top words for this topic\n",
    "        top_words = model.show_topic(i, num_words)\n",
    "        # Separate the words and their corresponding weights\n",
    "        words, weights = zip(*top_words)\n",
    "        weights = [abs(weight) for weight in weights]  # Use absolute values for weights\n",
    "\n",
    "        # Create a bar chart for the top words in this topic\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.barh(words, weights, color = colors[j])\n",
    "        # ax.set_yticklabels(words, fontsize=20)\n",
    "        j += 1\n",
    "\n",
    "        if j == 4:\n",
    "            j = 0\n",
    "\n",
    "        plt.xlabel('Weight')\n",
    "        plt.gca().invert_yaxis()  # Highest weights on top\n",
    "        plt.savefig(f'lsa_plots/{fiton}_{lexicon}_topic_{i + 1}.png', bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "# Apply the plotting function to each of your LSA models\n",
    "plot_top_words_for_each_topic(lsa_bow_words, 'words', 'bow')\n",
    "plot_top_words_for_each_topic(lsa_bow_sentences, 'sentences', 'bow')\n",
    "plot_top_words_for_each_topic(lsa_tfidf_words, 'words', 'tfidf')\n",
    "plot_top_words_for_each_topic(lsa_tfidf_sentences, 'sentences', 'tfidf')\n",
    "\n",
    "sona_speeches_clean['speech'].to_csv('data/sona_speeches_only.csv', index=False)\n",
    "sona_sentences_alltogether['sentence'].to_csv('data/sona_sentences_only.csv', index=False)\n",
    "\n",
    "import math\n",
    "\n",
    "def calculate_umass_coherence(plsa_result, corpus, top_n=10, tf_idf=False):\n",
    "    # Extract the top N words for each topic\n",
    "    top_words_by_topic = [\n",
    "        [word for word, _ in plsa_result.word_given_topic[i][:top_n]]\n",
    "        for i in range(plsa_result.n_topics)\n",
    "    ]\n",
    "    \n",
    "    # Get document-word matrix (document frequency matrix)\n",
    "    doc_word_matrix = corpus.get_doc_word(tf_idf=tf_idf)\n",
    "    \n",
    "    # Calculate document frequencies for single words\n",
    "    word_doc_freq = np.sum(doc_word_matrix > 0, axis=0)\n",
    "    \n",
    "    # Calculate coherence for each topic\n",
    "    topic_coherences = []\n",
    "    for top_words in top_words_by_topic:\n",
    "        pair_scores = []\n",
    "        for i, word in enumerate(top_words):\n",
    "            for j in range(i + 1, len(top_words)):\n",
    "                # Get indices in the vocabulary\n",
    "                word_i_index = corpus.index[word]\n",
    "                word_j_index = corpus.index[top_words[j]]\n",
    "                \n",
    "                # Count the documents where both words appear\n",
    "                both_docs = np.sum((doc_word_matrix[:, word_i_index] > 0) & (doc_word_matrix[:, word_j_index] > 0))\n",
    "                \n",
    "                # Calculate score for this word pair\n",
    "                score = math.log((both_docs + 1.0) / word_doc_freq[word_i_index])  # Add 1 to avoid log(0)\n",
    "                pair_scores.append(score)\n",
    "                \n",
    "        # Average over all pairs to get the topic coherence\n",
    "        topic_coherence = sum(pair_scores) / len(pair_scores)\n",
    "        topic_coherences.append(topic_coherence)\n",
    "        \n",
    "    # Average over all topics to get the overall coherence\n",
    "    overall_coherence = sum(topic_coherences) / len(topic_coherences)\n",
    "    return overall_coherence\n",
    "\n",
    "\n",
    "pipeline = Pipeline(*DEFAULT_PIPELINE)\n",
    "\n",
    "corpus = Corpus.from_csv(\"data/sona_speeches_only.csv\", pipeline)\n",
    "corpus_sent = Corpus.from_csv(\"data/sona_sentences_only.csv\", pipeline)\n",
    "\n",
    "topic_numbers = range(2, 12, 1)\n",
    "\n",
    "# Loop over the topic number and calculate the coherence values\n",
    "bow_coherence_values = []\n",
    "bow_coherence_values_sent = []\n",
    "tfidf_coherence_values = []\n",
    "tfidf_coherence_values_sent = []\n",
    "\n",
    "for n_topics in topic_numbers:\n",
    "    # Initialize the models\n",
    "    tfidf_plsa = PLSA(corpus, n_topics, tf_idf=True)\n",
    "    bow_plsa = PLSA(corpus, n_topics, tf_idf=False)\n",
    "\n",
    "    tfidf_plsa_sent = PLSA(corpus_sent, n_topics, tf_idf=True)\n",
    "    bow_plsa_sent = PLSA(corpus_sent, n_topics, tf_idf=False)\n",
    "\n",
    "    # Fit the models\n",
    "    tfidf_result = tfidf_plsa.fit()\n",
    "    bow_result = bow_plsa.fit()\n",
    "    tfidf_result_sent = tfidf_plsa_sent.fit()\n",
    "    bow_result_sent = bow_plsa_sent.fit()\n",
    "\n",
    "    # Calculate the coherence values\n",
    "    bow_coherence_values.append(calculate_umass_coherence(bow_result, corpus, tf_idf=False))\n",
    "    tfidf_coherence_values.append(calculate_umass_coherence(tfidf_result, corpus, tf_idf=True))\n",
    "    bow_coherence_values_sent.append(calculate_umass_coherence(bow_result_sent, corpus_sent, tf_idf=False))\n",
    "    tfidf_coherence_values_sent.append(calculate_umass_coherence(tfidf_result_sent, corpus_sent, tf_idf=True))\n",
    "\n",
    "\n",
    "# Save the coherence value results\n",
    "pd.DataFrame({\n",
    "    'topic_number': topic_numbers,\n",
    "    'bow_coherence': bow_coherence_values,\n",
    "    'tfidf_coherence': tfidf_coherence_values,\n",
    "    'bow_coherence_sent': bow_coherence_values_sent,\n",
    "    'tfidf_coherence_sent': tfidf_coherence_values_sent\n",
    "}).to_csv('data/saved_plsa_coherence_values.csv', index=False)\n",
    "\n",
    "\n",
    "# Load the coherence value results\n",
    "coherence_values = pd.read_csv('data/saved_plsa_coherence_values.csv')\n",
    "\n",
    "topic_numbers = coherence_values['topic_number']\n",
    "bow_coherence_values = coherence_values['bow_coherence']\n",
    "tfidf_coherence_values = coherence_values['tfidf_coherence']\n",
    "bow_coherence_values_sent = coherence_values['bow_coherence_sent']\n",
    "tfidf_coherence_values_sent = coherence_values['tfidf_coherence_sent']\n",
    "\n",
    "# Plot the speech coherence values - updated\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(topic_numbers, bow_coherence_values, label='BoW', color='midnightblue')\n",
    "plt.plot(topic_numbers, tfidf_coherence_values, label='tf-idf', color='darkgray')\n",
    "plt.xlabel(\"Number of Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(f'plsa_plots/words_coherence.png', bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Plot the sentence coherence values - updated\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(topic_numbers, bow_coherence_values_sent, label='BoW', color='midnightblue')\n",
    "plt.plot(topic_numbers, tfidf_coherence_values_sent, label='tf-idf', color='darkgray')\n",
    "plt.xlabel(\"Number of Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(f'plsa_plots/sentences_coherence.png', bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Fit the models with the calibrated number of topics\n",
    "tfidf_plsa = PLSA(corpus, 5, tf_idf=True)\n",
    "bow_plsa = PLSA(corpus, 5, tf_idf=False)\n",
    "tfidf_plsa_sent = PLSA(corpus_sent, 4, tf_idf=True)\n",
    "bow_plsa_sent = PLSA(corpus_sent, 4, tf_idf=False)\n",
    "\n",
    "# Fit the models\n",
    "tfidf_result = tfidf_plsa.fit()\n",
    "bow_result = bow_plsa.fit()\n",
    "tfidf_result_sent = tfidf_plsa_sent.fit()\n",
    "bow_result_sent = bow_plsa_sent.fit()\n",
    "\n",
    "# Function to plot the top words for a given topic\n",
    "def plot_top_words_for_topic(word_given_topic, topic_num, corptype, color, top_n=10):\n",
    "    # Extract the top words for this topic\n",
    "    top_words_data = word_given_topic[topic_num][:top_n]\n",
    "    words, probabilities = zip(*top_words_data)\n",
    "\n",
    "    # Create a bar plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(words, probabilities, color=color)\n",
    "    plt.xlabel('Probability')\n",
    "    plt.gca().invert_yaxis() \n",
    "    plt.savefig(f'plsa_plots/{corptype}_topic_{topic_num + 1}.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_word_contribution(result, corptype):\n",
    "    # Number of topics in your model\n",
    "    n_topics = len(result.word_given_topic)\n",
    "\n",
    "    colors = ['lightsteelblue', 'midnightblue', 'lightgray', 'darkgray', 'dimgray']\n",
    "    \n",
    "    i = 0\n",
    "\n",
    "    # Plot the top words for each topic\n",
    "    for topic_num in range(n_topics):\n",
    "        plot_top_words_for_topic(result.word_given_topic, topic_num, corptype, colours[i])\n",
    "        i+=1\n",
    "\n",
    "        # if i == 4:\n",
    "        #     i = 0\n",
    "\n",
    "# Plot the word contribution for each topic for each model\n",
    "plot_word_contribution(bow_result, 'words-BoW')\n",
    "plot_word_contribution(tfidf_result, 'words-tf-idf')\n",
    "plot_word_contribution(bow_result_sent, 'sentences-BoW')\n",
    "plot_word_contribution(tfidf_result_sent, 'sentences-tf-idf')\n",
    "\n",
    "\n",
    "texts = sona_speeches_clean['speech']\n",
    "sentences = sona_sentences_alltogether['sentence']\n",
    "\n",
    "# Further process tokens using gensim's simple_preprocess\n",
    "tokenized_texts = [simple_preprocess(doc, deacc=True) for doc in texts]  # deacc=True removes punctuations\n",
    "tokenized_sentences = [simple_preprocess(doc, deacc=True) for doc in sentences]  # deacc=True removes punctuations\n",
    "\n",
    "# Create a Gensim dictionary from the tokenized documents\n",
    "dictionary = corpora.Dictionary(tokenized_texts)\n",
    "dictionary.filter_extremes(no_below=3, no_above=0.7)\n",
    "\n",
    "dict_sentences = corpora.Dictionary(tokenized_sentences)\n",
    "dict_sentences.filter_extremes(no_below=3, no_above=0.7)\n",
    "\n",
    "# Create a BOW corpus\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in tokenized_texts]\n",
    "bow_corpus_sentences = [dict_sentences.doc2bow(text) for text in tokenized_sentences]\n",
    "\n",
    "# Create a TF-IDF corpus\n",
    "tfidf = TfidfModel(bow_corpus)\n",
    "tfidf_corpus = tfidf[bow_corpus]\n",
    "\n",
    "tfidf_sentences = TfidfModel(bow_corpus_sentences)\n",
    "tfidf_corpus_sentences = tfidf_sentences[bow_corpus_sentences]\n",
    "\n",
    "\n",
    "# Define the function to compute coherence values\n",
    "def compute_coherence_values(corpus, dictionary, k, a, b, texts):\n",
    "    lda_model = LdaModel(corpus=corpus,\n",
    "                         id2word=dictionary,\n",
    "                         num_topics=k, \n",
    "                         random_state=100,\n",
    "                         eval_every=None,\n",
    "                         alpha=a,\n",
    "                         eta=b)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='u_mass')\n",
    "    \n",
    "    return coherence_model_lda.get_coherence()\n",
    "\n",
    "# Define the parameter space for grid search\n",
    "grid = {}\n",
    "grid['Validation_Set'] = {}\n",
    "# Topics range\n",
    "min_topics = 2\n",
    "max_topics = 10\n",
    "step_size = 1\n",
    "topics_range = range(min_topics, max_topics, step_size)\n",
    "# Alpha parameter\n",
    "alpha = list(np.arange(0.1, 1, 0.1))\n",
    "# Beta parameter\n",
    "beta = list(np.arange(0.1, 1, 0.2))\n",
    "\n",
    "# Validation sets\n",
    "num_of_docs = len(bow_corpus)\n",
    "corpus_sets = [tfidf_corpus, \n",
    "               bow_corpus]\n",
    "corpus_title = ['TF-IDF Corpus', 'BoW Corpus']\n",
    "model_results = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "model_results_sentences = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "\n",
    "# Can take a long time to run\n",
    "# If you want to only test a few models, reduce the number of steps in topics_range\n",
    "# and/or limit the number of values in alpha and beta lists.\n",
    "if 1 == 1:\n",
    "    pbar = tqdm.tqdm(total=(max_topics-min_topics)*len(alpha)*len(beta)*len(corpus_sets))\n",
    "    \n",
    "    # iterate through validation corpuses\n",
    "    for i in range(len(corpus_sets)):\n",
    "        # iterate through number of topics\n",
    "        for k in topics_range:\n",
    "            # iterate through alpha values\n",
    "            for a in alpha:\n",
    "                # iterare through beta values\n",
    "                for b in beta:\n",
    "                    # get the coherence score for the given parameters\n",
    "                    cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=dictionary, k=k, a=a, b=b, texts=tokenized_texts)\n",
    "                    # Save the model results\n",
    "                    model_results['Validation_Set'].append(corpus_title[i])\n",
    "                    model_results['Topics'].append(k)\n",
    "                    model_results['Alpha'].append(a)\n",
    "                    model_results['Beta'].append(b)\n",
    "                    model_results['Coherence'].append(cv)\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "    pbar.close()\n",
    "\n",
    "\n",
    "# Get the results for the sentences\n",
    "if 1 == 1:\n",
    "    pbar = tqdm.tqdm(total=(max_topics-min_topics)*len(alpha)*len(beta)*len(corpus_sets))\n",
    "    \n",
    "    # iterate through validation corpuses\n",
    "    for i in range(len(corpus_sets)):\n",
    "        # iterate through number of topics\n",
    "        for k in topics_range:\n",
    "            # iterate through alpha values\n",
    "            for a in alpha:\n",
    "                # iterare through beta values\n",
    "                for b in beta:\n",
    "                    # get the coherence score for the given parameters\n",
    "                    cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=dict_sentences, k=k, a=a, b=b, texts=tokenized_sentences)\n",
    "                    # Save the model results\n",
    "                    model_results_sentences['Validation_Set'].append(corpus_title[i])\n",
    "                    model_results_sentences['Topics'].append(k)\n",
    "                    model_results_sentences['Alpha'].append(a)\n",
    "                    model_results_sentences['Beta'].append(b)\n",
    "                    model_results_sentences['Coherence'].append(cv)\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "    pbar.close()\n",
    "\n",
    "\n",
    "# # Save the results to a csv\n",
    "# model_results_df = pd.DataFrame(model_results)\n",
    "# model_results_sentences_df = pd.DataFrame(model_results_sentences)\n",
    "\n",
    "# model_results_df.to_csv('data/sona_speeches_lda.csv', index=False)\n",
    "# model_results_sentences_df.to_csv('data/sona_sentences_lda.csv', index=False)\n",
    "\n",
    "# Save the results to a csv\n",
    "model_results_df = pd.read_csv('data/sona_speeches_lda.csv')\n",
    "sorted_speeches_df = model_results_df.sort_values(by='Coherence', ascending=False)\n",
    "\n",
    "# Concatenate the head and tail of the DataFrame\n",
    "combined_speeches_df = pd.concat([sorted_speeches_df.head(5), sorted_speeches_df.tail(5)])\n",
    "\n",
    "combined_speeches_df['Validation_Set'] = combined_speeches_df['Validation_Set'].replace(['TF-IDF Corpus', 'BoW Corpus'], ['tf-idf', 'BoW'])\n",
    "\n",
    "# Change the validation set column name from \"Validation_Set\" to \"Corpus\"\n",
    "combined_speeches_df = combined_speeches_df.rename(columns={'Validation_Set': 'Corpus'})\n",
    "\n",
    "# Save the results to a csv\n",
    "model_results_sentences_df = pd.read_csv('data/sona_sentences_lda.csv')\n",
    "sorted_sentences_df = model_results_sentences_df.sort_values(by='Coherence', ascending=False)\n",
    "\n",
    "# Concatenate the head and tail of the DataFrame\n",
    "combined_sentences_df = pd.concat([sorted_sentences_df.head(5), sorted_sentences_df.tail(5)])\n",
    "combined_sentences_df['Validation_Set'] = combined_sentences_df['Validation_Set'].replace(['TF-IDF Corpus', 'BoW Corpus'], ['tf-idf', 'BoW'])\n",
    "\n",
    "# Change the validation set column name from \"Validation_Set\" to \"Corpus\"\n",
    "combined_sentences_df = combined_sentences_df.rename(columns={'Validation_Set': 'Corpus'})\n",
    "\n",
    "num_cols = combined_sentences_df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Remove the first value from the num_cols\n",
    "num_cols = num_cols[1:]\n",
    "\n",
    "# Use pivot_table to handle duplicate (Alpha, Beta) pairs by averaging their coherence values\n",
    "pivot_table = model_results_df.pivot_table(index='Alpha', columns='Beta', values='Coherence', aggfunc=np.mean)\n",
    "pivot_table_sentences = model_results_sentences_df.pivot_table(index='Alpha', columns='Beta', values='Coherence', aggfunc=np.mean)\n",
    "\n",
    "# Create the meshgrid for Alpha and Beta values\n",
    "Alpha, Beta = np.meshgrid(pivot_table.columns, pivot_table.index)\n",
    "Alpha_sentences, Beta_sentences = np.meshgrid(pivot_table_sentences.columns, pivot_table_sentences.index)\n",
    "\n",
    "# Create the contour plot using the values of the pivot_table\n",
    "# We need to use the values attribute to get the coherence scores as a 2D array\n",
    "plt.figure(figsize=(8, 6))\n",
    "cp = plt.contourf(Alpha, Beta, pivot_table.values, cmap='seismic', levels=100)\n",
    "plt.colorbar(cp)\n",
    "plt.xlabel('Beta')\n",
    "plt.ylabel('Alpha')\n",
    "plt.savefig(f'lda_plots/words_contour_plot.png', bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "cp = plt.contourf(Alpha_sentences, Beta_sentences, pivot_table_sentences.values, cmap='seismic', levels=100)\n",
    "plt.colorbar(cp)\n",
    "plt.xlabel('Beta')\n",
    "plt.ylabel('Alpha')\n",
    "plt.savefig(f'lda_plots/sentences_contour_plot.png', bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "def style_df(df):\n",
    "    # Select the numeric columns except the first one\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns[1:]\n",
    "    format_dict = {col: \"{:.2f}\" for col in numeric_cols}\n",
    "    styles = [\n",
    "        dict(selector=\"th\", props=[(\"text-align\", \"center\")]),\n",
    "        dict(selector=\"td\", props=[(\"text-align\", \"center\")]),\n",
    "        dict(selector=\"\", props=[(\"margin\", \"auto\"), (\"border\", \"1px solid black\")])\n",
    "    ]\n",
    "    return df.style.set_table_styles(styles).format(format_dict).hide()\n",
    "\n",
    "\n",
    "# Save the results to a csv\n",
    "style_df(combined_speeches_df)\n",
    "\n",
    "\n",
    "# Save the results to a csv\n",
    "style_df(combined_sentences_df)\n",
    "\n",
    "\n",
    "# Train the best models for each corpus\n",
    "lda_model_speeches = LdaModel(corpus=bow_corpus,\n",
    "                         id2word=dictionary,\n",
    "                         num_topics=9, \n",
    "                         random_state=100,\n",
    "                         eval_every=None,\n",
    "                         alpha=0.6,\n",
    "                         eta=0.5)\n",
    "\n",
    "lda_model_sentences = LdaModel(corpus=bow_corpus,\n",
    "                         id2word=dict_sentences,\n",
    "                         num_topics=2, \n",
    "                         random_state=100,\n",
    "                         eval_every=None,\n",
    "                         alpha=0.9,\n",
    "                         eta=0.9)\n",
    "\n",
    "# Prepare the visualization data\n",
    "vis_data_speeches = pyLDAvis.gensim_models.prepare(lda_model_speeches, bow_corpus, dictionary)\n",
    "vis_data_sentences = pyLDAvis.gensim_models.prepare(lda_model_sentences, bow_corpus_sentences, dict_sentences)\n",
    "\n",
    "# Enable the automatic display of visualizations in the Jupyter notebook\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "# Display the visualization\n",
    "pyLDAvis.display(vis_data_speeches)\n",
    "\n",
    "\n",
    "# Display the visualization\n",
    "pyLDAvis.display(vis_data_sentences)\n",
    "\n",
    "\n",
    "import tomotopy as tp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to calculate coherence scores\n",
    "def calculate_coherence(model, metric='u_mass'):\n",
    "    coherence = tp.coherence.Coherence(model, coherence=metric)\n",
    "    return coherence.get_score()\n",
    "\n",
    "# Prepare the data for the CTM model\n",
    "tokenized_docs = [text.split() for text in sona_speeches_clean['speech']]  # Ensure the texts are tokenized\n",
    "tokenized_sentences = [text.split() for text in sona_sentences_alltogether['sentence']]  # Ensure the texts are tokenized\n",
    "\n",
    "\n",
    "# Define the range of topic numbers you want to test\n",
    "topic_numbers = range(2, 12, 1)  # for example from 2 to 20 by step of 2\n",
    "\n",
    "# Store coherence scores for plotting\n",
    "coherence_scores = []\n",
    "coherence_scores_sentences = []\n",
    "\n",
    "for k in topic_numbers:\n",
    "    # Initialize CTM with the current number of topics\n",
    "    ctm = tp.CTModel(k=k)\n",
    "    ctms = tp.CTModel(k=k)\n",
    "\n",
    "    # Add documents to the model\n",
    "    for tokens in tokenized_docs:\n",
    "        ctm.add_doc(tokens)\n",
    "\n",
    "    # Add sentences to the model\n",
    "    for tokens in tokenized_sentences:\n",
    "        ctms.add_doc(tokens)    \n",
    "\n",
    "    # Train the model\n",
    "    ctm.train(0)\n",
    "    ctms.train(0)\n",
    "\n",
    "    for _ in range(100):\n",
    "        ctm.train(10)\n",
    "        ctms.train(10)\n",
    "\n",
    "    # Calculate and store the coherence score\n",
    "    score = calculate_coherence(ctm)\n",
    "    score_sentences = calculate_coherence(ctms)\n",
    "\n",
    "    coherence_scores.append(score)\n",
    "    coherence_scores_sentences.append(score_sentences)\n",
    "\n",
    "    #(f\"Topics: {k}, Coherence Score: {score}\")\n",
    "\n",
    "# Save the coherence scores to a csv\n",
    "pd.DataFrame({\n",
    "    'topic_number': topic_numbers,\n",
    "    'bow_coherence_values': coherence_scores,\n",
    "    'bow_coherence_values_sentences': coherence_scores_sentences\n",
    "}).to_csv('data/saved_ctm_coherence_values.csv', index=False)\n",
    "\n",
    "\n",
    "# Read in the saved values\n",
    "coherence_values = pd.read_csv('data/saved_ctm_coherence_values.csv')\n",
    "\n",
    "topic_numbers = coherence_values['topic_number']\n",
    "coherence_scores = coherence_values['bow_coherence_values']\n",
    "coherence_scores_sentences = coherence_values['bow_coherence_values_sentences']\n",
    "\n",
    "# Plot the speech coherence scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(topic_numbers, coherence_scores,  color='midnightblue')\n",
    "plt.xlabel('Number of Topics')\n",
    "plt.ylabel('Coherence Score')\n",
    "plt.xticks(topic_numbers)\n",
    "plt.savefig(f'ctm_plots/words_coherence_plots.png', bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Plot the sentence coherence scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(topic_numbers, coherence_scores_sentences, color='lightsteelblue')\n",
    "plt.xlabel('Number of Topics')\n",
    "plt.ylabel('Coherence Score')\n",
    "plt.xticks(topic_numbers)\n",
    "plt.savefig(f'ctm_plots/sentences_coherence_plots.png', bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Train the models with the optimal number of topics\n",
    "ctm = tp.CTModel(k=2)\n",
    "ctms = tp.CTModel(k=3)\n",
    "\n",
    "# Add documents to the model\n",
    "for tokens in tokenized_docs:\n",
    "    ctm.add_doc(tokens)\n",
    "\n",
    "# Add sentences to the model\n",
    "for tokens in tokenized_sentences:\n",
    "    ctms.add_doc(tokens)\n",
    "\n",
    "# Train the model\n",
    "ctm.train(0)\n",
    "ctms.train(0)\n",
    "\n",
    "for _ in range(100):\n",
    "    ctm.train(10)\n",
    "    ctms.train(10)\n",
    "\n",
    "# Function to plot the top words for one topic\n",
    "def plot_top_words_for_topic(model, modtype, topic_num, color, top_n=10):\n",
    "    # Extract the top words for this topic\n",
    "    top_words = model.get_topic_words(topic_num, top_n=top_n)\n",
    "    words, weights = zip(*top_words)\n",
    "\n",
    "    # Create a bar chart for the top words in this topic\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(words, weights, color=color)\n",
    "    plt.xlabel('Weight')\n",
    "    plt.gca().invert_yaxis()  # Highest weights on top\n",
    "    plt.savefig(f'ctm_plots/{modtype}_{topic_num+1}.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Plot the top words for each topic for the CTModel of documents\n",
    "i = 0\n",
    "colours = ['midnightblue', 'lightsteelblue']\n",
    "\n",
    "for k in range(ctm.k):\n",
    "    plot_top_words_for_topic(ctm, 'words', k, colours[i])\n",
    "    i+=1\n",
    "\n",
    "    if i == 2:\n",
    "        i = 0\n",
    "\n",
    "i = 0\n",
    "# Plot the top words for each topic for the CTModel of sentences\n",
    "for k in range(ctms.k):\n",
    "    plot_top_words_for_topic(ctms, 'sentences', k, colours[i])\n",
    "    i+=1\n",
    "\n",
    "    if i == 2:\n",
    "        i = 0\n",
    "\n",
    "\n",
    "# Note that ATM only works for BoW. Raw word counts (BoW) is standard because these models are based on the assumption that the data is generated from a multinomial distribution, which does not hold with TF-IDF weights.\n",
    "\n",
    "texts = sona_speeches_clean['speech']\n",
    "sentences = sona_sentences_alltogether['sentence']\n",
    "\n",
    "# Further process tokens using gensim's simple_preprocess\n",
    "tokenized_texts = [simple_preprocess(doc, deacc=True) for doc in texts]  # deacc=True removes punctuations\n",
    "tokenized_sentences = [simple_preprocess(doc, deacc=True) for doc in sentences]  # deacc=True removes punctuations\n",
    "\n",
    "# Create a Gensim dictionary from the tokenized documents\n",
    "dictionary = corpora.Dictionary(tokenized_texts)\n",
    "dictionary.filter_extremes(no_below=3, no_above=0.7)\n",
    "\n",
    "dict_sentences = corpora.Dictionary(tokenized_sentences)\n",
    "dict_sentences.filter_extremes(no_below=3, no_above=0.7)\n",
    "\n",
    "# Create a BOW corpus\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in tokenized_texts]\n",
    "bow_corpus_sentences = [dict_sentences.doc2bow(text) for text in tokenized_sentences]\n",
    "\n",
    "# Prepare the data for the AuthorTopicModel\n",
    "# Create a mapping of authors to documents\n",
    "author2doc = {author: [] for author in sona_speeches_clean['president'].unique()}\n",
    "for i, row in sona_speeches_clean.iterrows():\n",
    "    author2doc[row['president']].append(i)\n",
    "\n",
    "# Create a mapping of authors to sentences\n",
    "author2sent = {author: [] for author in sona_sentences_alltogether['president'].unique()}\n",
    "for i, row in sona_sentences_alltogether.iterrows():\n",
    "    author2sent[row['president']].append(i)\n",
    "\n",
    "\n",
    "# Define the range of topic numbers you want to test\n",
    "topic_numbers = range(2, 12, 1)  # for example from 2 to 20 by step of 2\n",
    "\n",
    "# Store coherence scores for plotting\n",
    "coherence_scores = []\n",
    "coherence_scores_sentences = []\n",
    "\n",
    "for num_topics in topic_numbers:\n",
    "    # Author-Topic LDA model with the current number of topics\n",
    "    author_topic_model = AuthorTopicModel(corpus=bow_corpus, author2doc=author2doc, id2word=dictionary, num_topics=num_topics)\n",
    "    author_topic_model_sentences = AuthorTopicModel(corpus=bow_corpus_sentences, author2doc=author2sent, id2word=dict_sentences, num_topics=num_topics)\n",
    "\n",
    "    # Train the model\n",
    "    author_topic_model.update(bow_corpus, author2doc=author2doc)\n",
    "    author_topic_model_sentences.update(bow_corpus_sentences, author2doc=author2sent)\n",
    "\n",
    "    # Compute coherence score\n",
    "    cm = CoherenceModel(model=author_topic_model, texts=tokenized_docs, dictionary=dictionary, coherence='u_mass')\n",
    "    cm_sentences = CoherenceModel(model=author_topic_model_sentences, texts=tokenized_sentences, dictionary=dict_sentences, coherence='u_mass')\n",
    "\n",
    "    coherence = cm.get_coherence()\n",
    "    coherence_sentences = cm_sentences.get_coherence()\n",
    "\n",
    "    coherence_scores.append(coherence)\n",
    "    coherence_scores_sentences.append(coherence_sentences)\n",
    "\n",
    "# Save the coherence scores to a csv\n",
    "pd.DataFrame({\n",
    "    'topic_number': topic_numbers,\n",
    "    'bow_coherence_values': coherence_scores,\n",
    "    'bow_coherence_values_sentences': coherence_scores_sentences\n",
    "}).to_csv('data/saved_atm_coherence_values.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "# Read in the saved values\n",
    "coherence_values = pd.read_csv('data/saved_atm_coherence_values.csv')\n",
    "\n",
    "topic_numbers = coherence_values['topic_number']\n",
    "coherence_scores = coherence_values['bow_coherence_values']\n",
    "coherence_scores_sentences = coherence_values['bow_coherence_values_sentences']\n",
    "\n",
    "# Plot the speech coherence scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(topic_numbers, coherence_scores,  color='midnightblue')\n",
    "plt.title('Coherence Scores by Number of Topics')\n",
    "plt.xlabel('Number of Topics')\n",
    "plt.ylabel('Coherence Score')\n",
    "plt.xticks(topic_numbers)\n",
    "plt.savefig(f'atm_plots/words_coherence_plots.png', bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Plot the sentence coherence scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(topic_numbers, coherence_scores_sentences, color='lightsteelblue')\n",
    "plt.title('Coherence Scores by Number of Topics')\n",
    "plt.xlabel('Number of Topics')\n",
    "plt.ylabel('Coherence Score')\n",
    "plt.xticks(topic_numbers)\n",
    "plt.savefig(f'atm_plots/sentences_coherence_plots.png', bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Author-Topic LDA model with the current number of topics\n",
    "author_topic_model = AuthorTopicModel(corpus=bow_corpus, author2doc=author2doc, id2word=dictionary, num_topics=2)\n",
    "author_topic_model_sentences = AuthorTopicModel(corpus=bow_corpus_sentences, author2doc=author2sent, id2word=dict_sentences, num_topics=3)\n",
    "\n",
    "# Train the model\n",
    "author_topic_model.update(bow_corpus, author2doc=author2doc)\n",
    "author_topic_model_sentences.update(bow_corpus_sentences, author2doc=author2sent)\n",
    "\n",
    "colours = ['midnightblue', 'lightsteelblue', 'darkgray']\n",
    "\n",
    "# Function to plot the top words for one topic in an AuthorTopicModel\n",
    "def plot_top_words_for_author_topic_model(model, modtype, topic_num, colour, top_n=10):\n",
    "    # Extract the top words for this topic\n",
    "    top_words = model.get_topic_terms(topic_num, topn=top_n)\n",
    "    words, weights = zip(*[(model.id2word[word_id], weight) for word_id, weight in top_words])\n",
    "\n",
    "    # Create a bar chart for the top words in this topic\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(words, weights, color=colour)\n",
    "    plt.xlabel('Weight')\n",
    "    plt.gca().invert_yaxis()  # Highest weights on top\n",
    "    plt.savefig(f'atm_plots/{modtype}_{topic_num+1}.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Plot the top words for each topic for the AuthorTopicModel of documents\n",
    "i = 0\n",
    "for k in range(author_topic_model.num_topics):\n",
    "    plot_top_words_for_author_topic_model(author_topic_model, \"words\",k, colours[i])\n",
    "\n",
    "    i += 1\n",
    "\n",
    "    if i == 3:\n",
    "        i = 0\n",
    "\n",
    "i = 0\n",
    "# Plot the top words for each topic for the AuthorTopicModel of sentences\n",
    "for k in range(author_topic_model_sentences.num_topics):\n",
    "    plot_top_words_for_author_topic_model(author_topic_model_sentences, \"sentences\", k, colours[i])\n",
    "\n",
    "    i += 1\n",
    "\n",
    "    if i == 3:\n",
    "        i = 0\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "def show_author(name, model, topic_labels):\n",
    "    print('\\n%s' % name)\n",
    "    print('Docs:', pd.Series(author_topic_model.author2doc[name]).unique())\n",
    "    print('Topics:')\n",
    "    pprint([(topic_labels[topic[0]], topic[1]) for topic in model[name]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (scientificProject)",
   "language": "python",
   "name": "scientificproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}